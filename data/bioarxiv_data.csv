Bioarxiv Title,Bioarxiv Abstract
Improving dictionary-based named entity recognition with deep learning,"Motivation Dictionary-based named entity recognition (NER) allows terms to be detected in a corpus and normalized to biomedical databases and ontologies. However, adaptation to different entity types requires new high-quality dictionaries and associated lists of blocked names for each type. The latter are so far created by identifying cases that cause many false positives through manual inspection of individual names, a process that scales poorly.Results In this work we aim to improve block lists by automatically identifying names to block, based on the context in which they appear. By comparing results of three well-established biomedical NER methods, we generated a dataset of over 12.5 million text spans where the methods agree on the boundaries and type of entity tagged. These were used to generate positive and negative examples of contexts for four entity types (genes, diseases, species, chemicals), which were used to train a Transformer-based model (BioBERT) to perform entity type classification. Application of the best model (F1-score=96.7%) allowed us to generate a list of problematic names that should be blocked. Introducing this into our system doubled the size of the previous list of corpus-wide blocked names. Additionally, we generated a document-specific list that allows ambiguous names to be blocked in specific documents. These changes boosted text mining precision by ∼5.5% on average, and over 8.5% for chemical and 7.5% for gene names, positively affecting several biological databases utilizing this NER system, like the STRING database, with only a minor drop in recall (0.6%).Availability All resources are available through Zenodo https://doi.org/10.5281/zenodo.10800530 and GitHub https://doi.org/10.5281/zenodo.10289360."
Geometric deep learning framework for de novo genome assembly,"The critical stage of every de novo genome assembler is identifying paths in assembly graphs that correspond to the reconstructed genomic sequences. The existing algorithmic methods struggle with this, primarily due to repetitive regions causing complex graph tangles, leading to fragmented assemblies. Here, we introduce GNNome, a framework for path identification based on geometric deep learning that enables training models on assembly graphs without relying on existing assembly strategies. By leveraging symmetries inherent to the problem, GNNome reconstructs assemblies with similar or superior contiguity compared to the state-of-the-art tools across several species, sequenced with PacBio HiFi or Oxford Nanopore. With every new genome assembled telomere-to-telomere, the amount of reliable training data at our disposal increases. Combining the straightforward generation of abundant simulated data for diverse genomic structures with the AI approach makes the proposed framework a plausible cornerstone for future work on reconstructing complex genomes with different ploidy and aneuploidy degrees. To facilitate such developments, we make the framework and the best-performing model publicly available, provided as a tool that can directly be used to assemble new haploid genomes."
Deep Learning Models for Atypical Serotoninergic Cells Recognition,"Background The serotonergic system modulates brain processes via functionally distinct subpopulations of neurons with heterogeneous properties, including their electrophysiological activity. In extracellular recordings, serotonergic neurons to be investigated for their functional properties are commonly identified on the basis of “typical” features of their activity, i.e. slow regular firing and relatively long duration of spikes. Thus, due to the lack of equally robust criteria for discriminating serotonergic neurons with “atypical” features from non-serotonergic cells, the physiological relevance of the diversity of serotonergic neuron activities results largely understudied.New Methods We propose deep learning models capable of discriminating typical and atypical serotonergic neurons from non-serotonergic cells with high accuracy. The research utilized electrophysiological in vitro recordings from serotonergic neurons identified by the expression of fluorescent proteins specific to the serotonergic system and non-serotonergic cells. These recordings formed the basis of the training, validation, and testing data for the deep learning models. The study employed convolutional neural networks (CNNs), known for their efficiency in pattern recognition, to classify neurons based on the specific characteristics of their action potentials.Results The models were trained on a dataset comprising 43,327 original spike samples, alongside an extensive set of 6.7 million synthetic spike samples, designed to mitigate the risk of overfitting the background noise in the recordings, a potential source of bias. Results show that the models achieved high accuracy and were further validated on “non-homogeneous” data, i.e., data not used for constructing the model, to confirm their robustness and reliability in real-world experimental conditions.Comparison with existing methods Conventional methods for identifying serotonergic neurons allow recognition of serotonergic neurons defined as typical. Our model based on the analysis of the sole spike reliably recognizes over 92 features of spike and activity.Conclusions The model is ready for use in experiments conducted with the here described recording parameters. We release the codes and procedures allowing to adapt the model to different acquisition parameters or for identification of other classes of spontaneously active neurons.PACS 87.19.L, 87.19.lv, 87.85.dm, 07.05.Mh, 87.85.Tu"
Ribonanza: deep learning of RNA structure through dual crowdsourcing,"Prediction of RNA structure from sequence remains an unsolved problem, and progress has been slowed by a paucity of experimental data. Here, we present Ribonanza, a dataset of chemical mapping measurements on two million diverse RNA sequences collected through Eterna and other crowdsourced initiatives. Ribonanza measurements enabled solicitation, training, and prospective evaluation of diverse deep neural networks through a Kaggle challenge, followed by distillation into a single, self-contained model called RibonanzaNet. When fine tuned on auxiliary datasets, RibonanzaNet achieves state-of-the-art performance in modeling experimental sequence dropout, RNA hydrolytic degradation, and RNA secondary structure, with implications for modeling RNA tertiary structure."
Interpretable deep learning reveals the sequence rules of Hippo signaling,"SummaryThe response to signaling pathways is highly context-specific, and identifying the transcription factors and mechanisms that are responsible is very challenging. Using the Hippo pathway in mouse trophoblast stem cells as a model, we show here that this information is encoded in cis-regulatory sequences and can be learned from high-resolution binding data of signaling transcription factors. Using interpretable deep learning, we show that the binding levels of TEAD4 and YAP1 are enhanced in a distance-dependent manner by cell type-specific transcription factors, including TFAP2C. We also discovered that strictly spaced Tead double motifs are widespread highly active canonical response elements that mediate cooperativity by promoting labile TEAD4 protein-protein interactions on DNA. These syntax rules and mechanisms apply genome-wide and allow us to predict how small sequence changes alter the activity of enhancers in vivo. This illustrates the power of interpretable deep learning to decode canonical and cell type-specific sequence rules of signaling pathways.Download figureOpen in new tab"
Deep Learning Based Models for Preimplantation Mouse and Human Development,"The rapid growth of single-cell transcriptomic technology has produced an increasing number of datasets for both embryonic development and in vitro pluripotent stem cell derived models. This avalanche of data about pluripotency and the process of lineage specification has meant it has become increasingly difficult to define specific cell types or states and compare these to in vitro differentiation. Here we utilize a set of deep learning (DL) tools to integrate and classify multiple datasets. This allows for the definition of both mouse and human embryo cell types, lineages and states, thereby maximising the information one can garner from these precious experimental resources. Our approaches are built on recent initiatives for large scale human organ atlases, but here we focus on the difficult to obtain and process material that spans early mouse, and in particular, human development. Using publicly available data for these stages, we test different deep learning approaches and develop both a model to classify cell types in an unbiased fashion and define the set of genes required to identify lineages, cell types and states. We have used our predictions to probe pluripotent stem cell models for both mouse and human development, showcasing the importance of this resource as a dynamic reference for early embryogenesis."
Fragle: Universal ctDNA quantification using deep learning of fragmentomic profiles,"Quantification of circulating tumor DNA (ctDNA) levels in blood enables non-invasive surveillance of cancer progression. Fragle is an ultra-fast deep learning-based method for ctDNA quantification directly from cell-free DNA fragment length profiles. We developed Fragle using low-pass whole genome sequence (lpWGS) data from 8 cancer types and healthy control cohorts, demonstrating high accuracy, and improved lower limit of detection in independent cohorts as compared to existing tumor-naïve methods. Uniquely, Fragle is also compatible with targeted sequencing data, exhibiting high accuracy across both research and commercial targeted gene panels. We used this method to study longitudinal plasma samples from colorectal cancer patients, identifying strong concordance of ctDNA dynamics and treatment response. Furthermore, prediction of minimal residual disease in resected lung cancer patients exhibited significant risk stratification beyond a tumor-naïve targeted panel. Overall, Fragle is a versatile, fast, and accurate method for ctDNA quantification with potential for broad clinical utility."
Decoding cell identity with multi-scale explainable deep learning,"Cells are the fundamental structural and functional units of life. Studying the definition and composition of different cell types can help us understand the complex mechanisms underlying biological diversity and functionality. The increasing volume of extensive single-cell omics data makes it possible to provide detailed characterisations of cell types. Recently, there has been a rise in deep learning-based approaches that generate cell type labels solely through mapping query data to reference data. However, these approaches lack multi-scale descriptions and interpretations of identified cell types. Here, we propose Cell Decoder, a biological prior knowledge informed model to achieve multi-scale representation of cells. We implemented automated machine learning and post-hoc analysis techniques to decode cell identity. We have shown that Cell Decoder compares favourably to existing methods, offering multi-view interpretability for decoding cell identity and data integration. Furthermore, we have showcased its applicability in uncovering novel cell types and states in both human bone and mouse embryonic contexts, thereby revealing the multi-scale heterogeneity inherent in cell identities."
Deep Learning Prediction of Glycopeptide Tandem Mass Spectra Powers Glycoproteomics,"Protein glycosylation plays a significant role in numerous physiological and pathological cellular functions. Glycoproteomics based on liquid chromatography-tandem mass spectrometry (LC-MS/MS) studies the protein glycosylation on a proteome-wide scale to get combinational information on glycosylation site, glycosylation level and glycan structure. However, the current sequence searching-based methods for glycoproteomics often fall short in glycan structure determination due to the limited occurrence of structure-determining ions. While spectral searching methods can utilize fragment intensity information to facilitate the identification of glycopeptides, its application is hindered by the difficulties in spectral library construction. In this work, we present DeepGP, a hybrid deep learning framework based on Transformer and graph neural network (GNN), for the prediction of MS/MS spectra and retention time of glycopeptides. Two GNN modules are utilized to capture the branched glycan structure and predict glycan ions intensity, respectively. Additionally, a pre-training strategy is implemented to alleviate the insufficiency of glycoproteomics data. Testing on multiple biological datasets, we demonstrate that DeepGP can predict MS/MS spectra and retention time of glycopeptides closely aligning with the experimental results. Comprehensive benchmarking of DeepGP on synthetic and biological datasets validates its effectiveness in distinguishing similar glycoforms. Remarkably, DeepGP can differentiate isomeric glycopeptides using MS/MS spectra without diagnostic ions. Based on various decoy methods, we demonstrated that DeepGP in combination with database searching can significantly increase the detection sensitivity of glycopeptides. We outlook that DeepGP can inspire extensive future work in glycoproteomics."
Comprehensive Hierarchical Classification of Transposable Elements based on Deep Learning,"Transposable elements (TEs) are DNA sequences capable of translocating within a genome. They constitute a substantial portion of eukaryotic genomes and play significant roles in genome evolution and gene regulation. The correct classification of these repetitive elements is essential to investigate their potential impact on genomes. Despite the existence of several tools for TE classification, they often neglect the importance of simultaneously utilizing global and local information for TE-type identification, resulting in suboptimal performance. Furthermore, these tools are not user-friendly due to the complex installation processes and numerous dependencies. In this study, we introduced a novel framework, CREATE, which leverages the strengths of Convolutional and Recurrent Neural NEtworks, combined with Attention mechanisms, for efficient TE classification. Given the tree-like structure of TE groups, we separately trained nine models within the class hierarchy. Benchmarking experiments showed that CREATE significantly outperformed other TE classification tools. The source code and demo data for CREATE are available at https://github.com/yangqi-cs/CREATE. To facilitate TE annotation for researchers, we have developed a web platform, named WebDLTE, based on the CREATE framework. This platform employs GPU-accelerated pre-trained deep learning models for real-time TE classification and offers the most comprehensive collection of TEs for download. The web interface can be accessed at https://www.webdlte.nwpu.edu.cn."
Deep learning methods in metagenomics: a review,"The ever-decreasing cost of sequencing and the growing potential applications of metagenomics have led to an unprecedented surge in data generation. One of the most prevalent applications of metagenomics is the study of microbial environments, such as the human gut. The gut microbiome plays a crucial role in human health, providing vital information for patient diagnosis and prognosis. However, analyzing metagenomic data remains challenging due to several factors, including reference catalogs, sparsity, and compositionality. Deep learning (DL) enables novel and promising approaches that complement state-of-the-art microbiome pipelines. DL-based methods can address almost all aspects of microbiome analysis, including novel pathogen detection, sequence classification, patient stratification, and disease prediction. Beyond generating predictive models, a key aspect of these methods is also their interpretability. This article reviews deep learning approaches in metagenomics, including convolutional networks (CNNs), autoencoders, and attention-based models. These methods aggregate contextualized data and pave the way for improved patient care and a better understanding of the microbiome’s key role in our health.Author summary In our study, we look at the vast world of research in metagenomics, the study of genetic material from environmental samples, spurred by the increasing affordability of sequencing technologies. Our particular focus is the human gut microbiome, an environment teeming with microscopic life forms that plays a central role in our health and well-being. However, navigating through the vast amounts of data generated is not an easy task. Traditional methods hit roadblocks due to the unique nature of metagenomic data. That’s where deep learning (DL), a today well known branch of artificial intelligence, comes in. DL-based techniques complement existing methods and open up new avenues in microbiome research. They’re capable of tackling a wide range of tasks, from identifying unknown pathogens to predicting disease based on a patient’s unique microbiome. In our article, we provide a very comprehensive review of different DL strategies for metagenomics, including convolutional networks, autoencoders, and attention-based models. We are convinced that these techniques significantly enhance the field of metagenomic analysis in its entirety, paving the way for more accurate data analysis and, ultimately, better patient care. The PRISMA augmented diagram of our review is illustrated in Fig 1."
Deep learning-based synaptic event detection,"ABSTRACTQuantitative information about synaptic transmission is key to our understanding of neural function. Spontaneous synaptic events carry important information about synaptic efficacy and plasticity. However, due to their stochastic nature and low signal-to-noise ratio, reliable and consistent detection of these events in neurophysiological data remains highly challenging. Here, we present miniML, a novel method for the accurate detection of spontaneous synaptic events based on deep learning. Using simulated ground-truth data, we demonstrate that miniML outperforms commonly used methods in terms of precision and recall over different signal-to-noise conditions. The event detection method generalizes easily to diverse synaptic preparations and different types of data. miniML provides a powerful and easy-to-use deep learning framework for automated, standardized and precise analysis of synaptic events in any cell, thus opening new avenues for in-depth investigations into the synaptic basis of neural function and dysfunction."
Interpretable deep learning for deconvolutional analysis of neural signals,"The widespread adoption of deep learning to build models that capture the dynamics of neural populations is typically based on “black-box” approaches that lack an interpretable link between neural activity and function. Here, we propose to apply algorithm unrolling, a method for interpretable deep learning, to design the architecture of sparse deconvolutional neural networks and obtain a direct interpretation of network weights in relation to stimulus-driven single-neuron activity through a generative model. We characterize our method, referred to as deconvolutional unrolled neural learning (DUNL), and show its versatility by applying it to deconvolve single-trial local signals across multiple brain areas and recording modalities. To exemplify use cases of our decomposition method, we uncover multiplexed salience and reward prediction error signals from midbrain dopamine neurons in an unbiased manner, perform simultaneous event detection and characterization in somatosensory thalamus recordings, and characterize the responses of neurons in the piriform cortex. Our work leverages the advances in interpretable deep learning to gain a mechanistic understanding of neural dynamics."
Current limitations in predicting mRNA translation with deep learning models,"Background The design of nucleotide sequences with defined properties is long-standing problem in bioengineering. An important application is protein expression, be it in the context of research or the production of mRNA vaccines. The rate of protein synthesis depends on the 5’ untranslated region (5’UTR) of the mRNAs, and recently, deep learning models were proposed to predict the translation output of mRNAs from the 5’UTR sequence. At the same time, large data sets of endogenous and reporter mRNA translation have become available.Results In this study we use complementary data obtained in two different cell types to assess the accuracy and generality of currently available models of translation. We find that while performing well on the data sets on which they were trained, deep learning models do not generalize well to other data sets, in particular of endogenous mRNAs, which differ in many properties from reporter constructs.Conclusions These differences limit the ability of deep learning models to uncover mechanisms of translation control and to predict the impact of genetic variation. We suggest directions that combine high-throughput measurements and machine learning to unravel mechanisms of translation control and improve construct design."
FLAb: Benchmarking deep learning methods for antibody fitness prediction,"The successful application of machine learning in therapeutic antibody design relies heavily on the ability of models to accurately represent the sequence-structure-function landscape, also known as the fitness landscape. Previous protein bench-marks (including The Critical Assessment of Function Annotation [33], Tasks Assessing Protein Embeddings [23], and FLIP [6]) examine fitness and mutational landscapes across many protein families, but they either exclude antibody data or use very little of it. In light of this, we present the Fitness Landscape for Antibodies (FLAb), the largest therapeutic antibody design benchmark to date. FLAb currently encompasses six properties of therapeutic antibodies: (1) expression, (2) thermosta-bility, (3) immunogenicity, (4) aggregation, (5) polyreactivity, and (6) binding affinity. We use FLAb to assess the performance of various widely adopted, pretrained, deep learning models for proteins (IgLM [28], AntiBERTy [26], ProtGPT2 [11], ProGen2 [21], ProteinMPNN [7], and ESM-IF [13]); and compare them to physics-based Rosetta [1]. Overall, no models are able to correlate with all properties or across multiple datasets of similar properties, indicating that more work is needed in prediction of antibody fitness. Additionally, we elucidate how wild type origin, deep learning architecture, training data composition, parameter size, and evolutionary signal affect performance, and we identify which fitness landscapes are more readily captured by each protein model. To promote an expansion on therapeutic antibody design benchmarking, all FLAb data are freely accessible and open for additional contribution at https://github.com/Graylab/FLAb."
Predicting RNA Sequence-Structure Likelihood via Structure-Aware Deep Learning,"Motivation The active functionalities of RNA are recognized to heavily dependent on the structure and sequence. Therefore, A model that can accurately evaluate a design by giving RNA sequence-structure pairs would be a valuable tool for many researchers. Machine learning methods have been explored to develop such tools, showing promising results. However, two key issues remain. Firstly, the performance of machine learning models is affected by the features used to characterize RNA. Currently, there is no consensus on which features are the most effective for characterizing RNA sequence-structure pairs. Secondly, most existing machine learning methods extract features describing entire RNA molecule. We argue that it is essential to define additional features that characterize nucleotides and specific sections of RNA structure to enhance the overall efficacy of the RNA design process.Results We develop two deep learning models for evaluating RNA sequence-structure pairs. The first model, NU-ResNet, uses a convolutional neural network architecture that solves the aforementioned problems by explicitly encoding RNA sequence-structure information into a 3D matrix. Building upon NU-ResNet, our second deep learning model, NUMO-ResNet, incorporates additional information derived from the characterizations of RNA, specifically the 2D folding motifs. In this work, we introduce an automated method to extract these motifs based on fundamental secondary structure descriptions. To assess the robustness of our models, we conduct 10-fold cross validation. Furthermore, we evaluate the performance of both models on two independent testing datasets. Our proposed models demonstrate excellent performance across both datasets and surpass the performance of the ENTRNA approach.Availability and Implementation The corresponding source code and data for this research is available at https://github.com/yzhou617/NU-ResNet_and_NUMO-ResNet.Contact Giulia.Pedrielli{at}asu.eduSupplementary information Supplementary data are available at Bioinformatics online."
Neural Activity Shaping in Visual Prostheses with Deep Learning,"Objective The visual perception provided by retinal prostheses is poor and limited to images constructed of phosphenes generated by the electrodes. One limiting factor has been the conventional strategy used to encode the target image into a stimulation pattern. Under this strategy, if the electrode density is high, the current spread of neighbouring unipolar stimuli overlaps, leading to blurred images. Simultaneous multipolar stimulation guided by the measured neural responses can attenuate excessive spread of excitation and allows for a more precise electrical input to the retina. However, it is far from trivial to predict what multipolar stimulus pattern will elicit the desired retinal response for a given target image. Here, we propose to solve this problem using an Artificial Neural Network (ANN) that could be trained with data acquired from the implant itself.Approach Our method consists of two ANNs trained sequentially. The Measurement Predictor Network (MPN) is trained on data from the implant and is used to predict how the retina responds to multipolar stimulation by learning the forward model. The Stimulus Generator Network (STG) is trained on a large dataset of natural images and uses the trained MPN to determine efficient multipolar stimulus patterns by learning the inverse model. We validate our method in silico using a realistic model of retinal response to multipolar stimulation.Main Results We show that the simulated retinal activations elicited with our ANN-based approach are considerably sharper when compared with the conventional method used in existing devices. The SGN finds multipolar stimulation patterns that are tuned to a specific retina, thus providing patient-specific stimuli. Also, due to its small computational cost, the SGN can output stimulation patterns at a very high rate.Significance Our novel protocol opens the door to personalized multipolar retinal stimulation, which may improve the visual experience and quality of life of retinal prosthesis users."
Data Imbalance in Drug Response Prediction - Multi-Objective Optimization Approach in Deep Learning Setting,"Drug response prediction (DRP) methods tackle the complex task of associating the effectiveness of small molecules with the specific genetic makeup of the patient. Anti-cancer DRP is a particularly challenging task requiring costly exper-iments as underlying pathogenic mechanisms are broad and associated with multiple genomic pathways. The scientific community has exerted significant efforts to generate public drug screening datasets, giving a path to various machine learning (ML) models that attempt to reason over complex data space of small compounds and biological characteris-tics of tumors. However, the data depth is still lacking compared to computer vision or natural language processing domains, limiting current learning capabilities. To combat this issue and increase the generalizability of the DRP mod-els, we are exploring strategies that explicitly address the imbalance in the DRP datasets. We reframe the problem as a multi-objective optimization across multiple drugs to maximize deep learning model performance. We implement this approach by constructing Multi-Objective Optimization Regularized by Loss Entropy (MOORLE) loss function and plug-ging it into a Deep Learning model. We demonstrate the utility of proposed drug discovery methods and make sugges-tions for further potential application of the work to promote equitable outcomes in the healthcare field.
Availability: https://github.com/AlexandrNP/MOORLE
Contact: onarykov@anl.gov"
H3-OPT: Accurate prediction of CDR-H3 loop structures of antibodies with deep learning,"Accurate prediction of the structurally diverse complementarity determining region heavy chain 3 (CDR-H3) loop structure remains a primary and long-standing challenge for antibody modeling. Here, we present the H3-OPT toolkit for predicting the 3D structures of monoclonal antibodies and nanobodies. H3-OPT combines the strengths of AlphaFold2 with a pre-trained protein language model, and provides a 2.24 Angstrom average C alpha-RMSD; between predicted and experimentally determined CDR-H3 loops, thus outperforming other current computational methods in our non-redundant high-quality dataset. The model was validated by experimentally solving three structures of anti-VEGF nanobodies predicted by H3-OPT. We examined the potential applications of H3-OPT through analyzing antibody surface properties and antibody-antigen interactions. This structural prediction tool can be used to optimize antibody-antigen binding, and to engineer therapeutic antibodies with biophysical properties for specialized drug administration route."
An unsupervised deep learning framework encodes super-resolved image features to decode bacterial cell cycle,"Super-resolution microscopy can resolve cellular features at the nanoscale. However, increased spatial resolution comes with increased phototoxicity, and reduced temporal resolution. As a result, studies that require the highest spatial resolutions often rely on static or fixed images, lacking dynamic information. This is particularly true of bacteria, whose lateral dimensions approach the scale of the diffraction limit. In this work, we present Enso, a method based on unsupervised machine learning to recover bacterial cell cycle and cell type information from static single-molecule localization microscopy (SMLM) images, whilst retaining nanoscale spatial resolution. Enso uses single-cell images as input, and orders cells according to their spatial pattern progression, ultimately linked to the cell cycle. Our method requires no a priori knowledge or categories, and is validated on both simulated and user-annotated experimental data."
Seq2MAIT: A Novel Deep Learning Framework for Identifying Mucosal Associated Invariant T (MAIT) Cells,"Mucosal-associated invariant T (MAIT) cells are a group of unconventional T cells that mainly recognize bacterial vitamin B metabolites presented on MHC-related protein 1 (MR1). MAIT cells have been shown to play an important role in controlling bacterial infection and in responding to viral infections. Furthermore, MAIT cells have been implicated in different chronic inflammatory diseases such as inflammatory bowel disease and multiple sclerosis. Despite their involvement in different physiological and pathological processes, a deeper understanding of MAIT cells is still lacking. Arguably, this can be attributed to the difficulty of quantifying and measuring MAIT cells in different biological samples which is commonly done using flow cytometry-based methods and single-cell-based RNA sequencing techniques. These methods mostly require fresh samples which are difficult to obtain, especially from tissues, have low to medium throughput, and are costly and labor-intensive. To address these limitations, we developed sequence-to-MAIT (Seq2MAIT) which is a transformer-based deep neural network capable of identifying MAIT cells in bulk TCR-sequencing datasets, enabling the quantification of MAIT cells from any biological materials where human DNA is available. Benchmarking Seq2MAIT across different test datasets showed an average area-under-the-receiver-operator-curve (AU[ROC]) >0.80. In conclusion, Seq2MAIT is a novel, economical, and scalable method for identifying and quantifying MAIT cells in virtually any biological sample."
"CatPred: A comprehensive framework for deep learning in vitro enzyme kinetic parameters kcat, Km and Ki","Quantification of enzymatic activities still heavily relies on experimental assays, which can be expensive and time-consuming. Therefore, methods that enable accurate predictions of enzyme activity can serve as effective digital twins. A few recent studies have shown the possibility of training machine learning (ML) models for predicting the enzyme turnover numbers (kcat) and Michaelis constants (Km) using only features derived from enzyme sequences and substrate chemical topologies by training on in vitro measurements. However, several challenges remain such as lack of standardized training datasets, evaluation of predictive performance on out-of-distribution examples, and model uncertainty quantification. Here, we introduce CatPred, a comprehensive framework for ML prediction of in vitro enzyme kinetics. We explored different learning architectures and feature representations for enzymes including those utilizing pretrained protein language model features and three-dimensional structural features. We systematically evaluate the performance of trained models for predicting kcat, Km, and inhibition constants (Ki) of enzymatic reactions on held-out test sets with a special emphasis on out-of-distribution test samples (corresponding to enzyme sequences dissimilar from those encountered during training). CatPred assumes a probabilistic regression approach offering probability distributions instead of single value predictions. Results on unseen data confirm that accuracy in enzyme parameter predictions made by CatPred positively correlate with lower predicted variances. Incorporating pre-trained language model features are found to be enabling for achieving robust performance on out-of-distribution samples. Test evaluations on both held-out and out-of-distribution test datasets confirm that CatPred performs at least competitively with existing methods while simultaneously offering robust uncertainty quantification. CatPred offers wider scope and larger data coverage (∼23k, 41k, 12k data-points) respectively for kcat, Km and Ki. A web-resource to use the trained models is available at: https://tiny.cc/catpred"
Explainable deep learning on 7500 whole genomes elucidates cancer-specific patterns of chromosomal instability,"Chromosomal instability (CIN) refers to an increased rate of chromosomal changes within cells. It is highly prevalent in cancer cells and leads to abnormalities in chromosome number (aneuploidy) and structure. CIN contributes to genetic diversity within a tumour, which facilitates tumour progression, drug resistance, and metastasis. Here, we present a deep learning method and an exploration of the chromosome copy aberrations (CNAs) resultant from CIN, across 7,500 high-depth, whole genome sequences, representing 13 cancer types. We found that the types of CNAs can act as a highly specific classifier for primary site. Using an explainable AI approach, we revealed both established and novel loci that contributed to cancer type, and focusing on highly significant chromosome loci within cancer types, we demonstrated prognostic relevance. We outline how the developed methodology can provide several applications for researchers, including drug target and biomarker discovery, as well as the identification of cancers of unknown primary site."
Generative interpolation and restoration of images using deep learning for improved 3D tissue mapping,"ABSTRACTThe development of novel imaging platforms has improved our ability to collect and analyze large three-dimensional (3D) biological imaging datasets. Advances in computing have led to an ability to extract complex spatial information from these data, such as the composition, morphology, and interactions of multi-cellular structures, rare events, and integration of multi-modal features combining anatomical, molecular, and transcriptomic (among other) information. Yet, the accuracy of these quantitative results is intrinsically limited by the quality of the input images, which can contain missing or damaged regions, or can be of poor resolution due to mechanical, temporal, or financial constraints. In applications ranging from intact imaging (e.g. light-sheet microscopy and magnetic resonance imaging) to sectioning based platforms (e.g. serial histology and serial section transmission electron microscopy), the quality and resolution of imaging data has become paramount.Here, we address these challenges by leveraging frame interpolation for large image motion (FILM), a generative AI model originally developed for temporal interpolation, for spatial interpolation of a range of 3D image types. Comparative analysis demonstrates the superiority of FILM over traditional linear interpolation to produce functional synthetic images, due to its ability to better preserve biological information including microanatomical features and cell counts, as well as image quality, such as contrast, variance, and luminance. FILM repairs tissue damages in images and reduces stitching artifacts. We show that FILM can decrease imaging time by synthesizing skipped images. We demonstrate the versatility of our method with a wide range of imaging modalities (histology, tissue-clearing/light-sheet microscopy, magnetic resonance imaging, serial section transmission electron microscopy), species (human, mouse), healthy and diseased tissues (pancreas, lung, brain), staining techniques (IHC, H&E), and pixel resolutions (8 nm, 2 µm, 1mm). Overall, we demonstrate the marked potential of generative AI in improving the resolution, throughput, and quality of biological image datasets, enabling improved 3D imaging."
Insights into Cellular Evolution: Temporal Deep Learning Models and Analysis for Cell Image Classification,"I. Understanding the temporal evolution of cells poses a significant challenge in developmental biology. This study embarks on a comparative analysis of various machine-learning techniques to classify sequences of cell colony images, thereby aiming to capture dynamic transitions of cellular states. Utilizing transfer learning with advanced classification networks, we achieved high accuracy in single-timestamp image categorization. We introduce temporal models—LSTM, R-Transformer, and ViViT—to explore the effectiveness of integrating temporal features in classification, comparing their performance against non-temporal models. This research benchmarks various machine learning approaches in understanding cellular dynamics, setting a foundation for future studies to enhance our understanding of cellular developments with computational methods, contributing significantly to biological research advancements."
Improving generalizability for MHC-I binding peptide predictions through geometric deep learning,"The interaction between peptides and major histocompatibility complex (MHC) molecules is pivotal in autoimmunity, pathogen recognition and tumor immunity. Recent advances in cancer immunotherapies demand for more accurate computational prediction of MHC-bound peptides. We address the generalizability challenge of MHC-bound peptide predictions, revealing limitations in current sequence-based approaches. Our structure-based methods leveraging geometric deep learning (GDL) demonstrated promising improvement in generalizability across unseen MHC alleles. Further, we tackle data efficiency by introducing a self-supervised learning approach on structures (3D-SSL). Without being exposed to any binding affinity data, our 3D-SSL outperforms sequence-based methods trained on ∼90 times more datapoints. Finally, we demonstrate the resilience of structure-based GDL methods to biases in binding data on an Hepatitis B virus vaccine immunopeptidomics case study. This proof-of-concept study highlights structure-based methods’ potential to enhance generalizability and data efficiency, with important implications for data-intensive fields like T-cell receptor specificity predictions, paving the way for enhanced comprehension and manipulation of immune responses."
U-FISH: a universal deep learning approach for accurate FISH spot detection across diverse datasets,"In the rapidly advancing landscape of fluorescence in situ hybridization (FISH) technologies, there is a critical need for sophisticated yet adaptable methods for spot detection. This study introduces U-FISH, a deep learning approach that significantly improves accuracy and generalization capabilities. Our method utilizes a U-Net model to transform noisy and ambiguous FISH images into a standardized representation with consistent signal characteristics, facilitating efficient spot detection. For the training and evaluation of the U-FISH model, we have constructed a comprehensive dataset comprising over 4,000 images and more than 1.6 million manually annotated spots, sourced from both experimental and simulated environments. Our benchmarks demonstrate that U-FISH outperforms existing methods for FISH spot detection, offering improved versatility by eliminating the need for laborious manual parameter adjustments. This allows for its application across a broad spectrum of datasets and formats. Furthermore, U-FISH is designed for high scalability and is capable of processing 3D data, supporting the latest generation of file formats for large and complex datasets. To promote community adoption and ensure accessibility, we provide a user-friendly interfaces: Napari plugin, web application and command-line interface. The complete training dataset is made publicly available, laying a solid foundation for future research in this field."
DisDock: A Deep Learning Method for Metal Ion-Protein Redocking,"The structures of metalloproteins are essential for comprehending their functions and interactions. The breakthrough of AlphaFold has made it possible to predict protein structures with experimental accuracy. However, the type of metal ion that a metalloprotein binds and the binding structure are still not readily available, even with the predicted protein structure. In this study, we present DisDock, a physics-driven deep learning method for predicting protein-metal docking. DisDock takes distogram of randomly initialized protein-ligand configuration as input and outputs the distogram of the predicted binding complex. It combines the U-net architecture with self-attention modules to enhance model performance. Taking inspiration from the physical principle that atoms in closer proximity display a stronger mutual attraction, this predictor capitalizes on geometric information to uncover latent characteristics indicative of atom interactions. To train our model, we employ a high-quality metalloprotein dataset sourced from the Mother of All Databases (MOAD). Experimental results demonstrate that our approach outperforms other existing methods in prediction accuracy for various types of metal ions."
Multifaceted Representation of Genes via Deep Learning of Gene Expression Networks,"Accurate predictive modeling of human gene relationships would fundamentally transform our ability to uncover the molecular mechanisms that underpin key biological processes and disease development. Recent studies have employed advanced AI techniques to model the complexities of gene networks using large gene expression datasets1–11. However, the extent and nature of the biological information these models can learn is not fully understood. On the other hand, the potential for improving model performance by using alternative data types, model architectures, and methodologies remains underexplored. Here, we developed GeneRAIN models by training on a large dataset of 410K human bulk RNA-seq samples, rather than single-cell RNA-seq datasets used by most previous studies. We showed that although the models were trained only on gene expression data, they learned a wide range of biological information well beyond expression. We introduced GeneRAIN-vec, a state-of-the-art, multifaceted vectorized representation of genes. Further, we showcased capabilities and broad applicability of our approach by making 62.5M predictions, equating to 4,797 biological attribute predictions for each of the 13,030 long non-coding RNAs. These achievements stem from various methodological innovations, including experimenting with multiple model architectures and a new ‘Binning-By-Gene’ normalization method. Comprehensive evaluation of our models clearly demonstrated that they significantly outperformed current state-of-the-art models3,12. This study improves our understanding of the capabilities of Transformer and self-supervised deep learning when applied to extensive expression data. Our methodological advancements offer crucial insights into refining these techniques, set to significantly advance our understanding and exploration of biology."
Spectroscopic assessment of flavor-related chemical compounds in fresh tea shoots using deep learning,"This study employs a deep-learning method, Y-Net, to estimate 10 tea flavor-related chemical compounds (TFCC), including gallic acid, caffeine and eight catechin isomers, using fresh tea shoot reflectance and transmittance. The unique aspect of Y-Net lies in its utilization of dual inputs, reflectance and transmittance, which are seamlessly integrated within the Y-Net architecture. This architecture harnesses the power of a convolutional neural network-based residual network to fuse tea shoot spectra effectively. This strategic combination enhances the capacity of the model to discern intricate patterns in the optical characteristics of fresh tea shoots, providing a comprehensive framework for TFCC estimation. In this study, we destructively sampled tea shoots from tea farms in Alishan (Ali-Mountain) in Central Taiwan within the elevation range of 879–1552 m a.s.l. Tea shoot reflectance and transmittance data (n = 2032) within the optical region (400–2500 nm) were measured using a portable spectroradiometer and pre-processed using an algorithm; corresponding TFCC were qualified using the high-performance liquid chromatography analysis. To enhance the robustness and performance of Y-Net, we employed data augmentation techniques for model training. We compared the performances of Y-Net and seven other commonly utilized statistical, machine-/deep-learning models (partial least squared regression, Gaussian process, cubist, random forests and three feedforward neural networks) using root-mean-square error (RMSE). Furthermore, we assessed the prediction accuracies of Y-Net and Y-Net using spectra within the visible and near-infrared (VNIR) regions (for higher energy throughput and low-cost instruments) and reflectance only (for airborne and spaceborne remote sensing applications). The results showed that overall Y-Net (mean RMSE ± standard deviation [SD] = 2.51 ± 2.20 mg g−1) outperformed the other statistical, machine- and deep-learning models (≥ 2.59 ± 2.64 mg g−1), demonstrating its superiority in predicting TFCC. In addition, this original Y-Net also yielded slightly lower mean RMSE (± SD) compared with VNIR (2.76 ± 2.41 mg g−1) and reflectance-only (2.68 ± 2.74 mg g−1) Y-Nets using validation data. This study highlights the feasibility of using spectroscopy and Y-Net to assess minor biochemical components in fresh tea shoots and sheds light on the potential of the proposed approach for effective regional monitoring of tea shoot quality."
"DeepPrep: An accelerated, scalable, and robust pipeline for neuroimaging preprocessing empowered by deep learning","Neuroimaging has entered the era of big data. However, the advancement of preprocessing pipelines falls behind the rapid expansion of data volume, causing significant computational challenges. Here, we present DeepPrep, a pipeline empowered by deep learning and workflow manager. Evaluated on over 55,000 scans, DeepPrep demonstrates a 11-fold acceleration, exceptional scalability, and robustness compared to the current state-of-the-art pipeline, providing a promising solution to meet the scalability requirements of neuroimaging."
Improved Peptide Docking with Privileged Knowledge Distillation using Deep Learning,"Protein-peptide interactions play a key role in biological processes. Understanding the interactions that occur within a receptor-peptide complex can help in discovering and altering their biological functions. Various computational methods for modeling the structures of receptor-peptide complexes have been developed. Recently, accurate structure prediction enabled by deep learning methods has significantly advanced the field of structural biology. AlphaFold (AF) is among the top-performing structure prediction methods and has highly accurate structure modeling performance on single-chain targets. Shortly after the release of AlphaFold, AlphaFold-Multimer (AFM) was developed in a similar fashion as AF for prediction of protein complex structures. AFM has achieved competitive performance in modeling protein-peptide interactions compared to previous computational methods; however, still further improvement is needed. Here, we present DistPepFold, which improves protein-peptide complex docking using an AFM-based architecture through a privileged knowledge distillation approach. DistPepFold leverages a teacher model that uses native interaction information during training and transfers its knowledge to a student model through a teacher-student distillation process. We evaluated DistPepFold’s docking performance on two protein-peptide complex datasets and showed that DistPepFold outperforms AFM. Furthermore, we demonstrate that the student model was able to learn from the teacher model to make structural improvements based on AFM predictions."
Deep learning methods to forecasting human embryo development in time-lapse videos,"Background In assisted reproductive technology, evaluating the quality of the embryo is crucial when selecting the most viable embryo for transferring to a woman. Assessment also plays an important role in determining the optimal transfer time, either in the cleavage stage or in the blastocyst stage. Several AI-based tools exist to automate the assessment process. However, none of the existing tools predicts upcoming video frames to assist embryologists in the early assessment of embryos. In this paper, we propose an AI system to forecast the dynamics of embryo morphology over a time period in the future.Methods The AI system is designed to analyze embryo development in the past two hours and predict the morphological changes of the embryo for the next two hours. It utilizes a predictive model incorporating Convolutional LSTM layers, to predict the future video frame by analyzing prior morphological changes within the embryo’s video sequence. The system uses the predictions recursively and forecasts up to 23 hours of embryo development.Results The results demonstrated that the AI system could accurately forecast embryo development at the cleavage stage on day 2 and the blastocyst stage on day 4. The system provided valuable information on the cell division processes on day 2 and the start of the blastocyst stage on day 4. The system focused on specific developmental features effective across both the categories of embryos. The embryos that were transferred to the female, and the embryos that were discarded. However, in the ‘transfer’ category, the forecast had a clearer cell membrane and less distortion as compared to the ‘avoid’ category.Conclusion This study assists in the embryo evaluation process by providing early insights into the quality of the embryo for both the transfer and avoid categories of videos. The embryologists recognize the ability of the forecast to depict the morphological changes of the embryo. Additionally, enhancement in image quality has the potential to make this approach relevant in clinical settings.Author summary The emergence of assisted reproductive technology has significantly improved infertility treatments. It involves fertilization of an egg outside the body, and the resultant embryos are developed in time-lapse incubators. The embryologists manually evaluate embryos using time-lapse videos and rank each embryo on the basis of several criteria including the dynamics of embryo cell stages, such as the start of the blastocyst stage. Traditional manual analysis is subjective and time-consuming, and AI tools are introduced to automate and enhance embryo selection efficiency. However, current AI tools do not generate video frames that forecast changes in embryo morphology. This study fills this gap by introducing an AI system that forecasts upcoming frames of a time-lapse video. In this approach, several hours were predicted ahead of the last video frame. The system was evaluated on crucial days of embryo evaluation. Our approach was effective in both good quality (transfer) and poor quality (avoid) video categories, and the forecast revealed crucial insights about embryo cell division and the start of the blastocyst stage. Despite some image quality issues, the proposed AI system demonstrated the potential for early and accurate assessment of embryo quality."
Transformer-Based Deep Learning Model with Latent Space Regularization for CRISPR-Cas Protein Sequence Classification,"The discovery of the CRISPR-Cas system has significantly advanced genome editing, offering vast applications in medical treatments and life sciences research. Despite their immense potential, the existing CRISPR-Cas proteins still face challenges concerning size, delivery efficiency, and cleavage specificity. Addressing these challenges necessitates a deeper understanding of CRISPR-Cas proteins to enhance the design and discovery of novel Cas proteins for precision gene editing. In this study, we performed extensive deep-learning research on CRISPR-Cas proteins, aiming to develop a classification model capable of distinguishing CAS from non-CAS proteins, as well as discriminating sub-categories of CAS proteins, specifically CAS9 and CAS12. We developed two types of deep learning models: 1) a transformer encoder-based classification model, trained from scratch; and 2) a large protein language model fine-tuned on ProtBert, pre-trained on more than 200 million proteins. To boost learning efficiency for the model trained from scratch, we introduced a novel margin-based loss function to maximize inter-class separability and intra-class compactness in protein sequence embedding latent space of a transformer encoder. The experimental results show that the Fine-Tuned ProtBert-based (FTPB) classification model achieved accuracies of 99.06%, 94.42%, 96.80%, 97.57% for CAS9 vs. Non-CAS, CAS12 vs. Non-CAS, CAS9 vs. CAS12, and multi-class classification of CAS9 vs. CAS12 vs. Non-CAS, respectively. The Latent Space Regularized Max-Margin Transformer (LSRMT) model achieved classification accuracies of 99.81%, 99.81%, 99.06%, 99.27% for the same tasks, respectively. These results demonstrate the effectiveness of the proposed Max-Margin-based latent space regularization in enhancing model robustness and generalization capabilities. Remarkably, the LSRMT model, even when trained on a significantly smaller dataset, outperformed the fine-tuned state-of-the-art large protein model. The high classification accuracies achieved by the LSRMT model demonstrate its proficiency in identifying discriminative features of CAS proteins, marking a significant step towards advancing our understanding of CAS protein structures in future research endeavors."
High-Throughput Phenotyping of Seed Quality Traits Using Imaging and Deep Learning in Dry Pea,"Seed traits, such as seed color and seed size, directly impact seed quality, affecting the marketability and value of dry peas [1]. Assessing seed quality is integral to a plant breeding programs to ensure optimal seed standards. This research introduced a phenotyping tool to assess seed quality traits specifically tailored for pulse crops, which integrates image processing with cutting-edge deep learning models. The proposed method is designed for automation, seamlessly processing a sequence of images while minimizing human intervention. The pipeline standardized red-green-blue (RGB) images captured from a color light box and used deep learning models to segment and detect seed features. Our method extracted up to 86 distinct seed characteristics, ranging from basic size metrics to intricate texture details and color nuances. Compared to traditional methods, our pipeline demonstrated a 95 percent similarity in seed quality assessment and increased time efficiency (from 2 weeks to 30 minutes for processing time). Specifically, we observed an improvement in the accuracy of seed trait identification by simply using an RGB value instead of a categorical, non-standard description, which allowed for an increase in the range of detectable seed quality characteristics. By integrating conventional image processing techniques with foundational deep learning models, this approach emerges as a pivotal instrument in pulse breeding programs, guaranteeing the maintenance of superior seed quality standards."
Deep5hmC: Predicting genome-wide 5-Hydroxymethylcytosine landscape via a multimodal deep learning model,"5-hydroxymethylcytosine (5hmC), a critical epigenetic mark with a significant role in regulating tissue-specific gene expression, is essential for understanding the dynamic functions of the human genome. Using tissue-specific 5hmC sequencing data, we introduce Deep5hmC, a multimodal deep learning framework that integrates both the DNA sequence and the histone modification information to predict genome-wide 5hmC modification. The multimodal design of Deep5hmC demonstrates remarkable improvement in predicting both qualitative and quantitative 5hmC modification compared to unimodal versions of Deep5hmC and state-of-the-art machine learning methods. This improvement is demonstrated through benchmarking on a comprehensive set of 5hmC sequencing data collected at four time points during forebrain organoid development and across 17 human tissues. Notably, Deep5hmC showcases its practical utility by accurately predicting gene expression and identifying differentially hydroxymethylated regions in a case-control study of Alzheimer’s disease."
Effects of input image size on the accuracy of fish identification using deep learning,"The length composition of catches by species is important for stock assessment. However, length measurement is performed manually, jeopardizing the future of continuous measurement because of likely labor shortages. We focused on applying deep learning to estimate length composition by species from images of fish caught for sustainable management. In this study, input image sizes were varied to evaluate the effect of input image size on detection and classification accuracy, as a method for improving the accuracy. The images (43,226 fish of 85 classes) were captured on conveyor belts to sort set-net catches. Fish detection and classification were performed using Mask R-CNN. The effect of input image size on accuracy was examined using three image sizes of 1333×888, 2000×1333, and 2666×1777 pixels, achieving an mAP50-95 of 0.580 or higher. The accuracy improved with increasing image size, attaining a maximum improvement of 4.3% compared to the smallest size. However, increasing the image size too far from the default size may not improve the accuracy of models with fine-tuning. Improvements in accuracy were primarily observed for the species with low accuracy at the smallest image size. Increasing image size would be a useful and simple way to improve accuracy for these species."
DeepSP: Deep Learning-Based Spatial Properties to Predict Monoclonal Antibody Stability,"Therapeutic antibody development, manufacturing, and administration face challenges due to high viscosities and aggregation tendencies often observed in highly concentrated antibody solutions. This poses a particular problem for subcutaneous administration, which requires low-volume and high-concentration formulations. The spatial charge map (SCM (mAbs, 8 (1) (2015), pp. 43-48)) and spatial aggregation propensity (SAP (PNAS. 2009; 106:11937–42) are two computational techniques proposed from previous studies to aid in predicting viscosity and aggregation, respectively. These methods rely on structural data derived from molecular dynamics (MD) simulations, which are known to be time-consuming and computationally demanding. DeepSCM (CSBJ. 2022, 20:2143-2152), a deep learning surrogate model to predict SCM scores in the entire variable region, was used to screen high-concentration antibody viscosity. DeepSCM is solely based on sequence information, which facilitates high throughput screening. This study further utilized a dataset of 20,530 antibody sequences to train a convolutional neural network deep learning surrogate model called Deep Spatial Properties (DeepSP). DeepSP directly predicts SAP and SCM scores in different domains of antibody variable regions based solely on their sequences without performing MD simulations. The linear correlation coefficient (R) between DeepSP scores and MD-derived scores for 30 properties achieved values between 0.76 and 0.96 with an average of 0.87 on the test set (N=2053). DeepSP was employed as features to build machine learning models to predict the aggregation rate of 21 antibodies. We observed remarkable results with R = 0.97 and a mean squared error (MSE) of 0.03 between the experimental and predicted aggregation rates, leave-one-out cross-validation (LOOCV) yielded R = 0.75 and MSE = 0.18, which is similar to the results obtained from the previous study using MD simulations. This result demonstrates that the DeepSP approach significantly reduces the computational time required compared to MD simulations. The DeepSP model enables the rapid generation of 30 structural properties that can also be used as features in other research to train machine learning models for predicting various antibody properties, such as viscosity, aggregation, or other properties that can influence their stability, using sequences only. The code and parameters are freely available at https://github.com/Lailabcode/DeepSPHighlightsDeep learning applied to develop a surrogate model (DeepSP) to rapidly predict 30 spatial properties of monoclonal antibodies that are usually calculated from MD simulations, using only sequences.The DeepSP models achieved a linear correlation ranging between 0.76 and 0.96 with an average of 0.87, between the actual (MD simulation) and predicted score for all properties.DeepSP features were employed to build a model to predict aggregation rates of antibodies obtained from a previous study. A strong correlation of 0.97, and LOOCV correlation of 0.75 were achieved between the actual and predicted aggregation rates.DeepSP can be employed to generate antibody-specific features that can be used to train different machine learning models to predict antibody stability."
Genotypic-phenotypic landscape computation based on first principle and deep learning,"The relationship between genotype and fitness is fundamental to evolution, but quantitatively mapping genotypes to fitness has remained challenging. We propose the Phenotypic-Embedding theorem (P-E theorem) that bridges genotype-phenotype through an encoder-decoder deep learning framework. Inspired by this, we proposed a more general first principle for correlating genotype-phenotype, and the Phenotypic-Embedding theorem provides a computable basis for the application of first principle. As an application example of the P-E theorem, we developed the Co-attention based Transformer model to bridge Genotype and Fitness (CoT2G-F) model, a Transformer-based pre-train foundation model with downstream supervised fine-tuning (SFT) that can accurately simulate the neutral evolution of viruses and predict immune escape mutations. Accordingly, following the calculation path of the P-E theorem, we accurately obtained the basic reproduction number (R0) of SARS-CoV-2 from first principles, quantitatively linked immune escape to viral fitness, and plotted the genotype-fitness landscape. The theoretical system we established provides a general and interpretable method to construct genotype-phenotype landscapes, providing a new paradigm for studying theoretical and computational biology."
Deep learning modeling of ribosome profiling reveals regulatory underpinnings of translatome and interprets disease variants,"Gene expression involves transcription and translation. Despite large datasets and increasingly powerful methods devoted to calculating genetic variants’ effects on transcription, discrepancy between mRNA and protein levels hinders the systematic interpretation of the regulatory effects of disease-associated variants. Accurate models of the sequence determinants of translation are needed to close this gap and to interpret disease-associated variants that act on translation. Here, we present Translatomer, a multimodal transformer framework that predicts cell-type-specific translation from mRNA expression and gene sequence. We train Translatomer on 33 tissues and cell lines, and show that the inclusion of sequence substantially improves the prediction of ribosome profiling signal, indicating that Translatomer captures sequence-dependent translational regulatory information. Translatomer achieves accuracies of 0.72 to 0.80 for de novo prediction of cell-type-specific ribosome profiling. We develop an in silico mutagenesis tool to estimate mutational effects on translation and demonstrate that variants associated with translation regulation are evolutionarily constrained, both within the human population and across species. Notably, we identify cell-type-specific translational regulatory mechanisms independent of eQTLs for 3,041 non-coding and synonymous variants associated with complex diseases, including Alzheimer’s disease, schizophrenia, and congenital heart disease. Translatomer accurately models the genetic underpinnings of translation, bridging the gap between mRNA and protein levels, and providing valuable mechanistic insights toward mapping “missing regulation” in disease genetics."
MarmoPose: A Deep Learning-Based System for Real-time Multi-Marmoset 3D Pose Tracking,"The common marmoset has become an important experimental animal model in scientific research. The ability to capture and quantify behaviors of marmosets in natural environment and social scenarios is highly desired by marmoset research community. Although existing pose tracking methods have enabled multi-marmoset two-dimensional (2D) tracking and single-marmoset three-dimensional (3D) pose estimation, they have not fully addressed the practical demands of marmoset research. Here, we introduce MarmoPose, a real-time 3D pose tracking system based on deep learning for automatically estimating 3D poses of multiple marmosets freely roaming in their homecage. MarmoPose employs a marmoset skeleton model to optimize 3D pose computation and estimate invisible body locations. Furthermore, MarmoPose provides a real-time processing module to enable short-latency closed-loop experimental control based on the 3D poses of marmosets. The objective of our effort is to design an efficient, cost-effective and user-friendly system that can be easily adapted by marmoset researchers to quantify natural behaviors in typical housing environment."
DeepSipred: A deep-learning-based approach on siRNA inhibition prediction,"Motivation The use of exogenous small interfering RNAs (siRNAs) for gene silencing has become a widespread molecular tool for gene function study and new drug identification. Although the pathway of RNAi to mediate gene expression has been widely investigated, the selection of hyperfunctional siRNA with high inhibition remains challenging.Results In this study, we build a deep-learning-based approach on siRNA inhibition prediction, named DeepSipred. It combines features from sequence context, thermodynamic property, and other expert knowledge together to predict the inhibition more accurately than existing methods. The sequence features from siRNA and local target mRNA are generated via one-hot encoding and pretrained RNA-FM encoding. The convolution layers with multiple kernels in DeepSipred can detect various decisive motifs, which will determine the actual inhibition of siRNA. The thermodynamic features are calculated from Gibbs Free Energy. In addition, the expert knowledge includes those design criteria from previous studies. Benchmarked on large available public datasets, the 10-fold cross-validation results indicate that our predictor achieving the state-of-the-art performance.Contact yuanye_auto{at}sjtu.edu.cn or chengjin520{at}sjtu.edu.cn."
Deep Learning Model Imputes Missing Stains in Multiplex Images,"Multiplex staining enables simultaneous detection of multiple protein markers within a tissue sample. However, the increased marker count increased the likelihood of staining and imaging failure, leading to higher resource usage in multiplex staining and imaging. We address this by proposing a deep learning-based MArker imputation model for multipleX IMages (MAXIM) that accurately impute protein markers by leveraging latent biological relationships between markers. The model’s imputation ability is extensively evaluated at pixel and cell levels across various cancer types. Additionally, we present a comparison between imputed and actual marker images within the context of a downstream cell classification task. The MAXIM model’s interpretability is enhanced by gaining insights into the contribution of individual markers in the imputation process. In practice, MAXIM can reduce the cost and time of multiplex staining and image acquisition by accurately imputing protein markers affected by staining issues."
A Framework for Designing Efficient Deep Learning-Based Genomic Basecallers,"Nanopore sequencing generates noisy electrical signals that need to be converted into a standard string of DNA nucleotide bases using a computational step called basecalling. The performance of basecalling has critical implications for all later steps in genome analysis. Therefore, there is a need to reduce the computation and memory cost of basecalling while maintaining accuracy. We present RUBICON, a framework to develop efficient hardware-optimized basecallers. We demonstrate the effectiveness of RUBICON by developing RUBICALL, the first hardware-optimized mixed-precision basecaller that performs efficient basecalling, outperforming the state-of-the-art basecallers. We believe RUBICON offers a promising path to develop future hardware-optimized basecallers."
Exploring the repository of de novo designed bifunctional antimicrobial peptides through deep learning,"Antimicrobial peptides (AMPs) are attractive candidates to combat antibiotic resistance for their capability to target bio-membranes and restrict a wide range of pathogens. It is a daunting challenge to discover novel AMPs due to their sparse distributions in a vast peptide universe, especially for peptides that demonstrate potencies for both bacterial membranes and viral envelopes. Here we establish a de novo AMP design framework by bridging a deep generative module and a graph-encoding activity regressor. The generative module learns hidden ‘grammars’ of AMP features and produces candidates sequentially pass antimicrobial predictor and antiviral classifiers. We discover three bifunctional AMPs and experimentally validated their abilities to inhibit a spectrum of pathogens in vitro and in animal models. Notably, P076 is a highly potent bactericide with the minimal inhibitory concentration of 0.21 μM against multidrug-resistant A. baumannii, while P002 broadly inhibits five enveloped viruses. Our study provides feasible means to uncover sequences that simultaneously encode antimicrobial and antiviral activities, thus bolstering the function spectra of AMPs to combat a wide range of drug-resistant infections."
Deep Learning Behavioral Phenotyping System in the Diagnosis of Parkinson’s Disease with Drosophila melanogaster,"Drosophila Melanogaster is widely used as animal models for Parkinson’s disease (PD) research. Because of the complexity of MoCap and quantitative assessment among Drosophila Melanogaster, however, there is a technical issue that identify PD symptoms within drosophila based on objective spontaneous behavioral characteristics. Here, we developed a deep learning framework generated from kinematic features of body posture and motion between wildtype and SNCAE46K mutant drosophila genetically modeled □-Syn, supporting clustering and classification of PD individuals. We record locomotor activity in a 3D-printed trap, and utilize the pre-analysis pose estimation software DeepLabCut (DLC) to calculate and generate numerical data representing the motion speed, tremor frequency, and limb motion of Drosophila Melanogaster. By plugging these data as the input, the diagnosis result (1/0) representing PD or WT as the output. Our result provides a toolbox which would be valuable in the investigation of PD progressing and pharmacotherapeutic drug development."
"DL4MicEverywhere: Deep learning for microscopy made flexible, shareable, and reproducible","Deep learning has revolutionised the analysis of extensive microscopy datasets, yet challenges persist in the widespread adoption of these techniques. Many lack access to training data, computing resources, and expertise to develop complex models. We introduce DL4MicEverywhere, advancing our previous ZeroCostDL4Mic platform, to make deep learning more accessible. DL4MicEverywhere uniquely allows flexible training and deployment across diverse computational environments by encapsulating methods in interactive Jupyter notebooks within Docker containers –a standalone virtualisation of required packages and code to reproduce a computational environment–. This enhances reproducibility and convenience. The platform includes twice as many techniques as originally provided by ZeroCostDL4Mic and enables community contributions via automated build pipelines. DL4MicEverywhere empowers participatory innovation and aims to democratise deep learning for bioimage analysis."
Deep learning insights into the architecture of the mammalian egg-sperm fusion synapse,"A crucial event in sexual reproduction is when haploid sperm and egg fuse to form a new diploid organism at fertilization. In mammals, direct interaction between egg JUNO and sperm IZUMO1 mediates gamete membrane adhesion, yet their role in fusion remains enigmatic. We used AlphaFold to predict the structure of other extracellular proteins essential for fertilization to determine if they could form a complex that may mediate fusion. We first identified TMEM81, whose gene is expressed by mouse and human spermatids, as a protein having structural homologies with both IZUMO1 and another sperm molecule essential for gamete fusion, SPACA6. Using a set of proteins known to be important for fertilization and TMEM81, we then systematically searched for predicted binary interactions using an unguided approach and identified a pentameric complex involving sperm IZUMO1, SPACA6, TMEM81 and egg JUNO, CD9. This complex is structurally consistent with both the expected topology on opposing gamete membranes and the location of predicted N-glycans not modeled by AlphaFold-Multimer, suggesting that its components could organize into a synapse-like assembly at the point of fusion. Finally, the structural modeling approach described here could be more generally useful to gain insights into transient protein complexes difficult to detect experimentally.Impact statement Structural modeling with AlphaFold-Multimer was used to investigate extracellular protein interactions involved in mammalian egg-sperm recognition, suggesting a putative pentameric complex that includes TMEM81, a sperm protein not previously involved in gamete recognition."
NeuroMDAVIS: Visualization of single-cell multi-omics data under deep learning framework,"Single-cell technologies have favoured extensive advancements in cell-type discovery, cell state identi-fication, development of lineage tracing and disease understanding among others. Further, single-cell multi-omics data generated using modern technologies provide several views of omics contribution for the same set of cells. However, dimension reduction and visualization of biological datasets (single or multi-omics) remain a challenging task since obtaining a low-dimensional embedding that preserves information about local and global structures in data, is difficult. Further, combining different views obtained from each omics layer to interpret the underlying biology is even more challenging. Earlier, we have developed NeuroDAVIS which can perform the task of visualization of high-dimensional datasets of a single modality while preserving cluster-structures within the data. Nevertheless, there is no model so far that supports joint visualization of multi-omics datasets. Joint visualization refers to transforming the feature space of each individual modality and combining them to produce a latent embedding that supports visualization of the multi-modal dataset in the newly transformed feature space. In this work, we introduce NeuroMDAVIS which is a generalized version of NeuroDAVIS for visualization of biological datasets having multiple modalities. To the best of our knowledge, NeuroMDAVIS is the first of its kind multi-modal data visualization model. It is able to learn both local and global relationships in the data while generating a low-dimensional embedding useful for downstream tasks. NeuroMDAVIS competes against state-of-the-art visualization models like t-Distributed Stochastic Neighbor Embedding (t-SNE), Uniform Manifold Approximation and Projection (UMAP), Fast interpolation-based t-SNE (Fit-SNE), and the Siamese network-based visualization method (IVIS)."
Revealing 3D cancer tissue structures using holotomography and virtual hematoxylin and eosin staining via deep learning,"In standard histopathology, hematoxylin and eosin (H&E) staining stands as a pivotal tool for cancer tissue analysis. However, this method is limited to two-dimensional (2D) analysis or requires labor-intensive preparation for three-dimensional (3D) inspection of cancer tissues. In this study, we present a method for 3D virtual H&E staining of label-free cancer tissues, employing holotomography and deep learning. Holotomography is used to measure the 3D refractive index (RI) distribution of the label-free cancer slides. A deep learning-based image-to-image translation framework is integrated into the resulting 3D RI distribution, enabling virtual H&E staining in 3D. Our method has been applied to colon cancer tissue slides with thicknesses up to 20 μm, with conventional chemical H&E staining providing a direct validation for the method. This framework not only bypasses the conventional staining process but also provides 3D structures of glands, lumens, and individual nuclei. The results demonstrate enhancement in histopathological efficiency and the extension of the standard histopathology into the 3D realm. To validate the repeatability and scalability of the approach, we applied the framework to the gastric cancer slides obtained from different institute and imaging devices."
Evaluation and optimization of sequence-based gene regulatory deep learning models,"Neural networks have emerged as immensely powerful tools in predicting functional genomic regions, notably evidenced by recent successes in deciphering gene regulatory logic. However, a systematic evaluation of how model architectures and training strategies impact genomics model performance is lacking. To address this gap, we held a DREAM Challenge where competitors trained models on a dataset of millions of random promoter DNA sequences and corresponding expression levels, experimentally determined in yeast, to best capture the relationship between regulatory DNA and gene expression. For a robust evaluation of the models, we designed a comprehensive suite of benchmarks encompassing various sequence types. While some benchmarks produced similar results across the top-performing models, others differed substantially. All top-performing models used neural networks, but diverged in architectures and novel training strategies, tailored to genomics sequence data. To dissect how architectural and training choices impact performance, we developed the Prix Fixe framework to divide any given model into logically equivalent building blocks. We tested all possible combinations for the top three models and observed performance improvements for each. The DREAM Challenge models not only achieved state-of-the-art results on our comprehensive yeast dataset but also consistently surpassed existing benchmarks on Drosophila and human genomic datasets. Overall, we demonstrate that high-quality gold-standard genomics datasets can drive significant progress in model development."
A Multimodal Deep Learning Framework for Predicting PPI-Modulator Interactions,"ABSTRACTProtein-protein interactions (PPIs) are essential for various biological processes and diseases. However, most existing computational methods for identifying PPI modulators require either target structure or reference modulators, which restricts their applicability to novel PPI targets. To address this challenge, we propose MultiPPIMI, a sequence-based deep learning framework that predicts the interaction between any given PPI target and modulator. MultiPPIMI integrates multimodal representations of PPI targets and modulators, and uses a bilinear attention network to capture inter-molecular interactions. Experimental results on our curated benchmark dataset show that MultiPPIMI achieves an average AUROC of 0.837 in three cold-start scenarios, and an AUROC of 0.994 in the random-split scenario. Furthermore, the case study show that MultiPPIMI can assist molecular simulations in screening inhibitors of Keap1/Nrf2 PPI interactions. We believe that the proposed method provides a promising way to screen PPI-targeted modulators."
Virtual tissue microstructure reconstruction across species using generative deep learning,"Analyzing tissue microstructure is essential for understanding complex biological systems in different species. Tissue functions largely depend on their intrinsic tissue architecture. Therefore, studying the three-dimensional (3D) microstructure of tissues, such as the liver, is particularly fascinating due to its conserved essential roles in metabolic processes and detoxification. Here, we present TiMiGNet, a novel deep learning approach for virtual 3D tissue microstructure reconstruction using Generative Adversarial Networks (GANs) and fluorescence microscopy. TiMiGNet overcomes challenges such as poor antibody penetration and time-intensive procedures by generating accurate, high-resolution predictions of tissue components across large volumes without the need of paired images as input. We applied TiMiGNet to analyze tissue microstructure in mouse and human liver tissue. TiMiGNet shows high performance in predicting structures like bile canaliculi, sinusoids, and Kupffer cell shapes from actin meshwork images. Remarkably, using TiMiGNet we were able to computationally reconstruct tissue structures that cannot be directly imaged due experimental limitations in deep dense tissues, a significant advancement in deep tissue imaging. Our open-source virtual prediction tool facilitates accessible and efficient multi-species tissue microstructure analysis, accommodating researchers with varying expertise levels. TiMiGNet’s simplicity and independence from paired images make it a versatile asset. Overall, our method represents a powerful and efficient approach for studying tissue microstructure, with far-reaching applications in diverse biological contexts and species."
"DEEP LEARNING APPROACH FOR RENAL CELL CARCINOMA DETECTION, SUBTYPING, AND GRADING","We propose a comprehensive end-to-end pipeline designed for the detection, subtyping, and grading of tumors. Our proposed method-ology initiates the generation of a heat map, indicating the severity of the tumor. Subsequently, the identification of the most critical patches is conducted based on the probability scores. These identified patches are then directed to a grade prediction network. A distinctive aspect of our research lies in being the first to explore an end-to-end pipeline for both heat map generation and grading prediction. Our experiments were conducted leveraging the public, The Cancer Genome Atlas (TCGA) repository, focusing specifically on renal cancer. We introduced additional patch-level labels to improve the model performance. The generation of tumor heat maps targeted three primary cancer subtypes: clear cell, papillary, and chromophobe. To enhance our approach, we implemented center-loss and introduced a method aimed at refining the quality of patches. The experimental outcomes highlight superior performance compared to state-of-the-art method. This research contributes to the advancement of tumor detection and grading, emphasizing the significance of an integrated approach for heat map generation and grading pre-diction."
Identifying Reproducibly Important EEG Markers of Schizophrenia with an Explainable Multi-Model Deep Learning Approach,"The diagnosis of schizophrenia (SZ) can be challenging due to its diverse symptom presentation. As such, many studies have sought to identify diagnostic biomarkers of SZ using explainable machine learning methods. However, the generalizability of identified biomarkers in many machine learning-based studies is highly questionable given that most studies only analyze explanations from a small number of models. In this study, we present (1) a novel feature interaction-based explainability approach and (2) several new approaches for summarizing multi-model explanations. We implement our approach within the context of electroencephalogram (EEG) spectral power data. We further analyze both training and test set explanations with the goal of extracting generalizable insights from the models. Importantly, our analyses identify effects of SZ upon the α, β, and θ frequency bands, the left hemisphere of the brain, and interhemispheric interactions across a majority of folds. We hope that our analysis will provide helpful insights into SZ and inspire the development of robust approaches for identifying neuropsychiatric disorder biomarkers from explainable machine learning models."
Antivirals for Monkeypox Virus: Proposing an Effective Machine/Deep Learning Framework,"Monkeypox is one of the infectious viruses which caused morbidity and mortality problems in these years. Despite its danger to public health, there is no approved drug to stand and handle Monkeypox. On the other hand, drug repurposing is a promising screening method for the low-cost introduction of approved drugs for emerging diseases and viruses which utilizes computational methods. Therefore, drug repurposing is a promising approach to suggesting approved drugs for the monkeypox virus. This paper proposes a computational framework for monkeypox antiviral prediction. To do this, we have geenrated a new virus-antiviral dataset. Moreover, we applied several machine learning and one deep learning method for virus-antiviral prediction. The suggested drugs by the learning methods have been investigated using docking studies. To the best of our knowledge, this work is the first work to study deep learning methods for the prediction of monkeypox antivirals. The screening results confirm that Tilorone, Valacyclovir, Ribavirin, Favipiravir, and Baloxavir marboxil are effective drugs for monkeypox treatment."
RNAformer: A Simple Yet Effective Deep Learning Model for RNA Secondary Structure Prediction,"Traditional RNA secondary structure prediction methods, based on dynamic programming, often fall short in accuracy. Recent advances in deep learning have aimed to address this, but may not adequately learn the biophysical model of RNA folding. Many deep learning approaches are also too complex, incorporating multi-model systems, ensemble strategies, or requiring external data like multiple sequence alignments. In this study, we demonstrate that a single deep learning model, relying solely on RNA sequence input, can effectively learn a biophysical model and outperform existing deep learning methods in standard benchmarks, as well as achieve comparable results to methods that utilize multi-sequence alignments. We dub this model RNAformer and achieve these benefits by a two-dimensional latent space, axial attention, and recycling in the latent space. Further, we found that our model performance improves when we scale it up. We also demonstrate how to refine a pre-trained RNAformer with fine-tuning techniques, which are particularly efficient when applied to a limited amount of high-quality data. A further aspect of our work is addressing the challenges in dataset curation in deep learning, especially regarding data homology. We tackle this through an advanced data processing pipeline that allows for training and evaluation of our model across various levels of sequence similarity. Our models and datasets are openly accessible, offering a simplified yet effective tool for RNA secondary structure prediction."
Deep learning-based Spatial Feature Extraction for Prognostic Prediction of Hepatocellular Carcinoma from Pathological Images,"The spatial structures of various cell types in tumor tissues have been demonstrated to be able to provide useful information for the evaluation of the disease progression as well as the responsiveness to targeted therapies. Therefore, powered by machine-learning, several image segmentation methods have been developed to identify tumor-cells, stromal, lymphocytes, etc., in hematoxylin and eosin (H&E) stained pathological images. However, the quantitative and systematic characterization of the spatial structures of various cell types is still challenging. In this work, we first developed a robust procedure based on deep learning to precisely recognize cancer cells, stromal and lymphocytes in H&E-stained pathological images of hepatocellular carcinoma (HCC). In order to quantitatively characterize the composition and spatial arrangement of the tumor microenvironment, we then systematically constructed 109 spatial features based on locations of the 3 major types of cells in the H&E images. Interestingly, we discovered that the absolute values of several spatial features are significantly associated with patient overall survival in two independent patient cohorts, such as the cellular diversity around stromal cells (StrDiv), the average distance between stromal cells (StrDis), the coefficient of variation of the tumor-cell polygon area in the Voronoi diagram (TumCV), etc., based on univariate analysis. In addition, multivariate Cox regress analyses further demonstrated that StrDiv and StrDis are independent survival prognostic factors for HCC patient from The Cancer Genome Atlas Program (TCGA). Furthermore, we demonstrated that a combination analysis with cell spatial features, i.e. StrDiv or TumCV, and another important clinical feature, i.e. microvascular invasion (MVI), can further improve the efficacy of prognostic stratification for patients from the Beijing Hospital cohorts. In summary, the spatial features of tumor microenvironment enabled by the digital image analysis pipeline developed in this work can be effective in patient stratification, which holds the promise for its usage in predicting the therapeutic response of patients in the future."
scGrapHiC : Deep learning-based graph deconvolution for Hi-C using single cell gene expression,"Single-cell Hi-C (scHi-C) protocol helps identify cell-type-specific chromatin interactions and sheds light on cell differentiation and disease progression. Despite providing crucial insights, scHi-C data is often underutilized due the high cost and the complexity of the experimental protocol. We present a deep learning framework, scGrapHiC, that predicts pseudo-bulk scHi-C contact maps using pseudo-bulk scRNA-seq data. Specifically, scGrapHiC performs graph deconvolution to extract genome-wide single-cell interactions from a bulk Hi-C contact map using scRNA-seq as a guiding signal. Our evaluations show that scGrapHiC, trained on 7 cell-type co-assay datasets, outperforms typical sequence encoder approaches. For example, scGrapHiC achieves a substantial improvement of 23.2% in recovering cell-type-specific Topologically Associating Domains over the baselines. It also generalizes to unseen embryo and brain tissue samples. scGrapHiC is a novel method to generate cell-type-specific scHi-C contact maps using widely available genomic signals that enables the study of cell-type-specific chromatin interactions.Availability https://github.com/rsinghlab/scGrapHiCContact ritambhara{at}brown.edu"
Deep learning-based proteomics enables accurate classification of bulk and single-cell samples,"Proteins are the main drivers of cell function and disease, making their analysis a powerful technique to characterize determinants of cell identity and to identify biomarkers. Current proteomic technology has the breadth to profile thousands of proteins and even the sensitivity to access single cells, however limitations in throughput restrict its application, e.g. not allowing classification of samples according to biological or clinical status in large sample cohorts. Therefore, we developed a deep learning-based approach for the analysis of mass spectrometric (MS) data, assigning proteomic profiles to sample identity. Specifically, we designed an architecture referred to as Proformer, and show that it is superior to convolutional neural network-driven architectures, is explainable, and demonstrates robustness towards batch-effects. Based on its tabular approach, we highlight the integration of all four dimensions of proteomic measurements (retention time, mass-to-charge, intensity and ion mobility), and demonstrate enhanced sample discrimination involving a treatment with IFN-γ, despite its subtle effect on the cell’s proteome. In addition, the Proformer is not restricted to proteomic depth, and can classify cells by cell type and their differentiation status even using single-cell proteomic data. Collectively, this work presents a novel deep learning-based model for rapid classification of proteomic data, with important future implications to enhance patient stratification, early detection and single-cell analysis."
Systematic benchmarking of deep-learning methods for tertiary RNA structure prediction,"The 3D structure of RNA critically influences its functionality, and understanding this structure is vital for deciphering RNA biology. Experimental methods for determining RNA structures are labour-intensive, expensive, and time-consuming. Computational approaches have emerged as valuable tools, leveraging physics-based-principles and machine learning to predict RNA structures rapidly. Despite advancements, the accuracy of computational methods remains modest, especially when compared to protein structure prediction. Deep learning methods, while successful in protein structure prediction, have shown some promise for RNA structure prediction as well but face unique challenges. This study systematically benchmarks state-of-the-art deep learning methods for RNA structure prediction across diverse datasets. Our aim is to identify factors influencing performance variation, such as RNA family diversity, sequence length, RNA type, multiple sequence alignment (MSA) quality, and deep learning model architecture. We show that generally ML-based methods perform much better than non-ML methods on most RNA targets, although the performance difference isn’t substantial when working with unseen novel or synthetic RNAs. The quality of the MSA and secondary structure prediction both play an important role and most methods aren’t able to predict non-Watson-Crick pairs in the RNAs. Overall, DeepFoldRNA has the best prediction followed by DRFold as the second best method. Finally, we also suggest possible mitigations to improve the quality of the prediction for future method development."
"GenomeFace: a deep learning-based metagenome binner trained on 43,000 microbial genomes","Metagenomic binning, the process of grouping DNA sequences into taxonomic units, is critical for understanding the functions, interactions, and evolutionary dynamics of microbial communities. We propose a deep learning approach to binning using two neural networks, one based on composition and another on environmental abundance, dynamically weighting the contribution of each based on characteristics of the input data. Trained on over 43,000 prokaryotic genomes, our network for composition-based binning is inspired by metric learning techniques used for facial recognition.Using a task-specific, multi-GPU accelerated algorithm to cluster the embeddings produced by our network, our binner leverages marker genes observed to be universally present in nearly all taxa to grade and select optimal clusters of sequences from a hierarchy of candidates.We evaluate our approach on four simulated datasets with known ground truth. Our linear time integration of marker genes recovers more near complete genomes than state of the art but computationally infeasible solutions using them, while being over an order of magnitude faster. Finally, we demonstrate the scalability and acuity of our approach by testing it on three of the largest metagenome assemblies ever performed. Compared to other binners, we produced 47%-183% more near complete genomes. From these datasets, we find over the genomes of over 3000 new candidate species which have never been previously cataloged, representing a potential 4% expansion of the known bacterial tree of life."
Identification of B cell subsets based on antigen receptor sequences using deep learning,"B cell receptors (BCRs) denote antigen specificity, while corresponding cell subsets indicate B cell functionality. Since each B cell uniquely encodes this combination, physical isolation and subsequent processing of individual B cells become indispensable to identify both attributes. However, this approach accompanies high costs and inevitable information loss, hindering high-throughput investigation of B cell populations. Here, we present BCR-SORT, a deep learning model that predicts cell subsets from their corresponding BCR sequences by leveraging B cell activation and maturation signatures encoded within BCR sequences. Subsequently, BCR-SORT is demonstrated to improve reconstruction of BCR phylogenetic trees, and reproduce results consistent with those verified using physical isolation-based methods or prior knowledge. Notably, when applied to BCR sequences from COVID-19 vaccine recipients, it revealed inter-individual heterogeneity of evolutionary trajectories towards Omicron-binding memory B cells. Overall, BCR-SORT offers great potential to improve our understanding of B cell responses."
Genome-scale annotation of protein binding sites via language model and geometric deep learning,"Revealing protein binding sites with other molecules, such as nucleic acids, peptides, or small ligands, sheds light on disease mechanism elucidation and novel drug design. With the explosive growth of proteins in sequence databases, how to accurately and efficiently identify these binding sites from sequences becomes essential. However, current methods mostly rely on expensive multiple sequence alignments or experimental protein structures, limiting their genome-scale applications. Besides, these methods haven’t fully explored the geometry of the protein structures. Here, we propose GPSite, a multi-task network for simultaneously predicting binding residues of DNA, RNA, peptide, protein, ATP, HEM, and metal ions on proteins. GPSite was trained on informative sequence embeddings and predicted structures from protein language models, while comprehensively extracting residual and relational geometric contexts in an end-to-end manner. Experiments demonstrate that GPSite substantially surpasses state-of-the-art sequence-based and structure-based approaches on various benchmark datasets, even when the structures are not well-predicted. The low computational cost of GPSite enables rapid genome-scale binding residue annotations for over 568,000 sequences, providing opportunities to unveil unexplored associations of binding sites with molecular functions, biological processes, and genetic variants. The GPSite webserver and annotation database can be freely accessed at https://bio-web1.nscc-gz.cn/app/GPSite."
"UniFed: A unified deep learning framework for segmentation of partially labelled, distributed neuroimaging data","It is essential to be able to combine datasets across imaging centres to represent the breadth of biological variability present in clinical populations. This, however, leads to two challenges: first, an increase in non-biological variance due to scanner differences, known as the harmonisation problem, and, second, data privacy concerns due to the inherently personal nature of medical images. Federated learning has been proposed to train deep learning models on distributed data; however, the majority of approaches assume fully labelled data at each participating site, which is unlikely to exist due to the time and skill required to produce manual segmentation labels. Further, they assume all of the sites are available when the federated model is trained. Thus, we introduce UniFed, a unified federated harmonisation framework which enables three key processes to be completed: 1) the training of a federated harmonisation network, 2) the selection of the most appropriate pretrained model for a new unseen site, and 3) the incorporation of a new site into the harmonised federation. We show that when working with partially labelled distributed datasets, our methods produce high-quality image segmentations and enable all sites to benefit from the knowledge of the federation. The framework is flexible and widely applicable across segmentation tasks and choices of model architecture."
Decoding the Impact of Neighboring Amino Acid on ESI-MS Intensity Output through Deep Learning,"Peptide-level quantification using mass spectrometry (MS) is no trivial task as the physicochemical properties affect both response and detectability. The specific amino acid (AA) sequence affects these properties, however the link from sequence to intensity output remains poorly understood. In this work, we explore combinations of amino acid pairs (i.e., dimer motifs) to determine a potential relationship between the local amino acid environment and MS1 intensity. For this purpose, a deep learning (DL) model, consisting of an encoder-decoder with an attention mechanism, was built. The attention mechanism allowed to identify the most relevant motifs. Specific patterns were consistently observed where a bulky/aromatic and hydrophobic AA followed by a cationic AA as well as consecutive bulky/aromatic and hydrophobic AAs were found important for the MS1 intensity. Correlating attention weights to mean MS1 intensities revealed that some important motifs, particularly containing Trp, His, and Cys, were linked with low responding peptides whereas motifs containing Lys and most bulky hydrophobic AAs were often associated with high responding peptides. Moreover, Asn–Gly was associated with low MS1 response. The model could predict MS1 response with a mean average percentage error of ∼11% and a Pearson correlation coefficient of ∼0.68."
Accurate single-molecule spot detection for image-based spatial transcriptomics with weakly supervised deep learning,"Image-based spatial transcriptomics methods enable transcriptome-scale gene expression measurements with spatial information but require complex, manually-tuned analysis pipelines. We present Polaris, an analysis pipeline for image-based spatial transcriptomics that combines deep learning models for cell segmentation and spot detection with a probabilistic gene decoder to quantify single-cell gene expression accurately. Polaris offers a unifying, turnkey solution for analyzing spatial transcriptomics data from MERFSIH, seqFISH, or ISS experiments. Polaris is available through the DeepCell software library (https://github.com/vanvalenlab/deepcell-spots) and https://www.deepcell.org."
BiaPy: A unified framework for versatile bioimage analysis with deep learning,"BiaPy, a unified open-source bioimage analysis library, offers a comprehensive suite of deep learning-powered workflows. Tailored for users of all levels, BiaPy features an intuitive interface, zero-code notebooks, and Docker integration. With support for 2D and 3D image data, it addresses existing gaps by providing multi-GPU capabilities, memory optimization, and compatibility with large datasets. As a collaborative and accessible solution, BiaPy aims to empower researchers by democratizing the use of sophisticated and efficient bioimage analysis workflows."
nanoBERT: A deep learning model for gene agnostic navigation of the nanobody mutational space,"Nanobodies are a subclass of immunoglobulins, whose binding site consists of only one peptide chain, bestowing favorable biophysical properties. Recently, the first nanobody therapy was approved, paving the way for further clinical applications of this antibody format. Further development of nanobody-based therapeutics could be streamlined by computational methods. One of such methods is infilling - positional prediction of biologically feasible mutations in nanobodies. Being able to identify possible positional substitutions based on sequence context, facilitates functional design of such molecules. Here we present nanoBERT, a nanobody-specific transformer to predict amino acids in a given position in a query sequence. We demonstrate the need to develop such machine-learning based protocol as opposed to gene-specific positional statistics since appropriate genetic reference is not available. We benchmark nanoBERT with respect to human-based language models and ESM-2, demonstrating the benefit for domain-specific language models. We also demonstrate the benefit of employing nanobody-specific predictions for fine-tuning on experimentally measured thermostability dataset. We hope that nanoBERT will help engineers in a range of predictive tasks for designing therapeutic nanobodies.Availability https://huggingface.co/NaturalAntibody/"
Being confident in confidence scores: calibration in deep learning models for camera trap image sequences,"In ecological studies, machine learning models are increasingly being used for the automatic processing of camera trap images. Although this automation facilitates and accelerates the identification step, the results of these models may lack interpretability and their immediate applicability to ecological downstream tasks (e.g occupancy estimation) remain questionable. In particular, little is known about their calibration, a property that guarantees that confidence scores can be reliably interpreted as probabilities that a model’s predictions are true. Using a large and diverse European camera trap dataset, we investigate whether deep learning models for species classification in camera trap images are well calibrated, or in contrast over/under-confident. Additionally, as camera traps are often configured to take multiple photos of the same event, we also explore the calibration of predictions at the sequence level. Finally, we study the effect and the practicality of a post-hoc calibration method, i.e. temperature scaling, for predictions made at image and sequence levels. Based on five established models and three independent test sets, our findings show that, using the right methodology, it is possible to enhance the interpretability of the confidence scores, with clear implication for, for instance, the calculation of error rates or the selection of confidence score thresholds in ecological studies making use of artificial intelligence models."
In-silico Drug Repurposing pipeline for Epilepsy: Integrating Deep Learning and Structure-based Approaches,"Epilepsy is a severe neurological disorder characterized by its chronic predisposition to recurrent epileptic seizures. Due to its considerable global prevalence and healthcare burden, the pursuit of effective new medication for epilepsy treatment remains an urgent and significant challenge in medical practice. Drug repurposing emerges as a cost-effective and efficient strategy to combat this disorder. This study leverages the transformer-based deep learning methods coupled with molecular binding affinity calculation to develop a novel in-silico drug repurposing pipeline for epilepsy. The number of candidate inhibitors approved for chronic conditions against 24 gain-of-function (GOF) encoding targets implicated in epileptogenesis ranged from zero to several hundred. Nearly half of candidate medications for each target were used for psychiatric diseases and most of anti-epileptic drugs (AEDs) in market were identified, highlighting the effectiveness of our pipeline. Furthermore, Lomitapide, a cholesterol-lowering drug, emerged as particularly noteworthy, exhibiting high binding affinity for ten targets and verified by molecular dynamics (MD) simulation. These findings demonstrated the practical potential of our in-silico drug repurposing pipeline in epilepsy treatment, providing a novel perspective on therapeutic strategies for other central nervous system (CNS) disease."
A deep-learning strategy to identify cell types across species from high-density extracellular recordings,"High-density probes allow electrophysiological recordings from many neurons simultaneously across entire brain circuits but fail to determine each recorded neuron’s cell type. Here, we develop a strategy to identify cell types from extracellular recordings in awake animals, opening avenues to unveil the computational roles of neurons with distinct functional, molecular, and anatomical properties. We combine optogenetic activation and pharmacology using the cerebellum as a testbed to generate a curated ground-truth library of electrophysiological properties for Purkinje cells, molecular layer interneurons, Golgi cells, and mossy fibers. We train a semi-supervised deep-learning classifier that predicts cell types with greater than 95% accuracy based on waveform, discharge statistics, and layer of the recorded neuron. The classifier’s predictions agree with expert classification on recordings using different probes, in different laboratories, from functionally distinct cerebellar regions, and across animal species. Our approach provides a general blueprint for cell-type identification from extracellular recordings across the brain."
CODEX: COunterfactual Deep learning for the in-silico EXploration of cancer cell line perturbations,"Motivation High-throughput screens (HTS) provide a powerful tool to decipher the causal effects of chemical and genetic perturbations on cancer cell lines. Their ability to evaluate a wide spectrum of interventions, from single drugs to intricate drug combinations and CRISPR-interference, has established them as an invaluable resource for the development of novel therapeutic approaches. Nevertheless, the combinatorial complexity of potential interventions makes a comprehensive exploration intractable. Hence, prioritizing interventions for further experimental investigation becomes of utmost importance.Results We propose CODEX as a general framework for the causal modeling of HTS data, linking perturbations to their downstream consequences. CODEX relies on a stringent causal modeling strategy based on counterfactual reasoning. As such, CODEX predicts drug-specific cellular responses, comprising cell survival and molecular alterations, and facilitates the in-silico exploration of drug combinations. This is achieved for both bulk and single-cell HTS. We further show that CODEX provides a rationale to explore complex genetic modifications from CRISPR-interference in silico in single cells.Availability and Implementation Our implementation of CODEX is publicly available at https://github.com/sschrod/CODEX. All data used in this article are publicly available."
Deep Learning Outperforms Classical Machine Learning Methods in Pediatric Brain Tumor Classification through Mass Spectra,"Pediatric brain tumors are the most common cause of death among all childhood cancers and surgical resection usually is the first step in disease management. During surgery, it is important to perform safe gross resection of tumors, retaining as much brain tissue as possible. Therefore, appropriate resection margin delineation is extremely relevant.Currently available methods for tissue analysis have limited precision, are time-consuming, and often require multiple invasive procedures. Our main goal is to test whether machine learning techniques are capable of classifying the pediatric brain tissue chemical profile generated by DESI-MSI, which is mainly lipidic, into normal or abnormal tissue and into low- and high-grade malignancy subareas within each sample.Our experiments show that deep learning methods outperform classical machine learning methods in the task of classifying brain tissue from DESI-MSI mass spectra, both in normal versus abnormal tissue, and, for malignant tissues, in low-grade versus high-grade malignancy.Our conclusion are based on the analysis of 34,870 annotated spectra, obtained from the neoplastic and non-neoplastic microanatomical stratification of individual samples from 116 pediatric patients who underwent brain tumor surgical resection at the Boldrini Children’s Center between 2000 and 2020. Support Vector Machines, Random, Forests, and Least Absolute Shrinkage and Selection Operator (LASSO) were among the classical machine learning techniques evaluated."
Delineating yeast cleavage and polyadenylation signals using deep learning,"ABSTRACT3’-end cleavage and polyadenylation is an essential process for eukaryotic mRNA maturation. In yeast species, the polyadenylation signals that recruit the processing machinery are degenerate and remain poorly characterized compared to well-defined regulatory elements in mammals. Especially, recent deep sequencing experiments showed extensive cleavage heterogeneity for some mRNAs in Saccharomyces cerevisiae and uncovered the polyA motif differences between S. cerevisiae vs. Schizosaccharomyces pombe. The findings raised the fundamental question of how polyadenylation signals are formed in yeast. Here we addressed this question by developing deep learning models to deconvolute degenerate cis-regulatory elements and quantify their positional importance in mediating yeast polyA site formation, cleavage heterogeneity, and strength. In S. cerevisiae, cleavage heterogeneity is promoted by the depletion of U-rich elements around polyA sites as well as multiple occurrences of upstream UA-rich elements. Sites with high cleavage heterogeneity show overall lower strength. The site strength and tandem site distances modulate alternative polyadenylation (APA) under the diauxic stress. Finally, we developed a deep learning model to reveal the distinct motif configuration of S. pombe polyA sites which show more precise cleavage than S. cerevisiae. Altogether, our deep learning models provide unprecedented insights into polyA site formation across yeast species."
Efficient Inference on a Network of Spiking Neurons using Deep Learning,"The process of making inference on networks of spiking neurons is crucial to decipher the underlying mechanisms of neural computation. Mean-field theory simplifies the interactions between neurons to produce macroscopic network behavior, facilitating the study of information processing and computation within the brain. In this study, we perform inference on a mean-field model of spiking neurons to gain insight into likely parameter values, uniqueness and degeneracies, and also to explore how well the statistical relationship between parameters is maintained by traversing across scales. We benchmark against state-of-the-art optimization and Bayesian estimation algorithms to identify their strengths and weaknesses in our analysis. We show that when confronted with dynamical noise or in the case of missing data in the presence of bistability, generating probability distributions using deep neural density estimators outperforms other algorithms, such as adaptive Monte Carlo sampling. However, this class of deep generative models may result in an overestimation of uncertainty and correlation between parameters. Nevertheless, this issue can be improved by incorporating time-delay embedding. Moreover, we show that training deep Neural ODEs on spiking neurons enables the inference of system dynamics from microscopic states. In summary, this work demonstrates the enhanced accuracy and efficiency of inference on networks of spiking neurons when deep learning is harnessed to solve inverse problems in neural computation."
Automating clinical assessments of memory deficits: Deep Learning based scoring of the Rey-Osterrieth Complex Figure,"Background Memory deficits are a hallmark of many different neurological and psychiatric conditions. The Rey-Osterrieth complex figure (ROCF) is the state–of-the-art assessment tool for neuropsychologists across the globe to assess the degree of non-verbal visual memory deterioration. To obtain a score, a trained clinician inspects a patient’s ROCF drawing and quantifies deviations from the original figure. This manual procedure is time-consuming, slow and scores vary depending on the clinician’s experience, motivation and tiredness.Methods Here, we leverage novel deep learning architectures to automatize the rating of memory deficits. For this, we collected more than 20k hand-drawn ROCF drawings from patients with various neurological and psychiatric disorders as well as healthy participants. Unbiased ground truth ROCF scores were obtained from crowdsourced human intelligence. This dataset was used to train and evaluate a multi-head convolutional neural network.Results The model performs highly unbiased as it yielded predictions very close to the ground truth and the error was similarly distributed around zero. The neural network outperforms both online raters and clinicians. The scoring system can reliably identify and accurately score individual figure elements in previously unseen ROCF drawings, which facilitates explainability of the AI-scoring system. To ensure generalizability and clinical utility, the model performance was successfully replicated in a large independent prospective validation study that was pre-registered prior to data collection.Conclusions Our AI-powered scoring system provides healthcare institutions worldwide with a digital tool to assess objectively, reliably and time-efficiently the performance in the ROCF test from hand-drawn images."
Genotype sampling for deep-learning assisted experimental mapping of fitness landscapes,"Motivation Experimental characterization of fitness landscapes, which map genotypes onto fitness, is important for both evolutionary biology and protein engineering. It faces a fundamental obstacle in the astronomical number of genotypes whose fitness needs to be measured for any one protein. Deep learning may help to predict the fitness of many genotypes from a smaller neural network training sample of genotypes with experimentally measured fitness. Here I use a recently published experimentally mapped fitness landscape of more than 260,000 protein genotypes to ask how such sampling is best performed.Results I show that multilayer perceptrons, recurrent neural networks (RNNs), convolutional networks, and transformers, can explain more than 90 percent of fitness variance in the data. In addition, 90 percent of this performance is reached with a training sample comprising merely ≈103 sequences. Generalization to unseen test data is best when training data is sampled randomly and uniformly, or sampled to minimize the number of synonymous sequences. In contrast, sampling to maximize sequence diversity or codon usage bias reduces performance substantially. These observations hold for more than one network architecture. Simple sampling strategies may perform best when training deep learning neural networks to map fitness landscapes from experimental data."
Label-free Identification of Protein Aggregates Using Deep Learning,"Protein misfolding and aggregation play central roles in the pathogenesis of various neurodegenerative diseases (NDDs), including Huntington’s disease, which is caused by a genetic mutation that leads to a polyglutamine repeat length > 35 in exon 1 of the Huntingtin protein (Httex1). Current research on protein aggregation often involves the use of fluorescent labels to visualize and monitor the dynamics of protein expression, which can alter the biophysical properties of proteins and the final ultrastructure, composition, and toxic properties of the formed aggregates. To overcome this limitation, we present a method for label-free identification of NDD-associated aggregates (LINA). Our approach utilizes deep learning to detect unlabeled and unaltered Httex1 aggregates in living cells from transmitted-light images, without the need for fluorescent labeling. We developed pixel-classification and pixel-regression models, which are robust across imaging conditions, and validated them on aggregates formed by different constructs of Httex1. Our results reveal that Httex1 proteins with shorter polyglutamine repeat lengths form aggregates with a higher average dry mass and area, highlighting the differences in their ultrastructure and aggregation mechanisms. LINA enables the dynamic identification of label-free aggregates and measurement of their dry mass and area changes during their growth process. Our highly-robust models offer high speed, specificity, and simplicity to analyze label-free protein aggregation dynamics and obtain high-fidelity information."
Evaluation of Deep Learning for predicting rice traits using structural and single-nucleotide genomic variants,"Structural variants (SVs) such as deletions, inversions, duplications, and Transposable Element (TE) Insertion Polymorphisms (TIPs) are prevalent in plant genomes and have played an important role in evolution and domestication, as they constitute a significant source of genomic and phenotypic variability. Nevertheless, most methods in quantitative genetics focusing on crop improvement, such as genomic prediction, consider Single Nucleotide Polymorphisms (SNPs) as the only type of genetic marker. Here, we used rice to investigate whether combining the structural and nucleotide genome-wide variation can improve prediction ability of traits when compared to using only SNPs. Moreover, we also examine the potential advantage of Deep Learning (DL) networks over Bayesian Linear models, which have been widely applied in genomic prediction. Specifically, the performance of BayesC and a Bayesian Reproducible Kernel Hilbert space regressions were compared to two different DL architectures, the Multilayer Perceptron, and the Convolution Neural Network. We further explore their prediction ability by using various marker input strategies and found that exploiting structural and nucleotide variation improves prediction ability on complex traits in rice. Also, DL models outperformed Bayesian models in 75% of the studied cases. Finally, DL systematically improved prediction ability of binary traits against the Bayesian models."
Fruit-In-Sight: a deep learning-based framework for secondary metabolite class prediction using fruit and leaf images,"Fruits produce a wide variety of secondary metabolites of great economic value. Analytical measurement of secondary metabolites is tedious, time-consuming and expensive. Additionally, metabolite concentration varies greatly from tree to tree, making it difficult to choose trees for fruit collection. The current study tested whether deep learning-based models can be developed using fruit and leaf images alone to predict a metabolite's concentration class (high or low). We collected fruits and leaves (n = 1045) from neem trees grown in the wild across 0.6 million sq km, imaged those, measured concentration of five metabolites (azadirachtin, deacetyl-salannin, salannin, nimbin and nimbolide) using high-performance liquid chromatography and used those to train deep learning models for metabolite class prediction. The best model out of the seven tested (YOLOv5, GoogLeNet, InceptionNet, EfficientNet_B0, Resnext_50, Resnet18, and SqueezeNet) provided a validation F1 score of 0.93 and a test F1 score of 0.88. The sensitivity and specificity of the fruit model alone in the test set were 83.52 ± 6.19 and 82.35 ± 5.96 and 79.40 ± 8.50 and 85.64 ± 6.21, for the low and the high class, respectively. The sensitivity was further boosted to 92.67 ± 5.25 for the low class and 88.11 ± 9.17 for the high class and the specificity to 100% for both classes, using a multi-analyte framework. We incorporated the model in an Android mobile App Fruit-In-Sight that uses fruit and leaf images to decide whether to ″pick″ or ″not pick″ the fruits from a specific tree based on the metabolite concentration class. Our study provides evidence that images of fruits and leaves alone can predict the concentration class of a secondary metabolite without using extensive analytical laboratory procedures and equipment and makes the process of choosing the right tree for fruit collection easy and free of equipment and additional cost."
FateNet: an integration of dynamical systems and deep learning for cell fate prediction,"Understanding cellular decision-making, particularly its timing and impact on the biological system such as tissue health and function, is a fundamental challenge in biology and medicine. Existing methods for inferring fate decisions and cellular state dynamics from single-cell RNA sequencing data lack precision regarding decision points and broader tissue implications. Addressing this gap, we present FateNet, a computational approach integrating dynamical systems theory and deep learning to probe the cell decision-making process using scRNA-seq data. By leveraging information about normal forms and scaling behavior near tipping pointscommon to many dynamical systems, FateNet accurately predicts cell decision occurrence and offers qualitative insights into the new state of the biological system. Also, through in-silico perturbation experiments, FateNet identifies key genes and pathways governing the differentiation process in hematopoiesis. Validated using different scRNA-seq data, FateNet emerges as a user-friendly and valuable tool for predicting critical points in biological processes, providing insights into complex trajectories."
Deep learning prediction of enzyme optimum pH,"The relationship between pH and enzyme catalytic activity, as well as the optimal pH (pHopt) at which enzymes function, is crucial for biotechnological applications. Consequently, computational methods that predict pHopt would significantly benefit enzyme discovery and design by facilitating accurate identification of enzymes that function optimally at a specific pH, and by promoting a better understanding of how sequence affects enzyme function in relation to pH. In this study, we present EpHod (Enzyme pH optimum prediction with deep learning), which is a deep semi-supervised language model for predicting enzyme pHopt directly from the protein sequence. By evaluating various machine learning methods with extensive hyperparameter optimization (training over 4,000 models in total), we find that semi-supervised methods that utilize language model embeddings, including EpHod, achieve the lowest error in predicting pHopt. From sequence data alone, EpHod learns structural and biophysical features that relate to pHopt, including proximity of residues to the catalytic center and the accessibility of solvent molecules. Overall, EpHod presents a promising advancement in pHopt prediction and could potentially speed up the development of improved enzyme technologies."
Deep-learning quantified cell-type-specific nuclear morphology predicts genomic instability and prognosis in multiple cancer types,"ABSTRACTWhile alterations in nucleus size, shape, and color are ubiquitous in cancer, comprehensive quantification of nuclear morphology across a whole-slide histologic image remains a challenge. Here, we describe the development of a pan-tissue, deep learning-based digital pathology pipeline for exhaustive nucleus detection, segmentation, and classification and the utility of this pipeline for nuclear morphologic biomarker discovery. Manually-collected nucleus annotations were used to train an object detection and segmentation model for identifying nuclei, which was deployed to segment nuclei in H&E-stained slides from the BRCA, LUAD, and PRAD TCGA cohorts. Interpretable features describing the shape, size, color, and texture of each nucleus were extracted from segmented nuclei and compared to measurements of genomic instability, gene expression, and prognosis. The nuclear segmentation and classification model trained herein performed comparably to previously reported models. Features extracted from the model revealed differences sufficient to distinguish between BRCA, LUAD, and PRAD. Furthermore, cancer cell nuclear area was associated with increased aneuploidy score and homologous recombination deficiency. In BRCA, increased fibroblast nuclear area was indicative of poor progression-free and overall survival and was associated with gene expression signatures related to extracellular matrix remodeling and anti-tumor immunity. Thus, we developed a powerful pan-tissue approach for nucleus segmentation and featurization, enabling the construction of predictive models and the identification of features linking nuclear morphology with clinically-relevant prognostic biomarkers across multiple cancer types."
RNA3DB: A structurally-dissimilar dataset split for training and benchmarking deep learning models for RNA structure prediction,"With advances in protein structure prediction thanks to deep learning models like AlphaFold, RNA structure prediction has recently received increased attention from deep learning researchers. RNAs introduce substantial challenges due to the sparser availability and lower structural diversity of the experimentally resolved RNA structures in comparison to protein structures. These challenges are often poorly addressed by the existing literature, many of which report inflated performance due to using training and testing sets with significant structural overlap. Further, the most recent Critical Assessment of Structure Prediction (CASP15) has shown that deep learning models for RNA structure are currently outperformed by traditional methods.In this paper we present RNA3DB, a dataset of structured RNAs, derived from the Protein Data Bank (PDB), that is designed for training and benchmarking deep learning models. The RNA3DB method arranges the RNA 3D chains into distinct groups (Components) that are non-redundant both with regard to sequence as well as structure, providing a robust way of dividing training, validation, and testing sets. Any split of these structurally-dissimilar Components are guaranteed to produce test and validations sets that are distinct by sequence and structure from those in the training set. We provide the RNA3DB dataset, a particular train/test split of the RNA3DB Components (in an approximate 70/30 ratio) that will be updated periodically. We also provide the RNA3DB methodology along with the source-code, with the goal of creating a reproducible and customizable tool for producing structurally-dissimilar dataset splits for structural RNAs.Download figureOpen in new tabHighlightsWhile there is a recent surge in applying deep learning to RNA structure prediction, domain experts have raised concerns about generalization and current trends in benchmarking.Many of the concerns primarily relate to how novel RNA families–i.e. families unseen in the training set–are benchmarked, and whether the models are effective at handling such cases. Performance on bench-marks reflective of real-world applications, such as CASP15 and RNA-Puzzles, is poor for RNA deep learning models.We present a dataset–RNA3DB–that is designed for training and bench-marking deep learning models for RNA structure prediction. RNA3DB provides coverage of all RNA chains found in the Protein Data Bank (PDB).RNA3DB is clustered into groups that are both sequentially and structurally non-redundant, providing a robust way of creating training, validation, and testing sets for deep learning models. Along with the dataset, we also provide a transparent methodology as well as the source-code, making our tool both reproducible and customizable."
EvoAug-TF: Extending evolution-inspired data augmentations for genomic deep learning to TensorFlow,"ABSTRACTDeep neural networks (DNNs) have been widely applied to predict the molecular functions of regulatory regions in the non-coding genome. DNNs are data hungry and thus require many training examples to fit data well. However, functional genomics experiments typically generate limited amounts of data, constrained by the activity levels of the molecular function under study inside the cell. Recently, EvoAug was introduced to train a genomic DNN with evolution-inspired augmentations. EvoAug-trained DNNs have demonstrated improved generalization and interpretability with attribution analysis. However, EvoAug only supports PyTorch-based models, which limits its applications to a broad class of genomic DNNs based in TensorFlow. Here, we extend EvoAug’s functionality to TensorFlow in a new package we call EvoAug-TF. Through a systematic benchmark, we find that EvoAug-TF yields comparable performance with the original EvoAug package.Availability EvoAug-TF is freely available for users and is distributed under an open-source MIT license. Researchers can access the open-source code on GitHub (https://github.com/p-koo/evoaug-tf). The pre-compiled package is provided via PyPI (https://pypi.org/project/evoaug-tf) with in-depth documentation on ReadTheDocs (https://evoaug-tf.readthedocs.io). The scripts for reproducing the results are available at (https://github.com/p-koo/evoaug-tf_analysis)."
Contextualizing protein representations using deep learning on protein networks and single-cell data,"Understanding protein function and developing molecular therapies require deciphering the cell types in which proteins act as well as the interactions between proteins. However, modeling protein interactions across diverse biological contexts, such as tissues and cell types, remains a significant challenge for existing algorithms. We introduce Pinnacle, a flexible geometric deep learning approach that is trained on contextualized protein interaction networks to generate context-aware protein representations. Leveraging a human multiorgan single-cell transcriptomic atlas, Pinnacle provides 394,760 protein representations split across 156 cell type contexts from 24 tissues and organs. Pinnacle’s contextualized representations of proteins reflect cellular and tissue organization and Pinnacle’s tissue representations enable zero-shot retrieval of the tissue hierarchy. Pretrained Pinnacle’s protein representations can be adapted for downstream tasks: to enhance 3D structure-based protein representations for important protein interactions in immuno-oncology (PD-1/PD-L1 and B7-1/CTLA-4) and to study the effects of drugs across cell type contexts. Pinnacle outperforms state-of-the-art, yet context-free, models in nominating therapeutic targets for rheumatoid arthritis and inflammatory bowel diseases, and can pinpoint cell type contexts that predict therapeutic targets better than context-free models (29 out of 156 cell types in rheumatoid arthritis; 13 out of 152 cell types in inflammatory bowel diseases). Pinnacle is a graph-based contextual AI model that dynamically adjusts its outputs based on biological contexts in which it operates."
DARDN: A deep-learning approach for CTCF binding sequence classification and oncogenic regulatory feature discovery,"Characterization of gene regulatory mechanisms in cancer is a key task in cancer genomics. CCCTC-binding factor (CTCF), a DNA binding protein, exhibits specific binding patterns in the genome of cancer cells and has a non-canonical function to facilitate oncogenic transcription programs by cooperating with transcription factors bound at flanking distal regions. Identification of DNA sequence features from a broad genomic region that distinguish cancer-specific CTCF binding sites from regular CTCF binding sites can help find oncogenic transcription factors in a cancer type. However, the long DNA sequences without localization information makes it difficult to perform conventional motif analysis. Here we present DNAResDualNet (DARDN), a computational method that utilizes convolutional neural networks (CNNs) for predicting cancer-specific CTCF binding sites from long DNA sequences and employs DeepLIFT, a method for interpretability of deep learning models that explains the model’s output in terms of the contributions of its input features [1], for identifying DNA sequence features associated with cancer-specific CTCF binding. Evaluation on DNA sequences associated with CTCF binding sites in T-cell acute lymphoblastic leukemia (T-ALL) and other cancer types demonstrates DARDN’s ability in classifying DNA sequences surrounding cancer-specific CTCF binding from control constitutive CTCF binding and identifying sequence motifs for transcription factors potentially active in each specific cancer type. We identified potential oncogenic transcription factors in T-ALL, acute myeloid leukemia (AML), breast cancer (BRCA), colorectal cancer (CRC), lung adenocarcinoma (LUAD), and prostate cancer (PRAD). Our work demonstrates the power of advanced machine learning and feature discovery approach in finding biologically meaningful information from complex high-throughput sequencing data."
LizardNet: A mobile hybrid deep learning tool for classification of 3D representations of Amazonian lizards,"Image classification is a highly significant field in machine learning (ML), especially when applied to address longstanding and challenging issues in the biological sciences. In this study, we present the development of a hybrid deep learning-based tool suitable for deployment on mobile devices. This tool is aimed at processing and classifying three-dimensional samples of endemic lizard species from the Amazon rainforest. The dataset used in our experiment was collected at the Museu Paraense Emílio Goeldi (MPEG), Belém-PA, Brazil, and comprises three species: a) Anolis fuscoauratus; b) Hoplocercus spinosus; and c) Polychrus marmoratus. We compared the effectiveness of four artificial neural networks (ANN) for feature extraction: a) MobileNet; b) MobileNetV2; c) MobileNetV3Small; and d) MobileNetV3Large. Additionally, we evaluated five classical ML models for classifying the extracted patterns: a) Support Vector Machine (SVM); b) GaussianNB (GNB); c) AdaBoost (ADB); d) K-Nearest Neighbors (KNN); and e) Random Forest (RF). Our most effective model, MobileNetV3-Small + Linear SVM, achieved an accuracy of 0.948 and a f1-score of 0.955. Notably, it not only proved to be the least complex model among all combinations but also demonstrated the best performance after a statistical comparison. These results indicate that the combination of deep learning (DL) models with less complex classical ML algorithms, which have a lower error propensity, emerges as a viable and efficient technique for classifying three-dimensional lizard species samples. Such an approach facilitates taxonomic identification work for professionals in the field and provides a tool adaptable for integration into mobile data recording equipment, such as smartphones.Author summary The taxonomic classification of lizards requires an exceptional level of knowledge and attention to minute details beyond the ordinary to accurately categorize specimens. Such tasks impose significant mental and visual costs on humans, unlike computer vision algorithms capable of extracting visual patterns from images imperceptible to the human eye. In this research, we utilized a dataset from the herpetarium of the Emílio Goeldi Museum in Belém-PA, Brazil. The data were self-captured, with each sample comprised of three photos: dorsal, lateral, and ventral views of each specimen. The sample size was constrained by the quality and abundance of preserved specimens, necessitating the application of a data augmentation method on the pre-separated training and validation sets. This augmentation led to a considerable increase in the number of samples per species, from a few dozen to several hundred. Our experimental approach involved utilizing pre-trained neural networks to extract 3D sample characteristics, subsequently classified using classical machine learning algorithms. This hybrid strategy was adopted due to the nature of data collection and synthetic data augmentation. Our method enables specimen identification through three-dimensional representations, allowing for a more comprehensive utilization of morphological information by the model."
Improving the performance of supervised deep learning for regulatory genomics using phylogenetic augmentation,"Structured abstractMotivation Supervised deep learning is used to model the complex relationship between genomic sequence and regulatory function. Understanding how these models make predictions can provide biological insight into regulatory functions. Given the complexity of the sequence to regulatory function mapping (the cis-regulatory code), it has been suggested that the genome contains insufficient sequence variation to train models with suitable complexity. Data augmentation is a widely used approach to increase the data variation available for model training, however current data augmentation methods for genomic sequence data are limited.Results Inspired by the success of comparative genomics, we show that augmenting genomic sequences with evolutionarily related sequences from other species, which we term phylogenetic augmentation, improves the performance of deep learning models trained on regulatory genomic sequences to predict high-throughput functional assay measurements. Additionally, we show that phylogenetic augmentation can rescue model performance when the training set is down-sampled and permits deep learning on a real-world small dataset, demonstrating that this approach improves experimental data efficiency. Overall, this data augmentation method represents a solution for improving model performance that is applicable to many supervised deep learning problems in genomics.Availability and implementation The open-source GitHub repository agduncan94/phylogenetic_augmentation_paper includes the code for rerunning the analyses here and recreating the figures.Contact alan.moses{at}utoronto.ca"
Molecular de-extinction of antibiotics enabled by deep learning,"Molecular de-extinction is an emerging field that aims to resurrect molecules to solve present-day problems such as antibiotic resistance. Here, we introduce a deep learning approach called Antibiotic Peptide de-Extinction (APEX) to mine the proteomes of all available extinct organisms (the “extinctome”) searching for encrypted peptide (EP) antibiotics. APEX mined a total of 10,311,899 EPs and identified 37,176 sequences predicted to have broad-spectrum antimicrobial activity, 11,035 of which were not found in extant organisms. Chemical synthesis and experimental validation yielded archaic EPs (AEPs) with activity against dangerous bacterial pathogens. Most peptides killed bacteria by depolarizing their cytoplasmic membrane, contrary to known antimicrobial peptides, which target the outer membrane. Notably, lead peptides, including those derived from the woolly mammoth, ancient sea cow, giant sloth, and extinct giant elk, exhibited anti-infective activity in preclinical mouse models. We propose molecular de-extinction, accelerated by deep learning, as a framework for discovering therapeutic molecules."
"AnNoBrainer, an Automated Annotation of Mouse Brain Images using Deep Learning","Annotation of multiple regions of interest across the whole mouse brain is an indispensable process for quantitative evaluation of a multitude of study endpoints in neuroscience digital pathology. Prior experience and domain expert knowledge are the key aspects for image annotation quality and consistency. At present, image annotation is often achieved manually by certified pathologists or trained technicians, limiting the total throughput of studies performed at neuroscience digital pathology labs. It may also mean that less rigorous, less time-consuming methods of histopathological assessment are employed by non-pathologists, especially for early discovery and preclinical studies. To address these limitations and to meet the growing demand for image analysis in a pharmaceutical setting, we developed AnNoBrainer, an open-source software tool that leverages deep learning, image registration, and standard cortical brain templates to automatically annotate individual brain regions on 2D pathology slides. Application of AnNoBrainer to a published set of pathology slides from transgenic mice models of synucleinopathy revealed comparable accuracy, increased reproducibility, and a significant reduction (∼50%) in time spent on brain annotation, quality control and labelling compared to trained scientists in pathology. Taken together, AnNoBrainer offers a rapid, accurate, and reproducible automated annotation of mouse brain images that largely meets the experts’ histopathological assessment standards (>85% of cases) and enables high-throughput image analysis workflows in digital pathology labs."
Reformer: Deep learning model for characterizing protein-RNA interactions from sequence at single-base resolution,"Protein-RNA interactions play an essential role in the regulation of transcription, translation, and metabolism of cellular RNA. Here, we develop Reformer, a deep learning model that predicts protein-RNA binding affinity purely from sequence. We developed Reformer with 155 RNA binding protein (RBP) targets from 3 cell lines. Reformer achieved high prediction accuracy at single-base resolution when tasking with inferring protein- and cell-type-specific binding affinity. We conducted electrophoretic mobility shift assays to validate high-impact RNA regulation mutations predicted by Reformer. In addition, Reformer learned to capture protein binding motifs that cannot be discovered by eCLIP-seq experiments. Furthermore, we demonstrated that motif signatures related to RNA processing functions are encoded within Reformer. In conclusion, Reformer will facilitate interpretation of the regulation mechanisms underlying RNA processing."
Deciphering the co-evolutionary dynamics of L2 β-lactamases via Deep learning,"L2 β-lactamases, a serine-based class A β-lactamases expressed by Stenotrophomonas maltophilia plays a pivotal role in antimicrobial resistance. However, limited studies have been conducted on these important enzymes. To understand the co-evolutionary dynamics of L2 β-lactamase, innovative computational methodologies, including adaptive sampling molecular dynamics simulations, and deep learning methods (convolutional variational autoencoders and BindSiteS-CNN) explored conformational changes and correlations within the L2 β-lactamase family together with other representative class A enzymes including SME-1 and KPC-2. This work also investigated the potential role of hydrophobic nodes and binding site residues in facilitating the functional mechanisms. The convergence of analytical approaches utilized in this effort yielded comprehensive insights into the dynamic behaviour of the β-lactamases, specifically from an evolutionary standpoint. In addition, this analysis presents a promising approach for understanding how the class A β-lactamases evolve in response to environmental pressure and establishes a theoretical foundation for forthcoming endeavours in drug development aimed at combating antimicrobial resistance.Synopsis Deep learning is used to reveal the dynamic co-evolutionary patterns of L2 β-lactamases.Analysis of hydrophobic nodes and binding site residues provides a detailed understanding of both local and global dynamic evolution, which explain the functional divergences.The employment of two distinct deep learning models, the Convolutional Variational Autoencoder (CVAE) and BindSiteS-CNN, facilitates the investigation of conformational shifts, thereby depicting the dynamic evolution of L2 β-lactamases.The effectiveness of CVAE and BindSiteS-CNN in dynamic classification is corroborated with selected features.Download figureOpen in new tab"
High-content high-resolution microscopy and deep learning assisted analysis reveals host and bacterial heterogeneity during Shigella infection,"Shigella flexneri is a Gram-negative bacterial pathogen and causative agent of bacillary dysentery. S. flexneri is closely related to Escherichia coli but harbors a virulence plasmid that encodes a Type III Secretion System (T3SS) required for host cell invasion. Widely recognized as a paradigm for research in cellular microbiology, S. flexneri has emerged as important to study mechanisms of cell-autonomous immunity, including septin cage entrapment. Here we use high-content high-resolution microscopy to monitor the dynamic and heterogeneous S. flexneri infection process by assessing multiple host and bacterial parameters (DNA replication, protein translation, T3SS activity). In the case of infected host cells, we report a reduction in DNA and protein synthesis together with morphological changes that suggest S. flexneri can induce cell-cycle arrest. We developed an artificial intelligence image analysis approach using Convolutional Neural Networks to reliably quantify, in an automated and unbiased manner, the recruitment of SEPT7 to intracellular bacteria. We discover that heterogeneous SEPT7 assemblies are recuited to actively pathogenic bacteria with increased T3SS activation. Our automated microscopy workflow is useful to illuminate host and bacterial dynamics at the single-cell and population level, and to fully characterise the intracellular microenvironment controlling the S. flexneri infection process."
Predictive Deep Learning Model for Neural Vessel Occlusion,"Recent advances in medical applications for clot removal have enabled physicians to unblock blood vessel occlusions that occur in extremely narrow regions of the brain along the Horizontal (M1) segment of the middle cerebral artery. FDA approved, clinical trials have proven the significant cerebral recovery that can be achieved for victims of ischemic stroke when they undergo swift surgical intervention for clot removal. That said, carrying out such a delicate operation simultaneously requires extreme surgical expertise, and the ability to quickly identify the site of occlusion from 2D x-ray images of the brain. Fortunately, recent efforts in object detection and classification within the fields of deep learning and computer vision have dramatically improved the predictive power of the computer. Accordingly, the goal of this research project is to develop a deep learning model capable of accurately predicting the site of occlusion from frontal view cerebral angiograms in real time. Our current model utilizes YOLOv3 architecture and identifies the site of occlusion in 94.4% of all cases given a minimum 25% confidence threshold. Furthermore, in 83.97% of cases, the occlusion region is detected with at least 50% average intersection over union between the predicted region and the ground truth region. Finally, distributed over the entire validation set, the average intersection over union between the predicted region and the ground truth region was 74.29%."
"APNet, an explainable sparse deep learning model to discover differentially active drivers of severe COVID-19","Motivation Computational analyses of plasma proteomics provide translational insights into complex diseases such as COVID-19 by revealing molecules, cellular phenotypes, and signaling patterns that contribute to unfavorable clinical outcomes. Current in silico approaches dovetail differential expression, biostatistics, and machine learning, but often overlook nonlinear proteomic dynamics, like post-translational modifications, and provide limited biological interpretability beyond feature ranking.Results We introduce APNet, a novel computational pipeline that combines differential activity analysis based on SJARACNe co-expression networks with PASNet, a biologically-informed sparse deep learning model to perform explainable predictions for COVID-19 severity. The APNet driver-pathway network ingests co-expression and classification weights to aid result interpretation and hypothesis generation. APNet outperforms alternative models in patient classification across three COVID-19 proteomic datasets, identifying predictive drivers and pathways, including some confirmed in single-cell omics and highlighting under-explored biomarker circuitries in COVID-19.Availability and Implementation APNet’s R, Python scripts and Cytoscape methodologies are available at https://github.com/BiodataAnalysisGroup/APNetContact ggeorav{at}certh.grSupplementary information Supplementary information can be accessed in Zenodo (10.5281/zenodo.10438830)."
MATES: A Deep Learning-Based Model for Locus-specific Quantification of Transposable Elements in Single Cell,"Transposable elements (TEs) are crucial for genetic diversity and gene regulation. Current single-cell quantification methods often align multi-mapping reads to either ‘best-mapped’ or ‘random-mapped’ locations and categorize them at sub-family levels, overlooking the biological necessity for accurate, locus-specific TE quantification. Moreover, these existing methods are primarily designed for and focused on transcriptomics data, which restricts their adaptability to single-cell data of other modalities. To address these challenges, here we introduce MATES, a novel deep-learning approach that accurately allocates multi-mapping reads to specific loci of TEs, utilizing context from adjacent read alignments flanking the TE locus. When applied to diverse single-cell omics datasets, MATES shows improved performance over existing methods, enhancing the accuracy of TE quantification and aiding in the identification of marker TEs for identified cell populations. This development enables exploring single-cell heterogeneity and gene regulation through the lens of TEs, offering a transformative tool for the single-cell genomics community."
Explainable Deep Learning Framework: Decoding Brain Task and Prediction of Individual Performance in False-Belief Task at Early Childhood Stage,"Decoding of brain tasks aims to identify individuals’ brain states and brain fingerprints to predict behavior. Deep learning provides an important platform for analyzing brain signals at different developmental stages to understand brain dynamics. Due to their internal architecture and feature extraction techniques, existing machine learning and deep-learning approaches for fMRI-based brain decoding must improve classification performance and explainability. The existing approaches also focus on something other than the behavioral traits that can tell about individuals’ variability in behavioral traits. In the current study, we hypothesized that even at the early childhood stage (as early as 3 years), connectivity between brain regions could decode brain tasks and predict behavioural performance in false-belief tasks. To this end, we proposed an explainable deep learning framework to decode brain states (Theory of Mind and Pain states) and predict individual performance on ToM-related false-belief tasks in a developmental dataset. We proposed an explainable spatiotemporal connectivity-based Graph Convolutional Neural Network (Ex-stGCNN) model for decoding brain tasks. Here, we consider a dataset (age range: 3-12 yrs and adults, samples: 155) in which participants were watching a short, soundless animated movie, ”Partly Cloudy,” that activated Theory-of-Mind (ToM) and pain networks. After scanning, the participants underwent a ToMrelated false-belief task, leading to categorization into the pass, fail, and inconsistent groups based on performance. We trained our proposed model using Static Functional Connectivity (SFC) and Inter-Subject Functional Correlations (ISFC) matrices separately. We observed that the stimulus-driven feature set (ISFC) could capture ToM and Pain brain states more accurately with an average accuracy of 94%, whereas it achieved 85% accuracy using SFC matrices. We also validated our results using five-fold cross-validation and achieved an average accuracy of 92%. Besides this study, we applied the SHAP approach to identify neurobiological brain fingerprints that contributed the most to predictions. We hypothesized that ToM network brain connectivity could predict individual performance on false-belief tasks. We proposed an Explainable Convolutional Variational Auto-Encoder model using functional connectivity (FC) to predict individual performance on false-belief tasks and achieved 90% accuracy."
STASCAN deciphers fine-resolution cell-distribution maps in spatial transcriptomics by deep learning,"Background The spatial transcriptomics (ST) technologies have been widely applied to decode the spatial distribution of cells by resolving gene expression profiles in tissues. However, a fine-resolved spatial cell map is still limited by algorithmic tools and sequencing techniques.Results Here we develop a novel deep learning approach, STASCAN, which could define the spatial cellular distribution of both captured and uncharted areas by cell feature learning that combines gene expression profiles and histology images. STASCAN additionally adopts optional transfer learning and pseudo-labeling methods to improve the accuracy of the cell-type prediction from images. We have successfully applied STASCAN to enhance cell resolution, and revealed finer organizational structures across diverse datasets from various species and tissues generated from 10× Visium technology. STASCAN improves cell resolution of Schmidtea mediterranea datasets by six times and reconstructs more detailed 3D cell-type models. Furthermore, STASCAN could accurately pinpoint the boundaries of distinct cell layers in human intestinal tissue, specifically identify a micrometer-scale smooth muscle bundle structure in consistent with anatomic insights in human lung tissue, and redraw the spatial structural variation with enhanced cell patterns in human myocardial infarction tissue. Additionally, through STASCAN on embryonic mouse brain datasets generated by DBiT-derived MISAR-seq technology, the increased cellular resolution and distinct anatomical tissue domains with cell-type niches are revealed. Collectively, STASCAN is compatible with different ST technologies and has notable advantages in generating cell maps solely from histology images, thereby enhancing the spatial cellular resolution.Conclusions In short, STASCAN displays significant advantages in deciphering higher-resolution cellular distribution, resolving enhanced organizational structures and demonstrating its potential applications in exploring cell-cell interactions within the tissue microenvironment."
Species-specific design of artificial promoters by transfer-learning based generative deep-learning model,"Native prokaryotic promoters share common sequence patterns, but are species dependent. For understudied species with limited data, it is challenging to predict the strength of existing promoters and generate novel promoters. Here, we developed PromoGen, a collection of nucleotide language models to generate species-specific functional promoters, across dozens of species in a data and parameter efficient way. Twenty-seven species-specific models in this collection were finetuned from the pretrained model which was trained on multi-species promoters. When systematically compared with native promoters, the Escherichia coli- and Bacillus subtilis-specific artificial PromoGen-generated promoters (PGPs) were demonstrated to hold all distribution patterns of native promoters. A regression model was developed to score generated either by PromoGen or by another competitive neural network, and the overall score of PGPs is higher. Encouraged by in silico analysis, we further experimentally characterized twenty-two B. subtilis PGPs, results showed that four of tested PGPs reached the strong promoter level while all were active. Furthermore, we developed a user-friendly website to generate species-specific promoters for 27 different species by PromoGen. This work presented an efficient deep-learning strategy for de novo species-specific promoter generation even with limited datasets, providing valuable promoter toolboxes especially for the metabolic engineering of understudied microorganisms."
Small molecules targeting the structural dynamics of AR-V7 partially disordered protein using deep learning and physics based models,"Partially disordered proteins can contain both stable and unstable secondary structure segments and are involved in various (mis)functions in the cell. The extensive conformational dynamics of partially disordered proteins scaling with extent of disorder and length of the protein hampers the efficiency of traditional experimental and in-silico structure-based drug discovery approaches. Therefore new efficient paradigms in drug discovery taking into account conformational ensembles of proteins need to emerge. In this study, using as a test case the AR-V7 transcription factor splicing variant related to prostate cancer, we present an automated methodology that can accelerate the screening of small molecule binders targeting partially disordered proteins. By swiftly identifying the conformational ensemble of AR-V7, and reducing the dimension of binding-sites by a factor of 90 by applying appropriate physicochemical filters, we combine physics based molecular docking and multi-objective classification machine learning models that speed up the screening of thousands of compounds targeting AR-V7 multiple binding sites. Our method not only identifies previously known binding sites of AR-V7, but also discovers new ones, as well as increases the multi-binding site hit-rate of small molecules by a factor of 10 compared to naive physics-based molecular docking."
Predicting Alu exonization in the human genome with a deep learning model,"Alu exonization, or the recruitment of intronic Alu elements into gene sequences, has contributed to functional diversification; however, its extent and the ways in which it influences gene regulation are not fully understood. We developed an unbiased approach to predict Alu exonization events from genomic sequences implemented in a deep learning model, eXAlu, that overcomes the limitations of tissue or condition specificity and the computational burden of RNA-seq analysis. The model captures previously reported characteristics of exonized Alu sequences and can predict sequence elements important for Alu exonization. Using eXAlu, we estimate the number of Alu elements in the human genome undergoing exonization to be between 55-110K, 11-21 fold more than represented in the GENCODE gene database. Using RT-PCR we were able to validate selected predicted Alu exonization events, supporting the accuracy of our method. Lastly, we highlight a potential application of our method to identify polymorphic Alu insertion exonizations in individuals and in the population from whole genome sequencing data."
De novo multi-mechanism antimicrobial peptide design via multimodal deep learning,"ABSTRACTArtificial intelligence (AI)-driven discovery of antimicrobial peptides (AMPs) is yet to fully utilise their three-dimensional (3D) structural characteristics, microbial specie-specific antimicrobial activities and mechanisms. Here, we constructed a QLAPD database comprising the sequence, structures and antimicrobial properties of 12,914 AMPs. QLAPD underlies a multimodal, multitask, multilabel, and conditionally controlled AMP discovery (M3-CAD) pipeline, which is proposed for the de novo design of multi-mechanism AMPs to combat multidrug-resistant organisms (MDROs). This pipeline integrates the generation, regression, and classification modules, using a innovative 3D voxel coloring method to capture the nuanced physicochemical context of amino acids, significantly enhancing structural characterizations. QL-AMP-1, discovered by M3-CAD, which possesses four antimicrobial mechanisms, exhibited low toxicity and significant activity against MDROs. The skin wound infection model demonstrates its considerable antimicrobial effects and negligible toxicity. Altogether, integrating 3D features, specie-specific antimicrobial activities and mechanisms enhanced AI-driven AMP discovery, making the M3-CAD pipeline a viable tool for de novo AMP design."
Deep Learning models for retinal cell classification,"Data analysis is equally important as an experimental part of the scientist’s work. Therefore any reliable automatization would accelerate research. Histology is a good example, where scientists work with different cell types. The difficulty level can be severe while trying to distinguish cell types from one another. In this paper, we focus on the retina. The retina consists of eight basic cell types, creating a layered structure. Some types of cells overlap within the layer, and some differ significantly in size. Fast and thorough manual analysis of the cross-section is impossible. Even though Deep Learning models are applied in multiple domains, we observe little effort to automatize retinal analysis. Therefore, this research aims to create a model for classifying retinal cell types based on morphology in a cross-section of retinal cell images.In this study, we propose a classification Deep Learning model for retinal cell classification. We implemented two models, each tested in three different approaches: Small dataset, Extended dataset, and One cell type vs. All cell types. Although the problem presented to the trained model was simplified, a significant data imbalance was created from multiclass to binary classification, influencing the models’ performance. Both, Sequential and Transfer Learning models performed best with the Extended dataset. The Sequential model generated the best overall results. The obtained results allow us to place prepared models within the benchmark of published models.This paper proposes the first Deep Learning tool classifying retinal cell types based on a dataset prepared from publicly available images collated from multiple sources and images obtained in our laboratory. The multiclass approach with an extended dataset showed the best results. With more effort, the model could become an excellent analytical tool."
Improving genome-scale metabolic models of incomplete genomes with deep learning,"Deciphering the metabolism of microbial species is crucial for understanding their function within complex ecosystems. Genome-scale metabolic models (GSMMs), which predict metabolic traits based on the enzymes encoded in a genome, are promising tools to study microbial ecosystems when genome sequences can be obtained. However, constructing GSMMs for uncultured bacteria is challenging, as metagenome-assembled genomes are typically incomplete, leading to metabolic reconstructions with numerous gaps. Existing methodologies often fill these gaps with the minimum set of reactions necessary to simulate an objective function such as growth. Here we introduce an artificial intelligence-based alternative: the Deep Neural Network Guided Imputation Of Reactomes (DNNGIOR). The DNNGIOR neural network learns weights for missing reactions in incomplete GSMMs from patterns in the presence and absence of metabolic reactions in genomes spanning the bacterial domain. We identified two important factors contributing to prediction accuracy: (1) the frequency of reaction across all bacteria, and (2) the phylogenetic distance between the query and the genomes in the training dataset. Reactions that occur in > 30% of the training genomes can be accurately predicted (Mean F1 score = 0.85). The weights generated by the DNNGIOR network improved the gap-filling of incomplete GSMMs, when assessed on a large and phylogenetically diverse testing dataset and a small set of high-quality manually curated models. The accuracy of DNNGIOR was on average 14 times greater than the standard unweighted gap-filling for draft reconstructions, and 2-9 times greater for manually curated models. DNNGIOR models could also simulate experimentally measured carbon usage profiles with similar accuracy as CarveMe. DNNGIOR is available at https://github.com/MGXlab/DNNGIOR or as a pip package (https://pypi.org/project/dnngior/)."
A Dataset for Deep Learning based Cleavage-stage Blastocyst Prediction with Time-lapse Images,"Recent advances in deep learning and artificial intelligence techniques have obtained notable progress in automated embryo image analysis. However, most current research focuses on blastocyst-stage embryo evaluation (more than 5 days after in vitro fertilization), which may reduce the number of transferable embryos and increase the risk of canceled circles. Therefore, this paper aims to investigate the possibility of evaluating blastocyst development at the cleavage stage with deep neural networks (DNNs). To this end, we collect a dataset that consists of time-lapse images of more than 500 embryos (about 194k frames in total). We evaluate several widely used DNNs on the dataset, including those of single-frame architectures and multi-frame architectures. Experimental results show that the accuracy of different DNNs varies from 66.42% to 77.74% and we also provide the possible reasons behind the performance gap. Our dataset and code will be published soon to facilitate related research."
Deep learning enables accurate soft tissue deformation estimation in vivo,"ABSTRACTImage-based deformation estimation is an important tool used in a variety of engineering problems, including crack propagation, fracture, and fatigue failure. These tools have been instrumental in biomechanics research where measuring in vitro and in vivo tissue deformations help evaluate tissue health and disease progression. However, accurately measuring tissue deformation in vivo is particularly challenging due to limited image signal-to-noise ratio. Therefore, we created a novel deep-learning approach for measuring deformation from a sequence of in vivo images called StrainNet. Utilizing a training dataset that incorporates image artifacts, StrainNet was designed to maximize performance in challenging in vivo settings. Artificially generated image sequences of human flexor tendons undergoing known deformations were used to compare StrainNet against two conventional image-based strain measurement techniques. StrainNet outperformed the traditional techniques by nearly 90%. High-frequency ultrasound imaging was then used to acquire images of the flexor tendons engaged during contraction. Only StrainNet was able to track tissue deformations under the in vivo test conditions. Findings revealed strong correlations between tendon deformation and contraction effort, highlighting the potential for StrainNet to be a valuable tool for assessing preventative care, rehabilitation strategies, or disease progression. Additionally, by using real-world data to train our model, StrainNet was able to generalize and reveal important relationships between the effort exerted by the participant and tendon mechanics. Overall, StrainNet demonstrated the effectiveness of using deep learning for image-based strain analysis in vivo."
A deep learning-based toolkit for 3D nuclei segmentation and quantitative analysis in cellular and tissue context,"We present a new set of computational tools that enable accurate and widely applicable 3D segmentation of nuclei in various 3D digital organs. We developed a novel approach for ground truth generation and iterative training of 3D nuclear segmentation models, which we applied to popular CellPose, PlantSeg, and StarDist algorithms. We provide two high-quality models trained on plant nuclei that enable 3D segmentation of nuclei in datasets obtained from fixed or live samples, acquired from different plant and animal tissues, and stained with various nuclear stains or fluorescent protein-based nuclear reporters. We also share a diverse high-quality training dataset of about 10,000 nuclei. Furthermore, we advanced the MorphoGraphX analysis and visualization software by, among other things, providing a method for linking 3D segmented nuclei to their surrounding cells in 3D digital organs. We found that the nuclear-to-cell volume ratio varies between different ovule tissues and during the development of a tissue. Finally, we extended the PlantSeg 3D segmentation pipeline with a proofreading script that uses 3D segmented nuclei as seeds to correct cell segmentation errors in difficult-to-segment tissues.Summary Statement We present computational tools that allow versatile and accurate 3D nuclear segmentation in plant organs, enable the analysis of cell-nucleus geometric relationships, and improve the accuracy of 3D cell segmentation."
Estimating protein-ligand interactions with geometric deep learning and mixture density models,"Understanding the interactions between a ligand and its molecular target is crucial in guiding the optimization of molecules for any in-silico drug-design workflow. Multiple experimental and computational methods have been developed to better understand these intermolecular interactions. With the availability of a large number of structural datasets, there is a need for developing statistical frameworks that improve upon existing physics-based solutions. Here, we report a method based on geometric deep learning that is capable of predicting the binding conformations of ligands to protein targets. A technique to generate graphical representations of protein was developed to exploit the topological and electrostatic properties of the binding region. The developed framework, based on graph neural networks, learns a statistical potential based on the distance likelihood, which is tailor-made for each ligand–target pair. This potential can be coupled with global optimization algorithms such as differential evolution to reproduce the experimental binding conformations of ligands. We show that the potential based on distance likelihood, described here, performs similarly or better than well-established scoring functions for docking and screening tasks. Overall, this method represents an example of how artificial intelligence can be used to improve structure-based drug design.Significance statement Current machine learning-based solutions to model protein-ligand interactions lack the level of interpretability that physics-based methods usually provide. Here, a workflow to embed protein binding surfaces as graphs was developed to serve as a viable data structure to be processed by geometric deep learning. The developed architecture based on mixture density models was employed to accurately estimate the position and conformation of the small molecule within the binding region. The likelihood-based scoring function was compared against existing physics-based alternatives, and significant performance improvements in terms of docking power, screening power and reverse screening power were observed. Taken together, the developed framework provides a platform for utilising geometric deep-learning models for interpretable prediction of protein-ligand interactions at a residue level."
Multimodal CustOmics: A Unified and Interpretable Multi-Task Deep Learning Framework for Multimodal Integrative Data Analysis in Oncology,"ABSTRACTCharacterizing cancer poses a delicate challenge as it involves deciphering complex biological interactions within the tumor’s microenvironment. Histology images and molecular profiling of tumors are often available in clinical trials and can be leveraged to understand these interactions. However, despite recent advances in representing multimodal data for weakly supervised tasks in the medical domain, numerous challenges persist in achieving a coherent and interpretable fusion of whole slide images and multi-omics data. Each modality operates at distinct biological levels, introducing substantial correlations both between and within data sources. In response to these challenges, we propose a deep-learning-based approach designed to represent multimodal data for precision medicine in a readily interpretable manner. While demonstrating superior performance compared to state-of-the-art methods across multiple test cases, our approach also provides robust results and extracts various scores characterizing the activity of each modality and their interactions at the pathway and gene levels. The strength of our method lies in its capacity to unravel pathway activation through multimodal relationships and extend enrichment analysis to spatial data for supervised tasks. We showcase the efficiency and robustness of its predictive capacity and interpretation scores through an extensive exploration of multiple TCGA datasets and validation cohorts, underscoring its value in advancing our understanding of cancer. The method is publicly available in Github."
ANTIPASTI: interpretable prediction of antibody binding affinity exploiting Normal Modes and Deep Learning,"SummaryThe high binding affinity of antibodies towards their cognate targets is key to eliciting effective immune responses, as well as to the use of antibodies as research and therapeutic tools. Here, we propose ANTIPASTI, a Convolutional Neural Network model that achieves state-of-the-art performance in the prediction of antibody binding affinity using as input a representation of antibody-antigen structures in terms of Normal Mode correlation maps derived from Elastic Network Models. This representation captures not only structural features but energetic patterns of local and global residue fluctuations. The learnt representations are interpretable: they reveal similarities of binding patterns among antibodies targeting the same antigen type, and can be used to quantify the importance of antibody regions contributing to binding affinity. Our results show the importance of the antigen imprint in the Normal Mode landscape, and the dominance of cooperative effects and long-range correlations between antibody regions to determine binding affinity."
Exploring “dark matter” protein folds using deep learning,"De novo protein design aims to explore uncharted sequence-and structure areas to generate novel proteins that have not been sampled by evolution. One of the main challenges in de novo design involves crafting “designable” structural templates that can guide the sequence search towards adopting the target structures. Here, we present an approach to learn patterns of protein structure based on a convolutional variational autoencoder, dubbed Genesis. We coupled Genesis with trRosetta to design sequences for a set of protein folds and found that Genesis is capable of reconstructing native-like distance-and angle distributions for five native folds and three novel, so-called “dark-matter” folds as a demonstration of generalizability. We used a high-throughput assay to characterize protease resistance of the designs, obtaining encouraging success rates for folded proteins and further biochemically characterized folded designs. The Genesis framework enables the exploration of the protein sequence and fold space within minutes and is not bound to specific protein topologies. Our approach addresses the backbone designability problem, showing that structural patterns in proteins can be efficiently learned by small neural networks and could ultimately contribute to the de novo design of proteins with new functions."
Deep learning-enhanced single-molecule spectrum imaging,"Fluorescence is widely used in biological imaging and biosensing. Rich information can be revealed from the fluorescence spectrum of fluorescent molecules, such as pH, viscosity and polarity of the molecule’s environment, and distance between two FRET molecules. However, constructing the fluorescence spectrum of a single fluorescent molecule typically requires a significant number of photons, which can suffer from photobleaching and therefore limit its potential applications. Here we propose a deep learning-enhanced single-molecule spectrum imaging method (SpecGAN) for improving the single-molecule spectrum imaging efficiency. In SpecGAN, the photon flux required to extract a single-molecule fluorescence spectrum can be reduced by 100 times, which enables it two orders of magnitude higher temporal resolution compared to the conventional single-molecule spectrometer. The concept of SpecGAN was validated through numerical simulation and single Nile Red molecule spectrum imaging on support lipid bilayers (SLBs). With SpecGAN, the super-resolution spectrum image of the COS-7 membrane can be reconstructed with merely 12,000 frames of single-molecule localization images, which is almost half of the previously reported frame count for spectrally resolved super-resolution imaging. The low photon flux requirement and high temporal resolution of SpecGAN make it a promising tool for investigating the molecular spectrum dynamics related to biological functions or biomolecule interactions."
Deep learning models to map osteocyte networks can successfully distinguish between young and aged bone,"Osteocytes, the most abundant and mechanosensitive cells in bone tissue, play a pivotal role in bone homeostasis and mechano-responsiveness, orchestrating the intricate balance between bone formation and resorption under daily activity. Studying osteocyte connectivity and understanding their intricate arrangement within the lacunar canalicular network (LCN) is essential for unraveling bone physiology. This is particularly true as our bones age, which is associated with decreased integrity of the osteocyte network, disrupted mass transport, and lower sensitivity to the mechanical stimuli that allow the skeleton to adapt to changing demands. Much work has been carried out to investigate this relationship, often involving high resolution microscopy of discrete fragments of this network, alongside advanced computational modelling of individual cells. However, traditional methods of segmenting and measuring osteocyte connectomics are time-consuming and labour-intensive, often hindered by human subjectivity and limited throughput. In this study, we explore the application of deep learning and computer vision techniques to automate the segmentation and measurement of osteocyte connectomics, enabling more efficient and accurate analysis. We compare several state-of-the-art computer vision models (U-Nets and Vision Transformers) to successfully segment the LCN, finding that an Attention U-Net model can accurately segment and measure 81.8% of osteocytes and 42.1% of dendritic processes, when compared to manual labelling. While further development is required, we demonstrate that this degree of accuracy is already sufficient to distinguish between bones of young (2 month old) and aged (36 month old) mice, as well as capturing the degeneration induced by genetic modification of osteocytes. By harnessing the power of these advanced technologies, further developments can unravel the complexities of osteocyte networks in unprecedented detail, revolutionising our understanding of bone health and disease."
PandoGen: Generating complete instances of future SARS-CoV-2 sequences using Deep Learning,"One of the challenges in a viral pandemic is the emergence of novel variants with different phenotypical characteristics. An ability to forecast future viral individuals at the sequence level enables advance preparation by characterizing the sequences and closing vulnerabilities in current preventative and therapeutic methods. In this article, we explore, in the context of a viral pandemic, the problem of generating complete instances of undiscovered viral protein sequences, which have a high likelihood of being discovered in the future using protein language models. Current approaches to training these models fit model parameters to a known sequence set, which does not suit pandemic forecasting as future sequences differ from known sequences in some respects. To address this, we develop a novel method, called PandoGen, to train protein language models towards the pandemic protein forecasting task. PandoGen combines techniques such as synthetic data generation, conditional sequence generation, and reward-based learning, enabling the model to forecast future sequences, with a high propensity to spread. Applying our method to modeling the SARS-CoV-2 Spike protein sequence, we find empirically that our model forecasts twice as many novel sequences with five times the case counts compared to a model that is thirty times larger. Our method forecasts unseen lineages months in advance, whereas models 4× and 30× larger forecast almost no new lineages. When trained on data available up to a month before the onset of important Variants of Concern, our method consistently forecasts sequences belonging to those variants within tight sequence budgets.PandoGen is available at: https://github.com/UIUC-ChenLab/PandoGen"
Drug Response Prediction and Biomarker Discovery Using Multi-Modal Deep Learning,"A major challenge in cancer care is that patients with similar demographics, tumor types, and medical histories can respond quite differently to the same drug regimens. This difference is largely explained by genetic and other molecular variabilities among the patients and their cancers. Efforts in the pharmacogenomics field are underway to understand better the relationship between the genome of the patient’s healthy and tumor cells and their response to therapy. To advance this goal, research groups and consortia have undertaken large-scale systematic screening of panels of drugs across multiple cancer cell lines that have been molecularly profiled by genomics, proteomics, and similar techniques. These large data drug screening sets have been applied to the problem of drug response prediction (DRP), the challenge of predicting the response of a previously untested drug/cell-line combination. Although deep learning algorithms outperform traditional methods, there are still many challenges in DRP that ultimately result in these models’ low generalizability and hampers their clinical application. In this paper, we describe a novel algorithm that addresses the major shortcomings of current DRP methods by combining multiple cell line characterization data, addressing drug response data skewness, and improving chemical compound representation. The result is an open-source, Python-based, command-line program available at https://github.com/LincolnSteinLab/MMDRP."
The discovery of antimicrobial peptides from the gut microbiome of cockroach Blattella germanica using deep learning pipeline,"Antimicrobial peptides (AMPs) are candidates for use against antibiotic-resistant microorganisms. However, due to high cytotoxicity and poor performance in biological contexts, most AMPs are unable to satisfy the requirements. The gut microbiomes of pathogenic species like Blattella germanica represent unexploited reservoirs of naturally evolved biocompatible AMPs. Here we developed a lightweight AI pipeline called AMPidentifer with two nine-layers Dense-Net blocks and one embedded new self-attention module to enable the discovery of biocompatible AMPs from microbiome. The core structure of AMPidentifer is simple, not requiring complexing code basis. On the independent test dataset, it showed robust performance and avoided high false-positive results. From the gut microbiome of B. germanica, new AMP candidates with potential low toxicities and antimicrobial activities were identified by AMPidentifer. The selected two AMPs demonstrated good antimicrobial effects in vitro and in vivo. The Cys residue was demonstrated to perform different action mechanisms in the antimicrobial activity of two AMPs, providing insights for future rational design. New efficient AMPs with low cytotoxicity identified by the new high-throughput AI pipeline from the gut microbiome of B. germanica successfully showed an important interdisciplinary strategy for discovering bio-safe AMPs from nature.Download figureOpen in new tabThe Graphic Abstract"
Spatial landmark detection and tissue registration with deep learning,"Spatial landmarks are crucial in describing histological features between samples or sites, tracking regions of interest in microscopy, and registering tissue samples within a common coordinate framework. Although other studies have explored unsupervised landmark detection, existing methods are not well-suited for histological image data as they often require a large number of images to converge, are unable to handle non-linear deformations between tissue sections, and are ineffective for z-stack alignment, other modalities beyond image data, or multimodal data. We address these challenges by introducing a new landmark detection and registration method, utilizing neural-network-guided thin-plate splines. Our proposed method is evaluated on a diverse range of datasets, demonstrating superior performance in both accuracy and stability compared to existing approaches."
Evaluating Augmentation Approaches for Deep Learning-based Major Depressive Disorder Diagnosis with Raw Electroencephalogram Data*,"While deep learning methods are increasingly applied in research contexts for neuropsychiatric disorder diagnosis, small dataset size limits their potential for clinical translation. Data augmentation (DA) could address this limitation, but the utility of EEG DA methods remains relatively underexplored in neuropsychiatric disorder diagnosis. In this study, we train a model for major depressive disorder diagnosis. We then evaluate the utility of 6 EEG DA approaches. Importantly, to remove the bias that could be introduced by comparing performance for models trained on larger augmented training sets to models trained on smaller baseline sets, we also introduce a new baseline trained on duplicate training data to better. We lastly examine the effects of the DA approaches upon representations learned by the model with a pair of explainability analyses. We find that while most approaches boost model performance, they do not improve model performance beyond that of simply using a duplicate training set without DA. The exception to this is channel dropout augmentation, which does improve model performance. These findings suggest the importance of comparing EEG DA methods to a baseline with a duplicate training set of equal size to the augmented training set. We also found that some DA methods increased model robustness to frequency (Fourier transform surrogates) and channel (channel dropout) perturbation. While our findings on EEG DA efficacy are restricted to our dataset and model, we hope that future studies on deep learning for small EEG datasets and on new EEG DA methods will find our findings helpful."
Unbiased Complete Estimation of Chloroplast Number in Plant Cells Using Deep Learning Methods,"Chloroplasts are essential organelles in plants that are involved in plant development and photosynthesis. Accurate quantification of chloroplast numbers is important for understanding the status and type of plant cells, as well as assessing photosynthetic potential and efficiency. Traditional methods of counting chloroplasts using microscopy are time-consuming and face challenges such as the possibility of missing out-of-focus samples or double counting when adjusting the focal position. Here, we developed an innovative approach called Detecting- and-Counting-chloroplasts (D&Cchl) for automated detection and counting of chloroplasts. This approach utilizes a deep-learning-based object detection algorithm called You-Only-Look-Once (YOLO), along with the Intersection Over Union (IOU) strategy. The application of D&Cchl has shown excellent performance in accurately identifying and quantifying chloroplasts. This holds true when applied to both a single image and a three-dimensional (3D) structure composed of a series of images. Furthermore, by integrating Cellpose, a cell-segmentation tool, we were able to successfully perform single-cell 3D chloroplast counting. Compared to manual counting methods, this approach improved the accuracy of detection and counting to over 95%. Together, our work not only provides an efficient and reliable tool for accurately analyzing the status of chloroplasts, enhancing our understanding of plant photosynthetic cells and growth characteristics, but also makes a significant contribution to the convergence of botany and deep learning.One-sentence summary This deep learning-based approach enables the accurate complete detection and counting of chloroplasts in 3D single cells using microscopic image stacks, and showcases a successful example of utilizing deep learning methods to analyze subcellular spatial information in plant cells.The authors responsible for distribution of materials integral to the findings presented in this article in accordance with the policy described in the Instructions for Authors (https://academic.oup.com/plcell/) is: Zhao Dong (dongzhao{at}hebeu.edu.cn), Shaokai Yang, (shaokai1{at}ualberta.ca), Ningjing Liu (liuningjing1{at}yeah.net), and Qiong Zhao (qzhao{at}bio.ecnu.edu.cn)."
DeepPBS: Geometric deep learning for interpretable prediction of protein–DNA binding specificity,"Predicting specificity in protein-DNA interactions is a challenging yet essential task for understanding gene regulation. Here, we present Deep Predictor of Binding Specificity (DeepPBS), a geometric deep-learning model designed to predict binding specificity across protein families based on protein-DNA structures. The DeepPBS architecture allows investigation of different family-specific recognition patterns. DeepPBS can be applied to predicted structures, and can aid in the modeling of protein-DNA complexes. DeepPBS is interpretable and can be used to calculate protein heavy atom-level importance scores, demonstrated as a case-study on p53-DNA interface. When aggregated at the protein residue level, these scores conform well with alanine scanning mutagenesis experimental data. The inference time for DeepPBS is sufficiently fast for analyzing simulation trajectories, as demonstrated on a molecular-dynamics simulation of a Drosophila Hox-DNA tertiary complex with its cofactor. DeepPBS and its corresponding data resources offer a foundation for machine-aided protein-DNA interaction studies, guiding experimental choices and complex design, as well as advancing our understanding of molecular interactions."
Finding and Following: A deep learning-based pipeline for tracking platelets during thrombus formation in vivo and ex vivo,"The last decade has seen increasing use of advanced imaging techniques in platelet research. However, there has been a lag in the development of image analysis methods, leaving much of the information trapped in images. Herein, we present a robust analytical pipeline for finding and following individual platelets over time in growing thrombi. Our pipeline covers four steps: detection, tracking, estimation of tracking accuracy, and quantification of platelet metrics. We detect platelets using a deep learning network for image segmentation, which we validated with proofreading by multiple experts. We then track platelets using a standard particle tracking algorithm and validate the tracks with custom image sampling — essential when following platelets within a dense thrombus. We show that our pipeline is more accurate than previously described methods. To demonstrate the utility of our analytical platform, we use it to show that in vivo thrombus formation is much faster than that ex vivo. Furthermore, platelets in vivo exhibit less passive movement in the direction of blood flow. Our tools are free and open source and written in the popular and user-friendly Python programming language. They empower researchers to accurately find and follow platelets in fluorescence microscopy experiments.xPlain language summary In this paper we describe computational tools to find and follow individual platelets in blood clots recorded with fluorescence microscopy. Our tools work in a diverse range of conditions, both in living animals and in artificial flow chamber models of thrombosis. Our work uses deep learning methods to achieve excellent accuracy. We also provide tools for visualising data and estimating error rates, so you don’t have to just trust the output. Our workflow measures platelet density, shape, and speed, which we use to demonstrate differences in the kinetics of clotting in living vessels versus a synthetic environment. The tools we wrote are open source, written in the popular Python programming language, and freely available to all. We hope they will be of use to other platelet researchers."
Imputation of label-free quantitative mass spectrometry-based proteomics data using self-supervised deep learning,"Imputation techniques provide means to replace missing measurements with a value and are used in almost all downstream analysis of mass spectrometry (MS) based proteomics data using label-free quantification (LFQ). Here we demonstrate how collaborative filtering, denoising autoencoders, and variational autoencoders can impute missing values in the context of LFQ at different levels. We applied our method, proteomics imputation modeling mass spectrometry (PIMMS), to an alcohol-related liver disease (ALD) cohort with blood plasma proteomics data available for 358 individuals. Removing 20 percent of the intensities we were able to recover 15 out of 17 significant abundant protein groups using PIMMS-VAE imputations. When analyzing the full dataset we identified 30 additional proteins (+13.2%) that were significantly differentially abundant across disease stages compared to no imputation and found that some of these were predictive of ALD progression in machine learning models. We, therefore, suggest the use of deep learning approaches for imputing missing values in MS-based proteomics on larger datasets and provide workflows for these."
Deep Learning for Predicting 16S rRNA Gene Copy Number,"ABSTRACTBackground Culture-independent 16S rRNA gene metabarcoding is a commonly used method in microbiome profiling. However, this approach can only reflect the proportion of sequencing reads, rather than the actual cell fraction. To achieve more quantitative cell fraction estimates, we need to resolve the 16S gene copy numbers (GCN) for different community members. Currently, there are several bioinformatic tools available to estimate 16S GCN, either based on taxonomy assignment or phylogeny.Method Here we develop a novel algorithm, Stacked Ensemble Model (SEM), that estimates 16S GCN directly from the 16S rRNA gene sequence strings, without resolving taxonomy or phylogeny. For accessibility, we developed a public, end-to-end, web-based tool based on the SEM model, named Artificial Neural Network Approximator for 16S rRNA Gene Copy Number (ANNA16).Results Based on 27,579 16S rRNA gene sequence data (rrnDB database), we show that ANNA16 outperforms the most commonly used 16S GCN prediction algorithms. The prediction error range in the 5-fold cross validation of SEM is completely lower than all other algorithms for the 16S full-length sequence and partially lower at 16S subregions. The final test and a mock community test indicate ANNA16 is more accurate than all currently available tools (i.e., rrnDB, CopyRighter, PICRUSt2, & PAPRICA). SHAP value analysis indicates ANNA16 mainly learns information from rare insertions.Conclusion ANNA16 represents a deep learning based 16S GCN prediction tool. Compared to the traditional GCN prediction tools, ANNA16 has a simple structure, faster inference speed without precomputing, and higher accuracy. With increased 16S GCN data in the database, future studies could improve the prediction errors for rare, high-GCN taxa due to current under sampling."
Automated staging of zebrafish embryos with deep learning,"The zebrafish (Danio rerio), is an important biomedical model organism used in many disciplines. The phenomenon of developmental delay in zebrafish embryos has been widely reported as part of a mutant or treatment-induced phenotype. However, the detection and quantification of these delays is often achieved through manual observation with reference to staging guides, which is both time-consuming and subjective. We recently reported a machine learning-based classifier, capable of quantifying the developmental delay between two populations of zebrafish embryos. Here, we build on that work by introducing a deep learning-based model (KimmelNet) that has been trained to predict the age (hours post fertilisation) of populations of zebrafish embryos. We show that when KimmelNet is tested on 2D brightfield images of zebrafish embryos, the predictions generated agree closely with those expected from established approaches to staging. Random sampling of the test data demonstrate that KimmelNet can be used to detect developmental delay between two populations with high confidence based on as few as 100 images of each population. Finally, we show that KimmelNet generalises to previously unseen data, with limited transfer learning improving this performance significantly. With the ability to analyse tens of thousands of standard brightfield microscopy images on a timescale of minutes, we envisage that KimmelNet will be a valuable resource for the developmental biology community. Furthermore, the approach we have used could easily be adapted to generate models for other organisms."
Translating deep learning to neuroprosthetic control,"Advances in deep learning have given rise to neural network models of the relationship between movement and brain activity that appear to far outperform prior approaches. Brain-computer interfaces (BCIs) that enable people with paralysis to control external devices, such as robotic arms or computer cursors, might stand to benefit greatly from these advances. We tested recurrent neural networks (RNNs) on a challenging nonlinear BCI problem: decoding continuous bimanual movement of two computer cursors. Surprisingly, we found that although RNNs appeared to perform well in offline settings, they did so by overfitting to the temporal structure of the training data and failed to generalize to real-time neuroprosthetic control. In response, we developed a method that alters the temporal structure of the training data by dilating/compressing it in time and re-ordering it, which we show helps RNNs successfully generalize to the online setting. With this method, we demonstrate that a person with paralysis can control two computer cursors simultaneously, far outperforming standard linear methods. Our results provide evidence that preventing models from overfitting to temporal structure in training data may, in principle, aid in translating deep learning advances to the BCI setting, unlocking improved performance for challenging applications."
Deep learning-based location decoding reveals that across-day representational drift is better predicted by rewarded experience than time,"ABSTRACTNeural representations of space in the hippocampus and related brain areas change over timescales of days-weeks, even in familiar contexts and when behavior appears stable. It is unclear whether this ‘representational drift’ is primarily driven by the passage of time or by behavioral experience. Here we present a novel deep-learning approach for measuring network-level representational drift, quantifying drift as the rate of change in decoder error of deep neural networks as a function of train-test lag. Using this method, we analyse a longitudinal dataset of 0.5–475 Hz broadband local field potential (LFP) data recorded from dorsal hippocampal CA1, medial prefrontal cortex and parietal cortex of six rats over ∼30 days, during learning of a spatial navigation task in an unfamiliar environment. All three brain regions contained clear spatial representations which improve and drift over training sessions. We find that the rate of drift slows for later training sessions. Finally, we find that drift is statistically better explained by task-relevant rewarded experiences within the maze, rather than the passage of time or number of sessions the animal spent on the maze. Our use of deep neural networks to quantify drift in broadband neural time series unlocks new possibilities for testing which aspects of behavior drive representational drift."
Inferring Metabolic States from Single Cell Transcriptomic Data via Geometric Deep Learning,"The ability to measure gene expression at single-cell resolution has elevated our understanding of how biological features emerge from complex and interdependent networks at molecular, cellular, and tissue scales. As technologies have evolved that complement scRNAseq measurements with things like single-cell proteomic, epigenomic, and genomic information, it becomes increasingly apparent how much biology exists as a product of multimodal regulation. Biological processes such as transcription, translation, and post-translational or epigenetic modification impose both energetic and specific molecular demands on a cell and are therefore implicitly constrained by the metabolic state of the cell. While metabolomics is crucial for defining a holistic model of any biological process, the chemical heterogeneity of the metabolome makes it particularly difficult to measure, and technologies capable of doing this at single-cell resolution are far behind other multiomics modalities. To address these challenges, we present GEFMAP (Gene Expression-based Flux Mapping and Metabolic Pathway Prediction), a method based on geometric deep learning for predicting flux through reactions in a global metabolic network using transcriptomics data, which we ultimately apply to scRNAseq. GEFMAP leverages the natural graph structure of metabolic networks to learn both a biological objective for each cell and estimate a mass-balanced relative flux rate for each reaction in each cell using novel deep learning models."
DeePNAP: A deep learning method to predict protein-nucleic acids binding affinity from sequence,"ABSTRACTPredicting the protein-nucleic acid (PNA) binding affinity solely from their sequences is of paramount importance for the experimental design and analysis of PNA interactions (PNAIs). A large number of currently developed models for binding affinity prediction are limited to specific PNAIs, while also relying on both sequence and structural information of the PNA complexes for both train/test and also as inputs. As PNA complex structures available are scarce, this significantly limits the diversity and generalizability due to a small training dataset. Additionally, a majority of the tools predict a single parameter such as binding affinity or free energy changes upon mutations, rendering a model less versatile for usage. Hence, we propose DeePNAP, a machine learning-based model trained on a vast and heterogeneous dataset with 14,401 entries (from both eukaryotes and prokaryotes) of ProNAB database, consisting of wild-type and mutant PNA complex binding parameters. Our model precisely predicts the binding affinity and free energy changes due to the mutation(s) of PNAIs exclusively from the sequences. While other similar tools extract features from both sequence and structure information, DeePNAP employs sequence-based features to yield high correlation coefficients between the predicted and experimental values with low root mean squared errors for PNA complexes in predicting the KD and ΔΔG implying the generalizability of DeePNAP. Additionally, we have also developed a web interface hosting DeePNAP that can serve as a powerful tool to rapidly predict binding affinities for a myriad of PNAIs with high precision toward developing a deeper understanding of their implications in various biological systems. Web interface: http://14.139.174.41:8080/"
Deep Learning-based structural and functional annotation of Pandoravirus hypothetical proteins,"Giant viruses, including Pandoraviruses, contain large amounts of genomic ‘dark matter’ - genes encoding proteins of unknown function. New generation, deep learning-based protein structure modelling offers new opportunities to apply structure-based function inference to these sequences, often labelled as hypothetical proteins. However, the AlphaFold Protein Structure Database, a convenient resource covering the majority of UniProt, currently lacks models for most viral proteins. Here, we apply a panoply of predictive methods to protein structure predictions representative of large clusters of hypothetical proteins shared among four Pandoraviruses. In several cases, strong functional predictions can be made. Thus, we identify a likely nucleotidyltransferase putatively involved in viral tRNA maturation that has a BTB domain presumably involved in protein-protein interactions. We further identify a cluster of membrane channel sequences presenting three paralogous families which may, as seen in other giant viruses, induce host cell membrane depolarization. And we identify homologues of calcium-activated potassium channel beta subunits and pinpoint their likely Acanthamoeba cellular alpha subunit counterparts. Despite these successes, many other clusters remain cryptic, having folds that are either too functionally promiscuous or too novel to provide strong clues as to their role. These results suggest that significant structural and functional novelty remains to be uncovered in the giant virus proteomes."
Decoding multi-limb movements from low temporal resolution calcium imaging using deep learning,"SummaryTwo-photon imaging has been a critical tool for dissecting brain circuits and understanding brain function. However, relating slow two-photon calcium imaging data to fast behaviors has been challenging due to relatively low imaging sampling rates, thus limiting potential applications to neural prostheses. Here, we show that a recurrent encoder-decoder network with an output length longer than the input length can accurately decode limb trajectories of a running mouse from two-photon calcium imaging data. The encoder-decoder model could accurately decode information about all four limbs (contralateral and ipsilateral front and hind limbs) from calcium imaging data recorded in a single cortical hemisphere. Furthermore, neurons that were important for decoding were found to be well-tuned to both ipsilateral and contralateral limb movements, showing that artificial neural networks can be used to understand the function of the brain by identifying sub-networks of neurons that correlate with behaviors of interest."
Comparison and benchmark of deep learning methods for non-coding RNA classification,"The grouping of non-coding RNAs into functional classes started in the 1950s with housekeeping RNAs. Since, multiple additional classes were described. The involvement of non-coding RNAs in biological processes and diseases has made their characterization crucial, creating a need for computational methods that can classify large sets of non-coding RNAs. In recent years, the success of deep learning in various domains led to its application to non-coding RNA classification. Multiple novel architectures have been developed, but these advancements are not covered by current literature reviews. We propose a comparison of the different approaches and of non-coding RNA datasets proposed in the state-of-the-art. Then, we perform experiments to fairly evaluate the performance of various tools for non-coding RNA classification on two popular datasets. With regard to these results, we assess the relevance of the different architectural choices and provide recommendations to consider in future methods."
Piscis: a novel loss estimator of the F1 score enables accurate spot detection in fluorescence microscopy images via deep learning,"Single-molecule RNA fluorescence in situ hybridization (RNA FISH)-based spatial transcriptomics methods have enabled the accurate quantification of gene expression at single-cell resolution by visualizing transcripts as diffraction-limited spots. While these methods generally scale to large samples, image analysis remains challenging, often requiring manual parameter tuning. We present Piscis, a fully automatic deep learning algorithm for spot detection trained using a novel loss function, the SmoothF1 loss, that approximates the F1 score to directly penalize false positives and false negatives but remains differentiable and hence usable for training by deep learning approaches. Piscis was trained and tested on a diverse dataset composed of 358 manually annotated experimental RNA FISH images representing multiple cell types and 240 additional synthetic images. Piscis outperforms other state-of-the-art spot detection methods, enabling accurate, high-throughput analysis of RNA FISH-derived imaging data without the need for manual parameter tuning."
ODL-BCI: Optimal deep learning model for brain-computer interface to classify students confusion via hyperparameter tuning,"Brain-computer interface (BCI) research has gained increasing attention in educational contexts, offering the potential to monitor and enhance students’ cognitive states. Real-time classification of students’ confusion levels using electroencephalogram (EEG) data presents a significant challenge in this domain. Since real-time EEG data is dynamic and highly dimensional, current approaches have some limitations for predicting mental states based on this data. This paper introduces an optimal deep learning (DL) model for the BCI, ODL-BCI, optimized through hyperparameter tuning techniques to address the limitations of classifying students’ confusion in real time. Leveraging the “confused student EEG brainwave” dataset, we employ Bayesian optimization to fine-tune hyperparameters of the proposed DL model. The model architecture comprises input and output layers, with several hidden layers whose nodes, activation functions, and learning rates are determined utilizing selected hyperparameters. We evaluate and compare the proposed model with some state-of-the-art methods and standard machine learning (ML) classifiers, including Decision Tree, AdaBoost, Bagging, MLP, Näıve Bayes, Random Forest, SVM, and XG Boost, on the EEG confusion dataset. Our experimental results demonstrate the superiority of the optimized DL model, ODL-BCI. It boosts the accuracy between 4% and 9% over the current approaches, outperforming all other classifiers in the process. The ODL-BCI implementation source codes can be accessed by anyone at https://github.com/MdOchiuddinMiah/ODL-BCI."
Adaptive stretching of representations across brain regions and deep learning model layers,"Prefrontal cortex (PFC) is known to modulate the visual system to favor goal-relevant information by accentuating task-relevant stimulus dimensions. Does the brain broadly re-configures itself to optimize performance by stretching visual representations along task-relevant dimensions? We considered a task that required monkeys to selectively attend on a trial-by-trial basis to one of two dimensions (color or motion direction) to make a decision. Except for V4 (color bound) and MT (motion bound), the brain radically re-configured itself to stretch representations along task-relevant dimensions in lateral PFC, frontal eye fields (FEF), lateral intraparietal cortex (LIP), and inferotemporal cortex (IT). Spike timing was crucial to this code. A deep learning model was trained on the same visual input and rewards as the monkeys. Despite lacking an explicit selective attention or other control mechanism, the model displayed task-relevant stretching as a consequence of error minimization, indicating that stretching is an adaptive strategy."
Multimodal generation of astrocyte by integrating single-cell multi-omics data via deep learning,"ABSTRACTObtaining positive and negative samples to examining several multifaceted brain diseases in clinical trials face significant challenges. We propose an innovative approach known as Adaptive Conditional Graph Diffusion Convolution (ACGDC) model. This model is tailored for the fusion of single cell multi-omics data and the creation of novel samples. ACGDC customizes a new array of edge relationship categories to merge single cell sequencing data and pertinent meta-information gleaned from annotations. Afterward, it employs network node properties and neighborhood topological connections to reconstruct the relationship between edges and their properties among nodes. Ultimately, it generates novel single-cell samples via inverse sampling within the framework of conditional diffusion model. To evaluate the credibility of the single cell samples generated through the new sampling approach, we conducted a comprehensive assessment. This assessment included comparisons between the generated samples and real samples across several criteria, including sample distribution space, enrichment analyses (GO term, KEGG term), clustering, and cell subtype classification, thereby allowing us to rigorously validate the quality and reliability of the single-cell samples produced by our novel sample method. The outcomes of our study demonstrated the effectiveness of the proposed method in seamlessly integrating single-cell multi-omics data and generating innovative samples that closely mirrored both the spatial distribution and bioinformatic significance observed in real samples. Thus, we suggest that the generation of these reliable control samples by ACGDC holds substantial promise in advancing precision research on brain diseases. Additionally, it offers a valuable tool for classifying and identifying astrocyte subtypes.

Download figureOpen in new tab"
Inferring Disease Progressive Stages in Single-Cell Transcriptomics Using Weakly-Supervised Deep Learning Approach,"Background Application of single-cell/nucleus genomic sequencing to patient-derived tissues offers potential solutions to delineate disease mechanisms in human. However, individual cells in patient-derived tissues are in different pathological stages, and hence such cellular variability impedes subsequent differential gene expression analyses.Result To overcome such heterogeneity issue, we present a novel deep learning approach, scIDST, that infers disease progressive levels of individual cells with weak supervision framework. The inferred disease progressive cells displayed significant differential expression of disease-relevant genes, which could not be detected by comparative analysis between patients and healthy donors. In addition, we demonstrated that pre-trained models by scIDST are applicable to multiple independent data resources, and advantageous to infer cells related to certain disease risks and comorbidities.Conclusion Taken together, scIDST offers a new strategy of single-cell sequencing analysis to identify bona fide disease-associated molecular features."
Ridge regression baseline model outperforms deep learning method for cancer genetic dependency prediction,"Accurately predicting genetic or other cellular vulnerabilities of unscreened, or difficult to screen, cancer samples will allow vast advancements in precision oncology. We re-analyzed a recently published deep learning method for predicting cancer genetic dependencies from their omics profiles. After implementing a ridge regression baseline model with an alternative, simplified problem setup, we achieved a model that outperforms the original deep learning method. Our study demonstrates the importance of problem formulation in machine learning applications and underscores the need for rigorous comparisons with baseline approaches."
Vaxign-DL: A Deep Learning-based Method for Vaccine Design and its Evaluation,"Reverse vaccinology (RV) provides a systematic approach to identifying potential vaccine candidates based on protein sequences. The integration of machine learning (ML) into this process has greatly enhanced our ability to predict viable vaccine candidates from these sequences. We have previously developed a Vaxign-ML program based on the eXtreme Gradient Boosting (XGBoost). In this study, we further extend our work to develop a Vaxign-DL program based on deep learning techniques. Deep neural networks assemble non-linear models and learn multilevel abstraction of data using hierarchically structured layers, offering a data-driven approach in computational design models. Vaxign-DL uses a three-layer fully connected neural network model. Using the same bacterial vaccine candidate training data as used in Vaxign-ML development, Vaxign-DL was able to achieve an Area Under the Receiver Operating Characteristic of 0.94, specificity of 0.99, sensitivity of 0.74, and accuracy of 0.96. Using the Leave-One-Pathogen-Out Validation (LOPOV) method, Vaxign-DL was able to predict vaccine candidates for 10 pathogens. Our benchmark study shows that Vaxign-DL achieved comparable results with Vaxign-ML in most cases, and our method outperforms Vaxi-DL in the accurate prediction of bacterial protective antigens."
Robust Evaluation of Deep Learning-based Representation Methods for Survival and Gene Essentiality Prediction on Bulk RNA-seq Data,"Deep learning (DL) has shown potential to provide powerful representations of bulk RNA-seq data in cancer research. However, there is no consensus regarding the impact of design choices of DL approaches on the performance of the learned representation, including the model architecture, the training methodology and the various hyperparameters. To address this problem, we evaluate the performance of various design choices of DL representation learning methods using TCGA and DepMap pan-cancer datasets, and assess their predictive power for survival and gene essentiality predictions. We demonstrate that non DL-based baseline methods achieve comparable or superior performance compared to more complex models on survival predictions tasks. DL representation methods, however, are the most efficient to predict the gene essentiality of cell lines. We show that auto-encoders (AE) are consistently improved by techniques such as masking and multi-head training. Our results suggest that the impact of DL representations and of pre-training are highly task- and architecture-dependent, highlighting the need for adopting rigorous evaluation guidelines. These guidelines for robust evaluation are implemented in a pipeline made available to the research community."
Classification of helical polymers with deep-learning language models,"Many macromolecules in biological systems exist in the form of helical polymers. However, the inherent polymorphism and heterogeneity of samples complicate the reconstruction of helical polymers from cryo-EM images. Currently available 2D classification methods are effective at separating particles of interest from contaminants, but they do not effectively differentiate between polymorphs, resulting in heterogeneity in the 2D classes. As such, it is crucial to develop a method that can computationally divide a dataset of polymorphic helical structures into homogenous subsets. In this work, we utilized deep-learning language models to embed the filaments as vectors in hyperspace and group them into clusters. Tests with both simulated and experimental datasets have demonstrated that our method – HLM (Helical classification with Language Model) can effectively distinguish different types of filaments, in the presence of many contaminants and low signal-to-noise ratios. We also demonstrate that HLM can isolate homogeneous subsets of particles from a publicly available dataset, resulting in the discovery of a previously unknown non-proteinaceous density around tau filaments."
Gradient-based implementation of linear model outperforms deep learning models,"Deep learning has been widely considered more effective than traditional statistical models in modeling biological complex data such as single-cell omics. Here we show the devil is hidden in details: by adapting a modern gradient solver to a traditional linear mixed model, we showed that conventional models can outperform deep models in terms of both speed and accuracy. This work reveals the potential of re-implementing traditional models with modern solvers."
A Deep Learning Pipeline for Mapping in situ Network-level Neurovascular Coupling in Multi-photon Fluorescence Microscopy,"1 Functional hyperaemia is a well-established hallmark of healthy brain function, whereby local brain blood flow adjusts in response to a change in the activity of the surrounding neurons. Although functional hyperemia has been extensively studied at the level of both tissue and individual vessels, vascular network-level coordination remains largely unknown. To bridge this gap, we developed a deep learning-based computational pipeline that uses two-photon fluorescence microscopy images of cerebral microcirculation to enable automated reconstruction and quantification of the geometric changes across the microvascular network, comprising hundreds of interconnected blood vessels, pre and post-activation of the neighbouring neurons. The pipeline’s utility was demonstrated in the Thy1-ChR2 optogenetic mouse model, where we observed network-wide vessel radius changes to depend on the photostimulation intensity, with both dilations and constrictions occurring across the cortical depth, at an average of 16.1±14.3 μm (mean±stddev) away from the most proximal neuron for dilations; and at 21.9±14.6 μm away for constrictions. We observed a significant heterogeneity of the vascular radius changes within vessels, with radius adjustment varying by an average of 24 ± 28% of the resting diameter, likely reflecting the heterogeneity of the distribution of contractile cells on the vessel walls. A graph theory-based network analysis revealed that the assortativity of adjacent blood vessel responses rose by 152 ± 65% at 4.3 mW/mm2 of blue photostimulation vs. the control, with a 4% median increase in the efficiency of the capillary networks during this level of blue photostimulation in relation to the baseline. Interrogating individual vessels is thus not sufficient to predict how the blood flow is modulated in the network. Our computational pipeline, to be made openly available, enables tracking of the microvascular network geometry over time, relating caliber adjustments to vessel wall-associated cells’ state, and mapping network-level flow distribution impairments in experimental models of disease."
Deep learning-based method to identify disease-resistance proteins in Oryza sativa and relative species,"Rice (Oryza sativa) is a significant agricultural crop consumed by more than half of the global population. Its demand is expected to increase due to rising consumption and a growing global population. Moreover, the rice plant is frequently exposed to disease-causing pathogens, such as bacteria, fungi, viruses, and nematodes. Thus, cultivating disease-resistant varieties is an efficient way of disease control compared to pesticide applications. However, the rice plant has a well-defined defense system to prevent the onset of disease, including Pathogen-associated molecular pattern (PAMP)-triggered immunity (PTI) and effector-triggered immunity (ETI). The defense system is controlled by various disease-resistance proteins, such as resistance (R) proteins and pathogen recognition receptors (PRRs). Therefore, the identification of disease-resistance proteins not only reduces the amount of pesticides used in rice fields but also increases their yield. Though some resistant proteins have been characterized, their rapid identification, precise diagnosis, and appropriate management are still lacking. However, few methods based on sequence-similarity and de novo prediction, such as Machine Learning (ML), usually have low prediction power. In this study, we built a state-of-the-art classifier based on Deep Learning (DL) for the early detection of disease-resistance proteins in rice and related species. We compared the DL-based Multi-layer Perceptron (MLP) model with the five well-established ML-based methods using a protein dataset of rice and its related species. The DL-based MLP model outperformed all of the five classifiers on 10-fold cross-validation. The accuracy, Area Under Receiving Operating Characteristic (ROC) curve (AUC), F1-score, precision, and recall were superior in the DL-based MLP model. In conclusion, the MLP model is an effective DL model for predicting disease-resistance proteins with high scores in performance metrics. This study will provide insight to the breeders in developing disease-resistant rice varieties and assist in transforming traditional rice farming practices into a new age of smart rice farming."
Deep learning reveals the role of copy number variation in the genetic architecture of a highly polymorphic sexual trait,"The extraordinary variation in male guppy coloration has proven a powerful model for studying the interplay of natural and sexual selection. Many guppy populations exhibit substantial Y-linkage of color traits, and this has hampered the identification of the genetic architecture underlying male guppy color, as well as clouded our understanding of how this exceptional level of diversity is maintained. Here we identify the heritability and genetic basis of male color variation using convolutional neural networks for high-resolution phenotyping coupled with selection experiments, controlled pedigrees and whole-genome resequencing for a Genome Wide Association Study (GWAS) of color. Our phenotypic and genomic results converge to show that color patterning in guppies is a combination of many heritable features, each with a partially overlapping genetic architecture spanning the entire genome. Unusually, our GWAS results suggest that copy number variation, particularly copies shared between the Y chromosome and the remainder of the genome, is responsible for much of the variation in color in guppies, providing a potential mechanism for the maintenance of variation of this classic model trait."
A deep learning convolutional neural network distinguishes neuronal models of Parkinson’s disease from matched controls,"Parkinson’s disease (PD) is a neurodegenerative disorder that results in the loss of dopaminergic neurons in the substantia nigra pars compacta. Despite advances in understanding PD, there is a critical need for novel therapeutics that can slow or halt its progression. Induced pluripotent stem cell (iPSC)-derived dopaminergic neurons have been used to model PD but measuring differences between PD and control cells in a robust, reproducible, and scalable manner remains a challenge. In this study, we developed a binary classifier convolutional neural network (CNN) to accurately classify microscopy images of PD models and matched control cells. We acquired images of iPSC-derived neural precursor cells (NPCs) and dopaminergic (DANs) and trained multiple CNN models comparing control cells to genetic and chemical models of PD. Our CNN accurately predicted whether control NPC cells were treated with the PD-inducing pesticide rotenone with 97.60% accuracy. We also compared control to a genetic model of PD (deletion of the Parkin gene) and found a predictive accuracy of 86.77% and 95.47% for NPC and DAN CNNs, respectively. Our cells were stained for nuclei, mitochondria, and plasma membrane, and we compared the contribution of each to the CNN’s accuracy. Using all three features together produced the best accuracy, but nuclear staining alone produced a highly predictive CNN. Our study demonstrates the power of deep learning and computer vision for analyzing complex PD-related phenotypes in DANs and suggests that these tools hold promise for identifying new targets for therapy and improving our understanding of PD."
Deep learning-based cell profiling based on neuronal morphology,"Treatment of neurons with β-amyloid peptide (Aβ1-42) has been widely used as a model to interrogate the cellular and molecular mechanisms underlying Alzheimer’s disease, and as an assay system to identify drugs that reverse or block disease phenotype. Prior studies have largely relied on high content imaging (HCI) to extract cellular features such as neurite length or branching, but these have not offered a robust/comprehensive means of relating readout to Aβ1-42 concentrations. Here, we use a deep learning-based cell profiling technique to directly measure the impact of Aβ1-42 on primary murine cortical neurons. The deep learning model achieved approximately 80% accuracy, compared to 54% for the cell phenotypic feature-based approach. The deep learning model could distinguish subtle neuronal morphological changes induced by a range of Aβ1-42 concentration. When tested on a separate dataset, the accuracy remained comparable and dropped by only 2%. Our study demonstrates that deep learning-based cell profiling is superior to HCI-based feature extraction on neuronal morphology and it provides an alternative to a dose/response curve, where the modality of the response does not have to be pre-determined. Moreover, this approach could form the basis of a screening tool that can be applied to any cellular model where appropriate phenotypic markers based on genotypes and/or pathological insults are available."
Integrated Protocol of Protein Structure Modeling for Cryo-EM with Deep Learning and Structure Prediction,"Structure modeling from maps is an indispensable step for studying proteins and their complexes with cryogenic electron microscopy (cryo-EM). Although the resolution of determined cryo-EM maps has generally improved, there are still many cases where tracing protein main-chains is difficult, even in maps determined at a near atomic resolution. Here, we have developed a protein structure modeling method, called DeepMainmast, which employs deep learning to capture the local map features of amino acids and atoms to assist main-chain tracing. Moreover, since Alphafold2 demonstrates high accuracy in protein structure prediction, we have integrated complementary strengths of de novo density tracing using deep learning with Alphafold2’s structure modeling to achieve even higher accuracy than each method alone. Additionally, the protocol is able to accurately assign chain identity to the structure models of homo-multimers."
Deep learning predicts DNA methylation regulatory variants in specific brain cell types and enhances fine mapping for brain disorders,"DNA methylation (DNAm) is essential for brain development and function and potentially mediates the effects of genetic risk variants underlying brain disorders. We present INTERACT, a transformer-based deep learning model to predict regulatory variants impacting DNAm levels in specific brain cell types, leveraging existing single-nucleus DNAm data from the human brain. We show that INTERACT accurately predicts cell type-specific DNAm profiles, achieving an average area under the Receiver Operating Characteristic curve of 0.98 across cell types. Furthermore, INTERACT predicts cell type-specific DNAm regulatory variants, which reflect cellular context and enrich the heritability of brain-related traits in relevant cell types. Importantly, we demonstrate that incorporating predicted variant effects and DNAm levels of CpG sites enhances the fine mapping for three brain disorders—schizophrenia, depression, and Alzheimer’s disease—and facilitates mapping causal genes to particular cell types. Our study highlights the power of deep learning in identifying cell type-specific regulatory variants, which will enhance our understanding of the genetics of complex traits.Teaser Deep learning reveals genetic variations impacting brain cell type-specific DNA methylation and illuminates genetic bases of brain disorders"
Using Deep Learning to Decipher the Impact of Telomerase Promoter Mutations on the Morpholome,"Melanoma showcases a complex interplay of genetic alterations and cellular morphological changes during metastatic transformation. While pivotal, the role of specific mutations in dictating these changes still needs to be fully elucidated. Telomerase promoter mutations (TPMs) significantly influence melanoma’s progression, invasiveness, and resistance to various emerging treatments, including chemical inhibitors, telomerase inhibitors, targeted therapy, and immunotherapies. We aim to understand the morphological and phenotypic implications of the two dominant monoallelic TPMs, C228T and C250T, enriched in melanoma metastasis. We developed isogenic clonal cell lines containing the TPMs and utilized dual-color expression reporters steered by the endogenous Telomerase promoter, giving us allelic resolution. This approach allowed us to monitor morpholomic variations induced by these mutations. TPM-bearing cells exhibited significant morpholome differences from their wild-type counterparts, with increased allele expression patterns, augmented wound-healing rates, and unique spatiotemporal dynamics. Notably, the C250T mutation exerted more pronounced changes in the morpholome than C228T, suggesting a differential role in metastatic potential. Our findings underscore the distinct influence of TPMs on melanoma’s cellular architecture and behavior. The C250T mutation may offer a unique morpholomic and systems-driven advantage for metastasis. These insights provide a foundational understanding of how a non-coding mutation in melanoma metastasis affects the system, manifesting in cellular morpholome."
Comprehensive monitoring of tissue composition using in vivo imaging of cell nuclei and deep learning,"Comprehensive analysis of tissue composition has so far been limited to ex-vivo approaches. Here, we introduce NuCLear (Nucleus-instructed tissue composition using deep learning), an approach combining in vivo two-photon imaging of histone 2B-eGFP-labeled cell nuclei with subsequent deep learning-based identification of cell types from structural features of the respective cell nuclei. Using NuCLear, we were able to classify almost all cells per imaging volume in the secondary motor cortex of the mouse brain (0.25 mm3 containing ∼25000 cells) and to identify their position in 3D space in a non-invasive manner using only a single label throughout multiple imaging sessions. Twelve weeks after baseline, cell numbers did not change yet astrocytic nuclei significantly decreased in size. NuCLear opens a window to study changes in relative abundance and location of different cell types in the brains of individual mice over extended time periods, enabling comprehensive studies of changes in cellular composition in physiological and pathophysiological conditions."
Deep Learning Based Identification of Tissue of Origin for Carcinomas of Unknown Primary utilizing micro-RNA expression,"ABSTRACTCarcinoma of Unknown Primary (CUP) is a subset of metastatic cancers in which the primary tissue source, or origin, remains unidentified. CUP accounts for three to five percent of all malignancies [2]. Representing an exceptionally aggressive category of metastatic cancers, the median survival of those diagnosed with CUP is approximately three to six months [1]. The tissue in which a cancer arises plays a key role in our understanding of altered gene expression, altered cellular pathways, and sensitivities to various forms of cell death in cancer cells [3]. Thus, the lack of knowledge on tissue of origin makes it difficult to devise tailored treatments for patients with CUP [4]. Developing clinically implementable methods to identify the tissue of origin of the primary site is crucial in treating CUP patients [4]. In particular, the expression profiles of non-coding RNAs can provide insight into the tissue of origin for CUP. Non-coding RNAs provide a robust route to clinical implementation due to their resistance against chemical degradation [5].In this work, we investigate the potential of microRNAs as highly accurate biomarkers for detecting the tissue of origin for metastatic cancers. We further hypothesize that data driven approaches can identify specific microRNA biomarker targets. We used microRNA expression data from the Cancer Genome Atlas (TCGA) dataset [6] and assessed various machine learning approaches. Our results show that it is possible to design robust classifiers to detect the tissue of origin for metastatic samples on the TCGA dataset with an accuracy of up to 96%, which may be utilized in situations of CUP. As a validation of our classifiers, we evaluated the accuracy on a separate set of 194 primary tumor samples from the Sequence Read Archive (SRA) [7]. Our findings demonstrate that deep learning techniques enhance prediction accuracy. We progressed from an initial accuracy prediction of 62.5% with decision trees to 93.2% with logistic regression, finally achieving 96.1% accuracy using deep learning on metastatic samples. On the SRA validation set, a lower accuracy of 41.2% was achieved by decision tree, while deep learning achieved a higher accuracy of 81.2%. Notably, our feature importance analysis showed the top three important biomarkers for predicting tissue of origin to be mir-10b, mir-205, and mir-196b, which aligns with previous work [10]. Our findings highlight the potential of using machine learning techniques to devise tests for detecting tissue of origin for CUP. Since microRNAs are carried throughout the body via vesicles secreted from cells, they may serve as key biomarkers for liquid biopsy due to their presence in blood plasma [11]. Our work serves as a foundation towards developing blood-based cancer detection tests based on microRNA presence."
Integrative Multiscale Biochemical Mapping of the Brain via Deep-Learning-Enhanced High-Throughput Mass Spectrometry,"Elucidating the spatial-biochemical organization of the brain across different scales produces invaluable insight into the molecular intricacy of the brain. While mass spectrometry imaging (MSI) provides spatial localization of compounds, comprehensive chemical profiling at a brain-wide scale in three dimensions by MSI with single-cell resolution has not been achieved. We demonstrate complementary brain-wide and single-cell biochemical mapping via MEISTER, an integrative experimental and computational mass spectrometry framework. MEISTER integrates a deep-learning-based reconstruction that accelerates high-mass-resolving MS by 15-fold, multimodal registration creating 3D molecular distributions, and a data integration method fitting cell-specific mass spectra to 3D data sets. We imaged detailed lipid profiles in tissues with data sets containing millions of pixels, and in large single-cell populations acquired from the rat brain. We identified region-specific lipid contents, and cell-specific localizations of lipids depending on both cell subpopulations and anatomical origins of the cells. Our workflow establishes a blueprint for future developments of multiscale technologies for biochemical characterization of the brain."
Deep learning and direct sequencing of labeled RNA captures transcriptome dynamics,"Quantification of the dynamics of RNA metabolism is essential for understanding gene regulation in health and disease. Existing methods rely on metabolic labeling of nascent RNAs and physical separation or inference of labeling through PCR-generated mutations, followed by short-read sequencing. However, these methods are limited in their ability to identify transient decay intermediates or co-analyze RNA decay with cis-regulatory elements of RNA stability such as poly(A) tail length and modification status, at single molecule resolution. Here we use 5-ethynyl uridine (5EU) to label nascent RNA followed by direct RNA sequencing with nanopores. We developed RNAkinet, a deep convolutional and recurrent neural network that processes the electrical signal produced by nanopore sequencing to identify 5EU-labeled nascent RNA molecules. RNAkinet demonstrates generalizability to distinct cell types and organisms and reproducibly quantifies RNA kinetic parameters allowing the combined interrogation of RNA metabolism and cis-acting RNA regulatory elements."
DeepLocRNA: An Interpretable Deep Learning Model for Predicting RNA Subcellular Localization with domain-specific transfer-learning,"ABSTRACTAccurate prediction of RNA subcellular localization plays an important role in understanding cellular processes and functions. Although post-transcriptional processes are governed by trans-acting RNA-binding proteins (RBPs) through interaction with cis-regulatory RNA motifs, current methods do not incorporate RBP-binding information. In this paper, we propose DeepLocRNA, an interpretable deep-learning model that leverages a pre-trained multi-task RBP-binding prediction model to predict the subcellular localisation of RNA molecules via fine-tuning. We constructed DeepLocRNA using a comprehensive dataset with variant RNA types and evaluated it on held-out RNA species. Our model achieved state-of-the-art performance in predicting RNA subcellular localization in mRNA and miRNA. It has demonstrated great generalization capabilities, not only for human RNA but also for mice. Moreover, the interpretability of the model is enhanced through the motif analysis, enabling the understanding of the signal factors that contribute to the predictions. The proposed model provides general and powerful prediction abilities for different RNA and species, offering valuable insights into the localisation patterns of RNA molecules and contributing to advancing our understanding of cellular processes at the molecular level."
Deep learning assisted single particle tracking for automated correlation between diffusion and function,"Sub-cellular diffusion in living systems reflects cellular processes and interactions. Recent advances in optical microscopy allow the tracking of this nanoscale diffusion of individual objects with an unprecedented level of precision. However, the agnostic and automated extraction of functional information from the diffusion of molecules and organelles within the sub-cellular environment, is labor-intensive and poses a significant challenge. Here we introduce DeepSPT, a deep learning framework to interpret the diffusional 2D or 3D temporal behavior of objects in a rapid and efficient manner, agnostically. Demonstrating its versatility, we have applied DeepSPT to automated mapping of the early events of viral infections, identifying distinct types of endosomal organelles, and clathrin-coated pits and vesicles with up to 95% accuracy and within seconds instead of weeks. The fact that DeepSPT effectively extracts biological information from diffusion alone indicates that besides structure, motion encodes function at the molecular and subcellular level."
DeepMRG: a multi-label deep learning classifier for predicting bacterial metal resistance genes,"The widespread misuse of antibiotics has escalated antibiotic resistance into a critical global public health concern. Beyond antibiotics, metals function as antibacterial agents. Metal resistance genes (MRGs) enable bacteria to tolerate metal-based antibacterials and may also foster antibiotic resistance within bacterial communities through co-selection. Thus, predicting bacterial MRGs is vital for elucidating their involvement in antibiotic resistance and metal tolerance mechanisms. Currently, the “best hit” approaches are utilized to identify and annotate MRGs. This method is sensitive to cutoff values and produces a high false negative rate. To address such limitations, we introduce DeepMRG, a deep learning-based multi-label classifier, to predict bacterial MRGs. Because a bacterial MRG can confer resistance to multiple metals, DeepMRG is designed as a multi-label classifier capable of predicting multiple metal labels associated with an MRG. It leverages bit score-based similarity distribution of sequences with experimentally verified MRGs. To ensure unbiased model evaluation, we employed a clustering method to partition our dataset into six subsets, five for cross-validation and one for testing, with non-homologous sequences, mitigating the impact of sequence homology. DeepMRG consistently achieved high overall F1-scores and significantly reduced false negative rates across a wide range of datasets. It can be used to predict bacterial MRGs in metagenomic or isolate assemblies. The web server of DeepMRG can be accessed at https://deepmrg.cs.vt.edu/deepmrg and the source code is available at https://github.com/muhit-emon/DeepMRG under the MIT license."
Quality Matters: Deep Learning-Based Analysis of Protein-Ligand Interactions with Focus on Avoiding Bias,"The efficient and accurate prediction of protein-ligand binding affinities is an extremely appealing yet still unresolved goal in computational pharmacy. In recent years, many scientists have taken advantage of the remarkable progress of deep learning and applied it to address this issue. Despite all the advances in this field, there is increasing evidence that the typically applied validation of these methods is not suitable for medicinal chemistry applications. This work assesses the importance of dataset quality and proper dataset splitting techniques demonstrated on the example of the PDBbind dataset. We also introduce a new tool for the analysis of protein-ligand complexes, called po-sco. Po-sco allows the extraction of interaction information with much higher detail and comprehensibility than the tools available to date. We trained a transformer-based deep learning model to generate protein-ligand interaction fingerprints that can be utilized for downstream predictions, such as binding affinity. When using po-sco, this model generated predictions that were superior to those based on commonly used PLIP and ProLIF tools. We also demonstrate that the quality of the dataset is more important than the number of data points and that suboptimal dataset splitting can lead to a significant overestimation of model performance."
Bacterial community characterization by deep learning aided image analysis in soil chips,"Soil microbes play an important role in governing global processes such as carbon cycling, but it is challenging to study them embedded in their natural environment and at the single cell level due to the opaque nature of the soil. Nonetheless, progress has been achieved in recent years towards visualizing microbial activities and organo-mineral interaction at the pore scale, especially thanks to the development of microfluidic ‘soil chips’ creating transparent soil model habitats. Image-based analyses come with new challenges as manual counting of bacteria in thousands of digital images taken from the soil chips is excessively time-consuming, while simple thresholding cannot be applied due to the background of soil minerals and debris. Here, we adopt the well-developed deep learning algorithm Mask-RCNN to quantitatively analyse the bacterial communities in soil samples from different locations in the world. This work demonstrates analysis of bacterial abundance from three contrasting locations (Greenland, Sweden and Kenya) using deep learning in microfluidic soil chips in order to characterize population and community dynamics. We additionally quantified cell- and colony morphology including cell size, shape and the cell aggregation level via calculation of the distance to the nearest neighbor. This approach allows for the first time an automated visual investigation of soil bacterial communities, and a crude biodiversity measure based on phenotypic cell morphology, which could become a valuable complement to molecular studies."
A novel classification framework for genome-wide association study of whole brain MRI images using deep learning,"Genome-wide association studies (GWASs) have been widely applied in the neuroimaging field to discover genetic variants associated with brain-related traits. So far, almost all GWASs conducted in neuroimaging genetics are performed on univariate quantitative features summarized from brain images. On the other hand, powerful deep learning technologies have dramatically improved our ability to classify images. In this study, we proposed and implemented a novel machine learning strategy for systematically identifying genetic variants that lead to detectable nuances on Magnetic Resonance Images (MRI). For a specific single nucleotide polymorphism (SNP), if MRI images labeled by genotypes of this SNP can be reliably distinguished using machine learning, we then hypothesized that this SNP is likely to be associated with brain anatomy or function which is manifested in MRI brain images. We applied this strategy to a catalog of MRI image and genotype data collected by the Alzheimer’s Disease Neuroimaging Initiative (ADNI) consortium. From the results, we identified novel variants that show strong association to brain phenotypes."
Annotation-Free Deep Learning for Predicting Gene Mutations from Whole Slide Images of Acute Myeloid Leukemia,"The rapid development of deep learning in recent years has revolutionized the field of medical image processing, including the applications of using high-resolution whole slide images (WSIs) in predicting gene mutations in acute myeloid leukemia (AML). Although the potential of characterizing gene mutations directly from WSIs has been demonstrated in some studies, it still faces challenges due to memory limitations and manual annotation requirements. To address this, we propose a deep learning model based on multiple instance learning (MIL) to predict gene mutations from AML WSIs with no patch-level or cell-level annotations. The proposed MIL-based deep learning model offers a promising solution for gene mutation prediction on NPM1 mutations and FLT3 -ITD. With the property of annotation-free, the proposed method eliminates the need for manual annotations, reducing the manpower and time costs associated with traditional patch-based or cell-based approaches. We assessed our MIL models using a dataset of 572 WSIs from AML patients. By exclusively utilizing annotation-free WSIs for cell-level training, we achieved an AUC of 0.75 for predicting NPM1 mutations and 0.68 for FLT3 -ITD. Furthermore, upon applying upsampling and ensemble techniques to address the data imbalance issue, the AUC improved from 0.75 to 0.86 for NPM1 mutations and from 0.68 to 0.82 for FLT3 -ITD. These enhancements, leading to more precise predictions, have brought AML WSI analysis one step closer to being utilized in clinical practice."
genomicBERT and data-free deep-learning model evaluation,"The emerging field of Genome-NLP (Natural Language Processing) aims to analyse biological sequence data using machine learning (ML), offering significant advancements in data-driven diagnostics. Three key challenges exist in Genome-NLP. First, long biomolecular sequences require “tokenisation” into smaller subunits, which is non-trivial since many biological “words” remain unknown. Second, ML methods are highly nuanced, reducing interoperability and usability. Third, comparing models and reproducing results are difficult due to the large volume and poor quality of biological data.To tackle these challenges, we developed the first automated Genome-NLP workflow that integrates feature engineering and ML techniques. The workflow is designed to be species and sequence agnostic. In this workflow: a) We introduce a new transformer-based model for genomes called genomicBERT, which empirically tokenises sequences while retaining biological context. This approach minimises manual preprocessing, reduces vocabulary sizes, and effectively handles out-of-vocabulary “words”. (b) We enable the comparison of ML model performance even in the absence of raw data.To facilitate widespread adoption and collaboration, we have made genomicBERT available as part of the publicly accessible conda package called genomeNLP. We have successfully demonstrated the application of genomeNLP on multiple case studies, showcasing its effectiveness in the field of Genome-NLP.HighlightsWe provide a comprehensive classification of genomic data tokenisation and representation approaches for ML applications along with their pros and cons.We infer k-mers directly from the data and handle out-of-vocabulary words. At the same time, we achieve a significantly reduced vocabulary size compared to the conventional k-mer approach reducing the computational complexity drastically.Our method is agnostic to species or biomolecule type as it is data-driven.We enable comparison of trained model performance without requiring original input data, metadata or hyperparameter settings.We present the first publicly available, high-level toolkit that infers the grammar of genomic data directly through artificial neural networks.Preprocessing, hyperparameter sweeps, cross validations, metrics and interactive visualisations are automated but can be adjusted by the user as needed."
An interpretable deep learning framework for genome-informed precision oncology,"Cancers result from aberrations in cellular signaling systems, typically resulting from driver somatic genome alterations (SGAs) in individual tumors. Precision oncology requires understanding the cellular state and selecting medications that induce vulnerability in cancer cells under such conditions. To this end, we developed a computational framework consisting of two components: 1) A representation-learning component, which learns a representation of the cellular signaling systems when perturbed by SGAs, using a biologically-motivated and interpretable deep learning model. 2) A drug-response-prediction component, which predicts the response to drugs by leveraging the information of the cellular state of the cancer cells derived by the first component. Our cell-state-oriented framework significantly enhances the accuracy of genome-informed prediction of drug responses in comparison to models that directly use SGAs as inputs. Importantly, our framework enables the prediction of response to chemotherapy agents based on SGAs, thus expanding genome-informed precision oncology beyond molecularly targeted drugs."
"TRILL: Orchestrating Modular Deep-Learning Workflows for Democratized, Scalable Protein Analysis and Engineering","Deep-learning models have been rapidly adopted by many fields, partly due to the deluge of data humanity has amassed. In particular, the petabases of biological sequencing data enable the unsupervised training of protein language models that learn the “language of life.” However, due to their prohibitive size and complexity, contemporary deep-learning models are often unwieldy, especially for scientists with limited machine learning backgrounds. TRILL (TRaining and Inference using the Language of Life) is a platform for creative protein design and discovery. Leveraging several state-of-the-art models such as ESM-2, DiffDock, and RFDiffusion, TRILL allows researchers to generate novel proteins, predict 3-D structures, extract high-dimensional representations of proteins, functionally classify proteins and more. What sets TRILL apart is its ability to enable complex pipelines by chaining together models and effectively merging the capabilities of different models to achieve a sum greater than its individual parts. Whether using Google Colab with one GPU or a supercomputer with hundreds, TRILL allows scientists to effectively utilize models with millions to billions of parameters by using optimized training strategies such as ZeRO-Offload and distributed data parallel. Therefore, TRILL not only bridges the gap between complex deep-learning models and their practical application in the field of biology, but also simplifies the orchestration of these models into comprehensive workflows, democratizing access to powerful methods. Documentation: https://trill.readthedocs.io/en/latest/home.html."
Beyond functional connectivity: deep learning applied to resting-state fMRI time series in the prediction of 58 human traits in the HCP,"Machine learning has made several inroads into the study of brain-behavior relations based on in vivo imaging. While the advent of deep neural networks was expected to further improve predictions, the current literature based on resting-state functional connectivity presents mixed results. We hypothesize that the representation of the data, i.e. in the form of functional connectivity, could restrict an advantage of deep learning techniques, namely that of learning complex representations directly from the data. Thus, we investigated if bypassing this feature extraction resulted in improved performance in the prediction of 58 widely studied behavioral traits from a large sample of Human Connectome Project subjects, using deep learning techniques. For this task, we adapted the InceptionTime architecture, which jointly predicts traits directly from regional time series through representation learning, and compared results with a strong kernel-based baseline. Results revealed that both models achieve comparable performance in most traits. Eleven significant differences in mean squared error were detected, however, with seven favoring the neural network approach, and this number increased when accounting for covariates. We additionally show that contrary to the expectation, the neural network approach was more robust to reductions in the training set size. On the other hand, it was more sensitive to reductions in the length of the time series at test time. Our results present a more nuanced view of the potential of deep learning for the prediction of behavior from neuroimaging, which allows learning features directly from the data."
Accurate prediction of RNA translation with a deep learning architecture,"Accurate annotation of coding regions in RNAs is essential for understanding gene translation. We developed a deep neural network to directly predict and analyze translation initiation and termination sites from RNA sequences. Trained with human transcripts, our model learned hidden rules of translation control and achieved a near perfect prediction of translation sites across entire transcriptome. Our model revealed a surprising role of codon usage in regulating translation termination, which was experimentally validated. We also identified thousands of new open reading frames in mRNAs or annotated lncRNAs, some of which were confirmed experimentally. Remarkably, the model trained with human mRNAs achieved high prediction accuracy in all eukaryotes and good prediction in polycistronic transcripts from prokaryotes or RNA viruses, suggesting a high degree of conservation in translation control. Collectively, this study presents a general and efficient deep learning model for RNA translation, providing new insights into the complexity of translation regulation."
Determination of Metabolic Fluxes by Deep Learning of Isotope Labeling Patterns,"Fluxomics offers a direct readout of metabolic state but relies on indirect measurement. Stable isotope tracers imprint flux-dependent isotope labeling patterns on metabolites we measure; however, the relationship between labeling patterns and fluxes remains elusive. Here we innovate a two-stage machine learning framework termed ML-Flux that streamlines metabolic flux quantitation from isotope tracing. We train machine learning models by simulating atom transitions across five universal metabolic models starting from 26 13C-glucose, 2H-glucose, and 13C-glutamine tracers within feasible flux space. ML-Flux employs deep-learning-based imputation to take variable measurements of labeling patterns as input and successive neural networks to convert the ensuing comprehensive labeling information into metabolic fluxes. Using ML-Flux with multi-isotope tracing, we obtain fluxes through central carbon metabolism that are comparable to those from a least-squares method but orders-of-magnitude faster. ML-Flux is deployed as a webtool to expand the accessibility of metabolic flux quantitation and afford actionable information on metabolism."
"TrustAffinity: accurate, reliable and scalable out-of-distribution protein-ligand binding affinity prediction using trustworthy deep learning","Accurate, reliable and scalable predictions of protein-ligand binding affinity have a great potential to accelerate drug discovery. Despite considerable efforts, three challenges remain: out-of-distribution (OOD) generalizations for understudied proteins or compounds from unlabeled protein families or chemical scaffolds, uncertainty quantification of individual predictions, and scalability to billions of compounds. We propose a sequence-based deep learning framework, TrustAffinity, to address aforementioned challenges. TrustAffinity synthesizes a structure-informed protein language model, efficient uncertainty quantification based on residue-estimation and novel uncertainty regularized optimization. We extensively validate TrustAffinity in multiple OOD settings. TrustAffinity significantly outperforms state-of-the-art computational methods by a large margin. It achieves a Pearson’s correlation between predicted and actual binding affinities above 0.9 with a high confidence and at least three orders of magnitude of faster than protein-ligand docking, highlighting its potential in real-world drug discovery. We further demonstrate TrustAffinity’s practicality through an Opioid Use Disorder lead discovery case study."
IC-VAE: A Novel Deep Learning Framework for Interpreting Multiplexed Tissue Imaging Data,"Interpreting protein expression in multiplexed tissue imaging data presents a significant challenge due to the high dimensionality of the resulting images, the variety of intracellular structures, cell shapes resulting from 2-D tissue sectioning, and the presence of technological noise and imaging artifacts. Here, we introduce the Information-Controlled Variational Autoencoder (IC-VAE), a deep generative model designed to tackle this challenge. The contribution of IC-VAE to the VAE framework is the ability to control the shared information among latent subspaces. We use IC-VAE to factorize each cell’s image into its true protein expression, various cellular components, and background noise, while controlling the shared information among some of these components. Compared with other normalization methods, this approach leads to superior results in downstream analysis, such as analyzing the expression of biomarkers, classification for cell types, or visualizing cell clusters using t-SNE/UMAP techniques."
DeepVASP-S: a deep-learning tool for explaining steric mechanism that controls binding specificity,"DeepVASP-S is a computational tool that leverages the capabilities of convolutional neural networks (CNNs) to analyze steric aspects of protein-ligand interactions and predict amino acid contributions to binding specificity. This tool combines structural bioinformatics with machine learning to address the complex problem of understanding how specific amino acids contribute to the specificity of binding. Here, we use this tool to predict subclasses for Enolase and Serine Protease according to their binding specificity, and explain it through the underlying steric mechanism. The strength of DeepVASP-S lies in its ability to identify and highlight these specific regions, providing researchers with insights into the molecular determinants of protein function and interaction. Such information is extremely valuable for the field of drug design, as it enables the creation of more targeted and effective therapeutics with minimized side effects. The approach taken by DeepVASP-S represents a significant step forward in computational biochemistry, merging high-resolution 3D structural data with the predictive power of machine learning to unlock a deeper understanding of protein-ligand interactions."
Deep Learning Analysis on Images of iPSC-derived Motor Neurons Carrying fALS-genetics Reveals Disease-Relevant Phenotypes,"SummaryAmyotrophic lateral sclerosis (ALS) is a devastating condition with very limited treatment options. It is a heterogeneous disease with complex genetics and unclear etiology, making the discovery of disease-modifying interventions very challenging. To discover novel mechanisms underlying ALS, we leverage a unique platform that combines isogenic, induced pluripotent stem cell (iPSC)-derived models of disease-causing mutations with rich phenotyping via high-content imaging and deep learning models. We introduced eight mutations that cause familial ALS (fALS) into multiple donor iPSC lines, and differentiated them into motor neurons to create multiple isogenic pairs of healthy (wild-type) and sick (mutant) motor neurons. We collected extensive high-content imaging data and used machine learning (ML) to process the images, segment the cells, and learn phenotypes. Self-supervised ML was used to create a concise embedding that captured significant, ALS-relevant biological information in these images. We demonstrate that ML models trained on core cell morphology alone can accurately predict TDP-43 mislocalization, a known phenotypic feature related to ALS. In addition, we were able to impute RNA expression from these image embeddings, in a way that elucidates molecular differences between mutants and wild-type cells. Finally, predictors leveraging these embeddings are able to distinguish between mutant and wild-type both within and across donors, defining cellular, ML-derived disease models for diverse fALS mutations. These disease models are the foundation for a novel screening approach to discover disease-modifying targets for familial ALS."
DenoiseST: A dual-channel unsupervised deep learning-based denoising method to identify spatial domains and functionally variable genes in spatial transcriptomics,"Spatial transcriptomics provides a unique opportunity for understanding cellular organization and function in a spatial context. However, spatial transcriptome exists the problem of dropout noise, exposing a major challenge for accurate downstream data analysis. Here, we proposed DenoiseST, a dual-channel unsupervised adaptive deep learning-based denoising method for data imputing, clustering, and identifying functionally variable genes in spatial transcriptomics. To leverage spatial information and gene expression profiles, we proposed a dual-channel joint learning strategy with graph convolutional networks to sufficiently explore both linear and nonlinear representation embeddings in an unsupervised manner, enhancing the discriminative information learning ability from the global perspectives of data distributions. In particular, DenoiseST enables the adaptively fitting of different gene distributions to the clustered domains and employs tissue-level spatial information to accurately identify functionally variable genes with different spatial resolutions, revealing their enrichment in corresponding gene pathways. Extensive validations on a total of 18 real spatial transcriptome datasets show that DenoiseST obtains excellent performance and results on brain tissue datasets indicate it outperforms the state-of-the-art methods when handling artificial dropout noise with a remarkable margin of ∼15%, demonstrating its effectiveness and robustness. Case study results demonstrate that when applied to identify biological structural regions on human breast cancer spatial transcriptomic datasets, DenoiseST successfully detected biologically significant immune-related structural regions, which are subsequently validated through Gene Ontology (GO), cell-cell communication, and survival analysis. In conclusion, we expect that DenoiseST is a novel and efficient method for spatial transcriptome analysis, offering unique insights into spatial organization and function."
A New Paradigm for Applying Deep Learning to Protein-Ligand Interaction Prediction,"Protein-ligand interaction prediction poses a significant challenge in the field of drug design. Numerous machine learning and deep learning models have been developed to identify the most accurate docking poses of ligands and active compounds against specific targets. However, the current models often suffer from inadequate accuracy and lack practical physical significance in their scoring systems. In this research paper, we introduce IGModel, a novel approach that leverages the geometric information of protein-ligand complexes as input for predicting the root mean square deviation (RMSD) of docking poses and the binding strength (the negative value of the logrithm of binding affinity, pKd) with the same prediction framework. By incorporating the geometric information, IGModel ensures that its scores carry intuitive meaning. The performance of IGModel has been extensively evaluated on various docking power test sets, including the CASF-2016 benchmark, PDBbind-CrossDocked-Core, and DISCO set, consistently achieving state-of-theart accuracies. Furthermore, we assess IGModel’s generalization ability and robustness by evaluating it on unbiased test sets and sets containing target structures generated by AlphaFold2. The exceptional performance of IGModel on these sets demonstrates its efficacy. Additionally, we visualize the latent space of protein-ligand interactions encoded by IGModel and conduct interpretability analysis, providing valuable insights. This study presents a novel framework for deep learning-based prediction of protein-ligand interactions, contributing to the advancement of this field.Key MessagesKey MessagesWe introduce the first framework for simultaneously predicting the RMSD of the ligand docking pose and its binding strength to the target.IGModel can effectively improve the accuracy of identifying the near-native binding poses of the ligands, and can still outperform most baseline models in scoring power, ranking power and screening power tasks.IGModel is still ahead of other state-of-the-art models in the unbiased data set and the target structure predicted by AlphaFold2, proving its excellent generalization ability.Latent space provided by IGModel learns the physical interactions, thus indicating the robustness of the model."
DeLoop: a deep learning model for chromatin loop prediction from sparse ATAC-seq data,"Deciphering gene regulation and understanding the functional implications of disease-associated non-coding variants require the identification of cell-type-specific 3D chromatin interactions. Current chromosome conformation capture technologies fall short in resolution when handling limited cell inputs. To address this limitation, we introduce DeLoop, a deep learning model designed to predict CTCF-mediated chromatin loops from sparse ATAC-seq data by leveraging multitask learning techniques and attention mechanisms. Our model utilizes ATAC-seq data and DNA sequence features, showcasing superior performance compared to existing state-of-the-art models, particularly under low read depth conditions, enabling accurate chromatin loop inference when sufficient cells are infeasible. In addition, generalizing across cell types, DeLoop proves effective in de novo prediction tasks and its potential for predicting functional interactions."
Three-dimensional visualization of blood vessels in human gliomas based on tissue clearing and deep learning,"Gliomas, with their intricate and aggressive nature, call for a detailed visualization of their vasculature. While many studies lean towards 2D imaging of thin sections, this method often overlooks the full spatial heterogeneity inherent to tumors. To overcome this limitation, our study melded state-of-the-art techniques, encompassing tissue clearing technology, 3D confocal microscopy imaging, and deep learning-aided vessel extraction, resulting in a comprehensive 3D visualization of glioma vasculature in intact human tissue. Specifically, we treated formalin-fixed thick human glioma tissue sections (500 μ m) with OPTIClear for transparency and subsequently performed immunofluorescent labeling using CD31. Using confocal microscopy, we obtained 3D images of the glioma vasculature. For vessel extraction, we employed a specialized 3D U-Net, enriched with image preprocessing and post-processing methods, and benchmarked its performance against the Imaris software. Our findings indicated that OPTIClear-enabled tissue clearing yielded a holistic 3D representation of immunolabeled vessels in clinical human glioma samples. Impressively, our deep learning technique outshined the traditional Imaris approach in terms of accuracy and efficiency in vessel extraction. Further, discernible variations in vascular metrics, such as mean diameter, branching point count, and volume ratio, were observed between low-grade and high-grade gliomas. In essence, our innovative blend of tissue clearing and deep learning not only enables enhanced 3D visualization of human glioma vasculature but also underscores morphological disparities across glioma grades, potentially influencing pathological grading, therapeutic strategies, and prognostic evaluations."
Deep Learning-based Optical Aberration Estimation Enables Offline Digital Adaptive Optics and Super-resolution Imaging,"Optical aberrations degrade the performance of fluorescence microscopy. Conventional adaptive optics (AO) leverages specific devices, such as the Shack-Hartmann wavefront sensor and deformable mirror, to measure and correct optical aberrations. However, conventional AO requires either additional hardware or a more complicated imaging procedure, resulting in higher cost or a lower acquisition speed. In this study, we proposed a novel space-frequency encoding network (SFE-Net) that can directly estimate the aberrated point spread functions (PSFs) from biological images, enabling fast optical aberration estimation with high accuracy without engaging extra optics and image acquisition. We showed that with the estimated PSFs, the optical aberration can be computationally removed by deconvolution algorithm. Furthermore, to fully exploit the benefits of SFE-Net, we incorporated the estimated PSF with neural network architecture design to devise an aberration-aware deep-learning super-resolution (DLSR) model, dubbed SFT-DFCAN. We demonstrated that the combination of SFE-Net and SFT-DFCAN enables instant digital AO and optical aberration-aware super-resolution reconstruction for live-cell imaging."
Modelling protein complexes with crosslinking mass spectrometry and deep learning,"Scarcity of structural and evolutionary information on protein complexes poses a challenge to deep learning-based structure modelling. We integrated experimental distance restraints obtained by crosslinking mass spectrometry (MS) into AlphaFold-Multimer, by extending AlphaLink to protein complexes. Integrating crosslinking MS data substantially improves modelling performance on challenging targets, by helping to identify interfaces, focusing sampling, and improving model selection. This extends to single crosslinks from whole-cell crosslinking MS, suggesting the possibility of whole-cell structural investigations driven by experimental data."
Deep-Learning-Enabled Differentiation between Intraprostatic Gold Fiducial Markers and Calcification in Quantitative Susceptibility Mapping,"Purpose Interest is growing in MR-only radiotherapy (RT) planning for prostate cancer (PCa) due to the potential reductions in cost and patient exposure to radiation, and a more streamlined work-flow and patient imaging pathway. However, in MRI, the gold fiducial markers (FMs) used for target localization appear as signal voids, complicating differentiation from other void sources such as calcifications and bleeds. This work investigates using Quantitative Susceptibility Mapping (QSM), an MRI phase post-processing technique, to aid in the differentiation task. It also presents deep learning models that capture nuanced information and automate the segmentation task, facilitating a streamlined approach to MR-only RT.Methods CT and MRI, including GRE and T1-weighted imaging, were acquired from 26 PCa patients, each with three implanted gold FMs. GRE data were post-processed into QSM, T 2*, and R2* maps using QSMxT’s body imaging pipeline. Statistical analyses were conducted to investigate the quantitative differentiation of FMs and calcification in each contrast. 3D U-Nets were developed using fastMONAI to automate the segmentation task using various combinations of MR-derived contrasts, with a model trained on CT used as a baseline. Models were evaluated using precision and recall calculated using a leave-one-out cross-validation scheme.Results Significant differences were observed between FM and calcification regions in CT, QSM and T 2*, though overlap was observed in QSM and T 2*. The baseline CT U-Net achieved an FM-level precision of ≈ 98% and perfect recall. The best-performing QSM-based model achieved precision and recall of 80% and 90%, respectively, while conventional MRI had values below 70% and 80%, respectively. The QSM-based model produced segmentations with good agreement with the ground truth, including a challenging FM that coincided with a bleed.Conclusion The model performance highlights the value of using QSM over indirect measures in MRI, such as signal voids in magnitude-based contrasts. The results also indicate that a U-Net can capture more information about the presentation of FMs and other sources than would be possible using susceptibility quantification alone, which may be less reliable due to the diverse presentation of sources across a patient population. In our study, QSM was a reliable discriminator of FMs and other sources in the prostate, facilitating an accurate and streamlined approach to MR-only RT."
An Explainable and Robust Deep Learning Approach for Automated Electroencephalography-based Schizophrenia Diagnosis,"Schizophrenia (SZ) is a neuropsychiatric disorder that affects millions globally. Current diagnosis of SZ is symptom-based, which poses difficulty due to the variability of symptoms across patients. To this end, many recent studies have developed deep learning methods for automated diagnosis of SZ, especially using raw EEG, which provides high temporal precision. For such methods to be productionized, they must be both explainable and robust. Explainable models are essential to identify biomarkers of SZ, and robust models are critical to learn generalizable patterns, especially amidst changes in the implementation environment. One common example is channel loss during EEG recording, which could be detrimental to classifier performance. In this study, we developed a novel channel dropout (CD) approach to increase the robustness of explainable deep learning models trained on EEG data for SZ diagnosis to channel loss. We developed a baseline convolutional neural network (CNN) architecture and implement our approach as a CD layer added to the baseline (CNN-CD). We then applied two explainability approaches to both models for insight into learned spatial and spectral features and show that the application of CD decreases model sensitivity to channel loss. The CNN and CNN-CD achieved accuracies of 81.9% and 80.9% on testing data, respectively. Furthermore, our models heavily prioritized the parietal electrodes and the α-band, which is supported by existing literature. It is our hope that this study motivates the further development of explainable and robust models and bridges the transition from research to application in a clinical decision support role."
Deep Learning enables reliable and comprehensive profiling of invertible promoters in microbes,"Invertible promoters (invertons) are regulatory elements found in bacteria, with inverted repeat sequences at both ends, leading to alternating changes in the expression of the regulated genes. Since invertons were present in more than 20% of bacterial genomes, while they regulated more than 5% of genes in these genomes, they are of pivotal importance for microbial functional dynamics especially when under stress. However, the prevalence of invertons, as well as the full spectrum of gene functions regulated by them, remain poorly understood. In this study, we developed DeepInverton, a deep learning model capable of accurately identifying novel inverton sequences without sequencing reads, which could profile inverton sequences from large genomic and metagenomic datasets. We conducted a pan-genomic and pan-metagenomic analysis of invertons on 68,969 bacterial genomes and 8,516 metagenome samples, resulting in a comprehensive overview of more than 200,000 nonredundant invertons and their regulated gene functional patterns. This result suggests that invertons, as a key player for bacterial adaptation to environmental stresses, are prevalent in bacterial genomes. Among the genomes analyzed, we observed a profound enrichment of invertons in pathogen such as Bordetella pertussis, and discovered a significant increase of inverton enrichment rates in strains associated with recent pertussis outbreaks, as well as novel evolving strains, unveiling a hidden link between the evolution of Bordetella pertussis and its inverton enrichment. We also utilized DeepInverton to explore inverton profiles mong human and marine metagenomes. Results revealed an unprecedented diversity of functional genes regulated by invertons, including antimicrobial resistance, biofilm formation and flagella, indicating their potential role in facilitating environmental adaptation. The in vitro experiments have confirmed the functions of tens of novel invertons that we have identified. Overall, we developed the DeepInverton model for exploration of invertons at unprecedented scale, which enabled our comprehensive profiling of invertons and their regulated genes. The comprehensive inverton profiles have deepen our understanding of invertons at pan-genome and metagenome scale, and could enabled a broad spectrum of inverton-related applications in microbial ecology and synthetic biology."
Interpretable Deep Learning for Breast Cancer Cell Phenotyping Using Diffraction Images from Lens-Free Digital In-Line Holography,"Lens-free digital in-line holography (LDIH) offers a wide field of view at micrometer-scale resolution, surpassing the capabilities of lens-based microscopes, making it a promising diagnostic tool for high-throughput cellular analysis. However, the complex nature of holograms renders them challenging for human interpretation, necessitating time- consuming computational processing to reconstruct object images. To address this, we present HoloNet, a novel deep learning architecture specifically designed for direct analysis of holographic images from LDIH in cellular phenotyping. HoloNet extracts both global features from diffraction patterns and local features from convolutional layers, achieving superior performance and interpretability compared to other deep learning methods. By leveraging raw holograms of breast cancer cells stained with well-known markers ER/PR and HER2, HoloNet demonstrates its effectiveness in classifying breast cancer cell types and quantifying molecular marker intensities. Furthermore, we introduce the feature-fusion HoloNet model, which extracts diffraction features associated with breast cancer cell types and their marker intensities. This hologram embedding approach allows for the identification of previously unknown subtypes of breast cancer cells, facilitating a comprehensive analysis of cell phenotype heterogeneity, leading to precise breast cancer diagnosis."
Deep learning for rapid analysis of cell divisions in vivo during epithelial morphogenesis and repair,"Cell division is fundamental to all healthy tissue growth, as well as being rate-limiting in the tissue repair response to wounding and during cancer progression. However, the role that cell divisions play in tissue growth is a collective one, requiring the integration of many individual cell division events. It is particularly difficult to accurately detect and quantify multiple features of large numbers of cell divisions (including their spatio-temporal synchronicity and orientation) over extended periods of time. It would thus be advantageous to perform such analyses in an automated fashion, which can naturally be enabled using Deep Learning. Hence, we develop a pipeline of Deep Learning Models that accurately identify dividing cells in time-lapse movies of epithelial tissues in vivo. Our pipeline also determines their axis of division orientation, as well as their shape changes before and after division. This strategy enables us to analyse the dynamic profile of cell divisions within the Drosophila pupal wing epithelium, both as it undergoes developmental morphogenesis and as it repairs following laser wounding. We show that the division axis is biased according to lines of tissue tension and that wounding triggers a synchronised (but not oriented) burst of cell divisions back from the leading edge.Highlights□ Accurate and efficient detection of epithelial cell divisions can be automated by deep learning of dynamic time-lapse imaging data□ Optimal division detection is achieved using multiple timepoints and dual channels for visualisation of nuclei and cell boundaries□ Epithelial cell divisions are orientated according to lines of global tissue tension after post-division shuffling□ Spatio-temporal cell division analyses following wounding reveal spatial synchronicity that scales with wound size□ Additional deep learning tools enable rapid analysis of cell division orientation"
Deep Learning Restores Speech Intelligibility in Multi-Talker Interference for Cochlear Implant Users,"Cochlear implants (CIs) fail to provide the same level of benefit in noisy settings as in quiet. Current noise reduction solutions in hearing aids and CIs only remove predictable, stationary noise, and are ineffective against realistic, non-stationary noise such as multi-talker interference. Recent developments in deep neural network (DNN) models have achieved noteworthy performance in speech enhancement and separation. However, little work has investigated the potential of DNN models in removing multi-talker interference. The research in this regard is even more scarce for CIs. Here, we implemented two DNN models that are well suited for applications in speech audio processing, including (1) recurrent neural network (RNN) and (2) SepFormer. The models were trained with a dataset developed in house (∼ 30 hours), and then tested with thirteen CI listeners. Both RNN and SepFormer models significantly improved CI listener’s speech intelligibility in noise without compromising the perceived quality of speech. These models not only increased the intelligibility in stationary non-speech noise, but also introduced substantially more improvements in non-stationary speech noise, where conventional signal processing strategies fall short with little benefits. These results show the promise of using DNN models as a solution for listening challenges in multi-talker noise interference."
Context-aware geometric deep learning for protein sequence design,Protein design and engineering are evolving at an unprecedented pace leveraging the advances of deep learning. Current models nonetheless cannot natively consider non-protein entities within the design process. Here we introduce a deep learning approach based solely on a geometric transformer of atomic coordinates that predicts protein sequences from backbone scaffolds aware of the restraints imposed by diverse molecular environments. This new concept is anticipated to improve the design versatility for engineering proteins with desired functions.
Deep learning-based aberration compensation improves contrast and resolution in fluorescence microscopy,"Optical aberrations hinder fluorescence microscopy of thick samples, reducing image signal, contrast, and resolution. Here we introduce a deep learning-based strategy for aberration compensation, improving image quality without slowing image acquisition, applying additional dose, or introducing more optics into the imaging path. Our method (i) introduces synthetic aberrations to images acquired on the shallow side of image stacks, making them resemble those acquired deeper into the volume and (ii) trains neural networks to reverse the effect of these aberrations. We use simulations to show that applying the trained ‘de-aberration’ networks outperforms alternative methods, and subsequently apply the networks to diverse datasets captured with confocal, light-sheet, multi-photon, and super-resolution microscopy. In all cases, the improved quality of the restored data facilitates qualitative image inspection and improves downstream image quantitation, including orientational analysis of blood vessels in mouse tissue and improved membrane and nuclear segmentation in C. elegans embryos."
Exploring the Roles of RNAs in Chromatin Architecture Using Deep Learning,"Recent studies have highlighted the impact of both transcription and transcripts on 3D genome organization, particularly its dynamics. Here, we propose a deep learning framework, called AkitaR, that leverages both genome sequences and genome-wide RNA-DNA interactions to investigate the roles of chromatin-associated RNAs (caRNAs) on genome folding in HFFc6 cells. In order to disentangle the cis- and trans-regulatory roles of caRNAs, we compared models with nascent transcripts, trans-located caRNAs, open chromatin data, or DNA sequence alone. Both nascent transcripts and trans-located caRNAs improved the models’ predictions, especially at cell-type-specific genomic regions. Analyses of feature importance scores revealed the contribution of caRNAs at TAD boundaries, chromatin loops and nuclear sub-structures such as nuclear speckles and nucleoli to the models’ predictions. Furthermore, we identified non-coding RNAs (ncRNAs) known to regulate chromatin structures, such as MALAT1 and NEAT1, as well as several novel RNAs, RNY5, RPPH1, POLG-DT and THBS1-IT, that might modulate chromatin architecture through trans-interactions in HFFc6. Our modeling also suggests that transcripts from Alus and other repetitive elements may facilitate chromatin interactions through trans R-loop formation. Our findings provide new insights and generate testable hypotheses about the roles of caRNAs in shaping chromatin organization."
Deep DNAshape: Predicting DNA shape considering extended flanking regions using a deep learning method,"Understanding the mechanisms of protein-DNA binding is critical in comprehending gene regulation. Three-dimensional DNA shape plays a key role in these mechanisms. In this study, we present a deep learning-based method, Deep DNAshape, that fundamentally changes the current k-mer based high-throughput prediction of DNA shape features by accurately accounting for the influence of extended flanking regions, without the need for extensive molecular simulations or structural biology experiments. By using the Deep DNAshape method, refined DNA shape features can be predicted for any length and number of DNA sequences in a high-throughput manner, providing a deeper understanding of the effects of flanking regions on DNA shape in a target region of a sequence. Deep DNAshape method provides access to the influence of distant flanking regions on a region of interest. Our findings reveal that DNA shape readout mechanisms of a core target are quantitatively affected by flanking regions, including extended flanking regions, providing valuable insights into the detailed structural readout mechanisms of protein-DNA binding. Furthermore, when incorporated in machine learning models, the features generated by Deep DNAshape improve the model prediction accuracy. Collectively, Deep DNAshape can serve as a versatile and powerful tool for diverse DNA structure-related studies."
An Artificial Intelligence Method for Phenotyping of OCT Scans Using Unsupervised and Self-supervised Deep Learning,"Artificial intelligence (AI) has been increasingly used to analyze optical coherence tomography (OCT) images to better understand physiology and genetic architecture of ophthalmic diseases. However, to date, research has been limited by the inability to transfer OCT phenotypes from one dataset to another. In this work, we propose a new AI method for phenotyping and clustering of OCT-derived retinal layer thicknesses using unsupervised and self-supervised methods in a large clinical dataset using glaucoma as a model disease and subsequently transfer our phenotypes to a large biobank. The model includes a deep learning model, manifold learning, and a Gaussian mixture model. We also propose a correlation analysis for the performance evaluation of our model based on Pearson correlation coefficients. Our model was able to identify clinically meaningful OCT phenotypes and successfully transfer phenotypes from one dataset to another. Overall, our results will contribute to stronger research methodologies for future research in OCT imaging biomarkers, augment testing of OCT phenotypes in multiple datasets, and ultimately improve our understanding of pathophysiology and genetic architecture of ocular diseases."
Quantifying innervation facilitated by deep learning in wound healing,"ABSTRACTThe peripheral nerves (PNs) innervate the dermis and epidermis, which have been suggested to play an important role in wound healing. Several methods to quantify skin innervation during wound healing have been reported. Those usually require multiple observers, are complex and labor-intensive, and noise/background associated with the Immunohistochemistry (IHC) images could cause quantification errors/user bias. In this study, we employed the state-of-the-art deep neural network, DnCNN, to perform pre-processing and effectively reduce the noise in the IHC images. Additionally, we utilized an automated image analysis tool, assisted by Matlab, to accurately determine the extent of skin innervation during various stages of wound healing. The 8mm wound is generated using a circular biopsy punch in the wild-type mouse. Skin samples were collected on days 3,7,10 and 15, and sections from paraffin-embedded tissues were stained against pan-neuronal marker- protein-gene-product 9.5 (PGP 9.5) antibody. On day 3 and day 7, negligible nerve fibers were present throughout the wound with few only on the lateral boundaries of the wound. On day 10, a slight increase in nerve fiber density appeared, which significantly increased on day 15. Importantly we found a positive correlation (R-2 = 0.933) between nerve fiber density and re-epithelization, suggesting an association between re-innervation and re-epithelization. These results established a quantitative time course of re-innervation in wound healing, and the automated image analysis method offers a novel and useful tool to facilitate the quantification of innervation in the skin and other tissues."
Predicting glycan structure from tandem mass spectrometry via deep learning,"Glycans constitute the most complicated post-translational modification, modulating protein activity in health and disease. However, structural annotation from tandem mass spectrometry data is a bottleneck in glycomics, preventing high-throughput endeavors and relegating glycomics to a few experts. Trained on a newly curated set of 300,000 annotated MS/MS spectra, we present CandyCrunch, a dilated residual neural network predicting glycan structure from raw LC-MS/MS data in seconds (Top1 Accuracy: 87.7%). We developed an open-access Python-based workflow of raw data conversion and prediction, followed by automated curation and fragment annotation, with predictions recapitulating and extending expert annotation. We demonstrate that this can be used for de novo annotation, diagnostic fragment identification, and high-throughput glycomics. For maximum impact, this entire pipeline is tightly interlaced with our glycowork platform and can be easily tested at https://colab.research.google.com/github/BojarLab/CandyCrunch/blob/main/CandyCru nch.ipynb. We envision CandyCrunch to democratize structural glycomics and the elucidation of biological roles of glycans."
A deep learning model embedded framework to distinguish DNA and RNA mutations directly from RNA-seq,"We develop a stepwise computational framework, called DEMINING, to directly detect expressed DNA and RNA mutations in RNA deep sequencing data. DEMINING incorporates a deep learning model named DeepDDR, which facilitates the separation of expressed DNA mutations from RNA mutations after RNA-seq read mapping and pileup. When applied in RNA-seq of acute myeloid leukemia patients, DEMINING uncovered previously-underappreciated DNA and RNA mutations, some associated with the upregulated expression of host genes or the production of neoantigens. Finally, we demonstrate that DEMINING could precisely classify DNA and RNA mutations in RNA-seq data from non-primate species through the utilization of transfer learning."
Interpretable deep learning framework for understanding molecular changes in human brains with Alzheimer’s disease: implications for microglia activation and sex differences,"INTRODUCTION The objective of this study is to characterize the dysregulation of gene expression in AD affected brain tissues through an interpretable deep learning framework.METHODS We trained multi-layer perceptron models for the classification of neuropathologically confirmed AD vs. controls using transcriptomic data from three brain regions of ROSMAP study. The disease spectrum was then modeled as a progressive trajectory. SHAP value was derived to explain model predictions and identify significantly implicated genes for subsequent gene co-expression network analysis.RESULTS The models achieved excellent performance in classification and prediction in two external datasets from Mayo RNA-seq cohort and Mount Sinai Brain Bank cohort. SHAP explainer revealed common and specific transcriptomic signatures from different brain regions.DISCUSSION We identified common gene signatures among different brain regions in microglia and sex specific modules in neurons implicated in AD. This work paves the way for utilizing artificial intelligence approaches in studying AD at the molecular level.Research-in-ContextSystematic review: Postmortem brain transcriptomes have been analyzed to study the molecular changes associated with Alzheimer’s disease, usually by a direct contrast approach such as differential gene expression analysis. Nuanced gene regulatory networks thus cannot be easily pinpointed from convoluted data such as those from bulk-tissue profiling. We applied a novel interpretable deep learning approach to dissect the RNA-seq data collected from three different brain regions of a large clinical cohort and identified significant genes for network analysis implicated for AD.Interpretation: Our models successfully predicted neuropathological and clinical traits in both internal and external validations. We corroborated known microglial biology in addition to revealing novel sex chromosome-linked gene contributing to sex dimorphism in AD.Future directions: The framework could have broad utility for interpreting multi-omic data such as those from single-cell profiling, to advance our understanding of molecular mechanisms of complex human disease such as AD.HighlightsWe applied novel interpretable deep learning methods to postmortem brain transcriptomes from three different brain regionsWe interpreted the models to identify genes most strongly implicated in ADNetwork analysis corroborated known microglial biology and revealed novel sex specific transcriptional factors associated with neuronal loss in AD"
Continuous Tracking using Deep Learning-based Decoding for Non-invasive Brain-Computer Interface,"Brain-computer interfaces (BCI) using electroencephalography (EEG) provide a non-invasive method for users to interact with external devices without the need for muscle activation. While noninvasive BCIs have the potential to improve the lives of both healthy and motor impaired individuals, they currently have limited applications due to inconsistent performance and low degrees of freedom. In this study, we use deep-learning (DL)-based decoders for online Continuous Pursuit (CP), a complex BCI task requiring the user to track an object in 2D space. We developed a new labelling system to use CP data for supervised learning, trained DL-based decoders based on two architectures, including a newly proposed adaptation of the PointNet architecture, and evaluated the performance over several online sessions. We rigorously evaluated the DL-based decoders in a total of 28 human subjects, and found that the DL-based models improved throughout the sessions as more training data became available and significantly outperformed a traditional BCI decoder by the last session. We also performed additional experiments to test an implementation of transfer learning by pre-training models on data from other subjects, and mid-session training to reduce inter-session variability. The results from these experiments show that pre-training did not significantly improve performance, but updating the models mid-session may have some benefit. Overall, these findings support the use of DL-based decoders for improving BCI performance in complex tasks like CP, which can expand the potential applications of BCI devices and help improve the lives of both healthy individuals and motor-impaired patients."
Inference of drug off-target effects on cellular signaling using Interactome-Based Deep Learning,"Many diseases emerge from dysregulated cellular signaling, and drugs are often designed to target specific nodes in cellular networks e.g. signaling proteins, or transcription factors. However, off-target effects are common and may ultimately result in failed clinical trials. Computational modeling of the cell’s transcriptional response to drugs could improve our understanding of their mechanisms of action. Here we develop such an approach based on ensembles of artificial neural networks, that simultaneously infer drug-target interactions and their downstream effects on intracellular signaling. Applied to gene expression data from different cell lines, it outperforms basic machine learning approaches in predicting transcription factors’ activity, while recovering most known drug-target interactions and inferring many new, which we validate in an independent dataset. As a case study, we explore the inferred interactions of the drug Lestaurtinib and its effects on downstream signaling. Beyond its intended target FLT3 the model predicts an inhibition of CDK2 that enhances downregulation of the cell cycle-critical transcription factor FOXM1, corroborating literature findings. Our approach can therefore enhance our understanding of drug signaling for therapeutic design."
Accurate staging of chick embryonic tissues via deep learning,"ABSTRACTRecent work has indicated a need for increased temporal resolution for studies of the early chick brain. Over a 10-hour period, the developmental potential of progenitor cells in the HH10 brain changes, and concomitantly, the brain undergoes subtle changes in morphology. We asked if we could train a deep convolutional neural network to sub-stage HH10 brains from a small dataset (<200 images). By augmenting our images with a combination of biologically informed transformations and data-driven preprocessing steps, we successfully trained a classifier to sub-stage HH10 brains to 87.1% test accuracy. To determine whether our classifier could be generally applied, we re-trained it using images (<250) of randomised control and experimental chick wings, and obtained similarly high test accuracy (86.1%). Saliency analyses revealed that biologically relevant features are used for classification. Our strategy enables training of image classifiers for various applications in developmental biology with limited microscopy data.SUMMARY STATEMENT We train a deep convolutional network that can be generally applied to accurately classify chick embryos from images. Saliency analyses show that classification is based on biologically relevant features."
"Deep learning enables fast, gentle STED microscopy","STED microscopy is widely used to image subcellular structures with super-resolution. Here, we report that denoising STED images with deep learning can mitigate photobleaching and photodamage by reducing the pixel dwell time by one or two orders of magnitude. Our method allows for efficient and robust restoration of noisy 2D and 3D STED images with multiple targets and facilitates long-term imaging of mitochondrial dynamics."
Investigating the use of odour and colour foraging cues by rosy-faced lovebirds (Agapornis roseicollis) using deep-learning based behavioural analysis,"Olfaction and vision can play important roles in optimizing foraging decisions of birds, enabling them to maximize their net rate of energy intake while searching for, handling, and consuming food. Parrots have been used extensively in avian cognition research, and some species use olfactory cues to find food. Here we pioneered machine learning analysis and pose-estimation with convolutional neural networks (CNNs) to elucidate the relative importance of visual and olfactory cues for informing foraging decisions in the rosy-faced lovebird (Agapornis roseicollis) as a non-typical model species. In a binary choice experiment, we used markerless body pose tracking to analyse bird response behaviours. Rosy-faced lovebirds quickly learnt to discriminate the feeder provisioned with food by forming an association with visual (red/green papers) but not olfactory (banana/almond odour) cues. When visual cues indicated the provisioned and empty feeders, feeder choice was more successful, choice latency shorter, and interest in the empty feeder significantly lower. This demonstrates that visual cues alone are sufficient to inform lovebird foraging decisions without needing to use olfactory cues, suggesting that selection has not driven olfactory-based foraging in lovebird evolution."
VitTCR: A deep learning method for peptide recognition prediction,"The identification of the interaction between T-cell receptors (TCRs) and immunogenic peptides is important for the development of novel cancer immunotherapies and vaccines. However, experimentally determining whether a TCR recognizes a peptide is still time– and labour-consuming. In this study, we introduced VitTCR, a predictive model based on the architecture of the vision transformer (ViT), designed to forecast TCR-peptide interactions. Prior to prediction, VitTCR converts the TCR-peptide interactions into a numerical tensor named AtchleyMaps using Atchley factors. Subsequently, VitTCR takes AtchleyMaps as inputs and predicts whether an interaction between a TCR and a peptide exists. Through comprehensive evaluations, we demonstrate that VitTCR surpasses other published methods in classifying TCR-peptide pairs, exhibiting superior performance in terms of the area under the receiver operating characteristic (AUROC) and the area under the precision-recall curve (AUPR). To determine the focal contact point between TCRs and peptides, we obtained a positional bias weight matrix (PBWM) from the empirical amino acid (AA) contact probabilities derived from 83 structurally resolved pMHC-TCR complexes. The comparison of VitTCR with and without the integration of the PBWM revealed significant enhancements in the performance of the model. Moreover, the predicted probabilities generated by VitTCR exhibit significant correlations with immunological factors such as the clonal expansion and activation percentages of T cells. This further supports the efficacy of VitTCR in capturing biologically meaningful TCR-peptide interactions. In conclusion, VitTCR provides a useful computational tool for the prediction of TCR-peptide interactions, thereby contributing to our understanding in this field."
Mapping the topography of spatial gene expression with interpretable deep learning,"Spatially resolved transcriptomics technologies provide high-throughput measurements of gene expression in a tissue slice, but the sparsity of this data complicates the analysis of spatial gene expression patterns such as gene expression gradients. We address these issues by deriving a topographic map of a tissue slice—analogous to a map of elevation in a landscape—using a novel quantity called the isodepth. Contours of constant isodepth enclose spatial domains with distinct cell type composition, while gradients of the isodepth indicate spatial directions of maximum change in gene expression. We develop GASTON, an unsupervised and interpretable deep learning algorithm that simultaneously learns the isodepth, spatial gene expression gradients, and piecewise linear functions of the isodepth that model both continuous gradients and discontinuous spatial variation in the expression of individual genes. We validate GASTON by showing that it accurately identifies spatial domains and marker genes across several biological systems. In SRT data from the brain, GASTON reveals gradients of neuronal differentiation and firing, and in SRT data from a tumor sample, GASTON infers gradients of metabolic activity and epithelial-mesenchymal transition (EMT)-related gene expression in the tumor microenvironment."
DeepEnzyme: a robust deep learning model for improved enzyme turnover number prediction by utilizing features of protein 3D structures,"Turnover numbers (kcat), which indicate an enzyme’s catalytic efficiency, have a wide range of applications in fields including protein engineering and synthetic biology. Experimentally measuring the enzymes’ kcat is always time-consuming. Recently, the prediction of kcat using deep learning models has mitigated this problem. However, the accuracy and robustness in kcat prediction still needs to be improved significantly, particularly when dealing with enzymes with low sequence similarity compared to those within the training dataset. Herein, we present DeepEnzyme, a cutting-edge deep learning model that combines the most recent Transformer and Graph Convolutional Network (GCN) architectures. To improve the prediction accuracy, DeepEnzyme was trained by leveraging the integrated features from both sequences and 3D structures. Consequently, our model exhibits remarkable robustness when processing enzymes with low sequence similarity compared to those in the training dataset by utilizing additional features from high-quality protein 3D structures. DeepEnzyme also makes it possible to evaluate how point mutations affect the catalytic activity of the enzyme, which helps identify residue sites that are crucial for the catalytic function. In summary, DeepEnzyme represents a pioneering effort in predicting enzymes’ kcat values with superior accuracy and robustness compared to previous algorithms. This advancement will significantly contribute to our comprehension of enzyme function and its evolutionary patterns across species."
Protein-protein interaction prediction via structure-based deep learning,"Protein-protein interactions (PPIs) play an essential role in life activities. Many machine learning algorithms based on protein sequence information have been developed to predict PPIs. However, these models have difficulty dealing with various sequence lengths and suffer from low generalization and prediction accuracy. In this study, we proposed a novel end-to-end deep learning framework, RSPPI, combining Residual Neural Network (ResNet) and Spatial Pyramid Pooling (SPP), to predict PPIs based on the protein sequence physicochemistry properties and spatial structural information. In the RSPPI model, ResNet was employed to extract the structural and physicochemical information from the protein 3D structure and primary sequence; the SPP layer was used to transform feature maps to a single vector and avoid the fixed-length requirement. The RSPPI model possessed excellent cross-species performance and outperformed several state-of-the-art methods based either on protein sequence or gene ontology in most evaluation metrics. The RSPPI model provides a novel strategic direction to develop an AI PPI prediction algorithm."
Small immunological clocks identified by Deep Learning and Gradient Boosting,"Background The aging process affects all systems of the human body, and the observed increase in inflammatory components affecting the immune system in old age can lead to the development of age-associated diseases and systemic inflammation.Results We propose a small clock model SImAge based on a limited number of immunological biomarkers. To regress the chronological age from cytokine data, we first use a baseline Elastic Net model, gradient-boosted decision trees models, and several deep neural network architectures. For the full dataset of 46 immunological parameters, DANet, SAINT, FT-Transformer and TabNet models showed the best results for the test dataset. Dimensionality reduction of these models with SHAP values revealed the 10 most age-associated immunological parameters, taken to construct the SImAge small immunological clock. The best result of the SImAge model shown by the FT-Transformer deep neural network model has mean absolute error of 6.94 years and Pearson ρ = 0.939 on the independent test dataset. Explainable artificial intelligence methods allow for explaining the model solution for each individual participant.Conclusions We developed an approach to construct a model of immunological age based on just 10 immunological parameters, coined SImAge, for which the FT-Transformer deep neural network model had proved to be the best choice. The model shows competitive results compared to the published studies on immunological profiles, and takes a smaller number of features as an input. Neural network architectures outperformed gradient-boosted decision trees, and can be recommended in the further analysis of immunological profiles."
Interpreting Molecular Dynamics Forces as Deep Learning Gradients Improves Quality Of Predicted Protein Structures,"ABSTRACTProtein structure predictions from deep learning models like AlphaFold2, despite their remarkable accuracy, are likely insufficient for direct use in downstream tasks like molecular docking. The functionality of such models could be improved with a combination of increased accuracy and physical intuition. We propose a new method to train deep learning protein structure prediction models using molecular dynamics force fields to work toward these goals. Our custom PyTorch loss function, OpenMM-Loss, represents the potential energy of a predicted structure. OpenMM-Loss can be applied to any all-atom representation of protein structure capable of mapping into our software package, SidechainNet. We demonstrate our method’s efficacy by finetuning OpenFold. We show that subsequently predicted protein structures, both before and after a relaxation procedure, exhibit comparable accuracy while displaying lower potential energy and improved structural quality as assessed by MolProbity metrics.SIGNIFICANCE We propose a novel framework to directly incorporate forces from molecular dynamics as gradients for training deep learning models like AlphaFold2. We implement our method as a PyTorch loss function, OpenMM-Loss, which frames the potential energy of predicted protein structures as a minimization objective. When applied to OpenFold, our method demonstrates improved structural quality, lower potential energy, and comparable accuracy relative to the OpenFold baseline. Our framework may enhance the ability of deep learning models to recapitulate fundamental biophysical principles, reducing the number of structural irregularities in their predictions and paving the way for more effective downstream applications."
DeepRaccess: High-speed RNA accessibility prediction using deep learning,"RNA accessibility is a useful RNA secondary structural feature for predicting RNA-RNA interactions and translation efficiency in prokaryotes. However, conventional accessibility calculation tools, such as Raccess, are computationally expensive and require considerable computational time to perform transcriptome-scale analyses. In this study, we developed DeepRaccess, which predicts RNA accessibility based on deep learning methods. DeepRaccess was trained to take artificial RNA sequences as input and to predict the accessibility of these sequences as calculated by Raccess. Simulation and empirical dataset analyses showed that the accessibility predicted by DeepRaccess was highly correlated with the accessibility calculated by Raccess. In addition, we confirmed that DeepRaccess can predict protein abundance in E.coli with moderate accuracy from the sequences around the start codon. We also demonstrated that DeepRaccess achieved tens to hundreds of times software speed-up in a GPU environment. The source codes and the trained models of DeepRaccess are freely available at https://github.com/hmdlab/DeepRaccess."
Prediction of A. thaliana’s MCTP4 Structure using Deep Learning-Based tools and Exploration of Transmembrane domain Dynamics using Coarse-Grained Molecular Dynamics Simulations,"Multiple C2 Domains and Transmembrane region Proteins (MCTPs) in plants have been identified as important functional and structural components of plasmodesmata cytoplasmic bridges, which are vital for cell-cell communication. MCTPs are endoplasmic reticulum (ER)-associated proteins which contain three to four C2 domains and two transmembrane regions. In this study, we created structural models of Arabidopsis MCTP4 ER-anchor transmembrane region (TMR) domain using several prediction methods based on deep learning. This region, critical for driving ER association, presents a complex domain organization and remains largely unknown. Our study demonstrates that using a single deep-learning method to predict the structure of membrane proteins can be challenging. Our deep learning models presented three different conformations for the MCTP4 structure, provided by different deep learning methods, indicating the potential complexity of the protein’s conformational landscape. For the first time, we used simulations to explore the behaviour of the TMR of MCTPs within the lipid bilayer. We found that the TMR of MCTP4 is not rigid, but can adopt various conformations including some not identified by deep learning tools. These findings underscore the complexity of predicting protein structures. We learned that combining different methods, such as deep learning and simulations, enhances our understanding of complex proteins."
Inferring plasticity rules from single-neuron spike trains using deep learning methods,"Synaptic plasticity is a core basis for learning and adaptation. Determining how synapses are altered by local signals – the learning rules – is the hinge about which brain activity pivots. A large number of in vitro characterizations have focused on restricted sets of core properties [e.g., spike-timing-dependent plasticity (STDP), burst-dependent plasticity (BDP)], but it remains to be established which learning rule is most consistent with the changes in activity patterns observed while the network learns to perform a task. To address this question, we hypothesize that correlations between features of single post-synaptic neural activity and subsequent plasticity of the representations could distinguish between learning rules. Because this correlation was expected to be diluted by the notoriously large variability of brain activity, we propose to infer the learning rules from passive observations using artificial neural networks. Using surrogate data to test the validity of our approach, we found that transformers and temporal convolutional networks could classify learning rules far above the chance level (20%), with transformers achieving a better overall accuracy (78%) than the convolutional models (73%). This performance is achieved despite the presence of noise and representational drift. Although not as accurate as the complex transformer-based classifier, the convolutional model can provide insights into the interpretable features used by the algorithm to perform the classification. Our work establishes support for using deep learning methods to infer the category of learning rules given spiking data."
Virtual reality empowered deep learning analysis of brain activity,"ABSTRACTTissue clearing and fluorescent microscopy are powerful tools for unbiased organ-scale protein expression studies. Critical for interpreting expression patterns of large imaged volumes are reliable quantification methods. Here, we present DELiVR a deep learning pipeline that uses virtual reality (VR)-generated training data to train deep neural networks, and quantify c-Fos as marker for neuronal activity in cleared mouse brains and map its expression at cellular resolution. VR annotation significantly accelerated the speed of generating training data compared to conventional 2D slice based annotation. DELiVR detects cells with much higher precision than current threshold-based pipelines, and provides an extensive toolbox for data visualization, inspection and comparison. We applied DELiVR to profile cancer-related mouse brain activity, and discovered a novel activation pattern that distinguishes between weight-stable cancer and cancer-associated weight loss. Thus, DELiVR provides a robust mouse brain analysis pipeline at cellular scale that can be used to study brain activity patterns in health and disease.The DELiVR software, Fiji plugin and documentation can be found at https://www.DISCOtechnologies.org/DELiVR/.Download figureOpen in new tabHighlightsDELiVR detects labelled cells in cleared brains with deep learningDELiVR is trained by annotating ground-truth data in virtual reality (VR)DELiVR is launched via a FIJI plugin anywhere from PCs to clustersUsing DELiVR, we found new brain activity patterns in weight-stable vs. cachectic cancerHighlightsSupplementary Videos can be seen at: https://www.DISCOtechnologies.org/DELiVR/"
Deep learning to extract the meteorological by-catch of wildlife cameras,"Microclimate – proximal climatic variation at scales of meters and minutes – can exacerbate or mitigate the impacts of climate change on biodiversity. However, most microclimate studies are temperature-centric, and do not consider meteorological factors such as sunshine, hail and snow. Meanwhile, remote cameras have become a primary tool to monitor wild plants and animals, even at micro-scales, with deep learning tools to rapidly convert images into ecological data. However, deep learning applications for wildlife imagery have focused exclusively on living subjects. Here, we identify an overlooked opportunity to extract latent, yet ecologically relevant, meteorological information.We produce an annotated image dataset of micrometeorological conditions across 49 wildlife cameras in South Africa’s Maloti-Drakensberg and the Swiss Alps. We train ensemble deep learning models to classify conditions as overcast, sunshine, hail or snow. Our best model achieves 91.7% accuracy on test cameras not seen during training. Furthermore, we show how effective accuracy is raised to 96% by disregarding 14.1% of classifications where ensemble member models did not reach a consensus. Unlike previous studies we test model performance in remote and novel locations, distinguishing overcast and sunny conditions in Svalbard, Norway with 79.3% accuracy (93.9% consensus accuracy).Our model rapidly classifies sunshine, snow and hail in almost 2 million unlabeled images. Resulting micrometeorological data illustrated common seasonal patterns of summer hailstorms and autumn snowfalls across mountains in the northern and southern hemispheres. However, daily patterns of sunshine and shade diverged between sites, impacting daily temperature cycles. Crucially, we leverage micrometeorological data to demonstrate that (1) experimental warming using open-top chambers shortens early snow events in autumn, and (2) image-derived sunshine marginally outperforms sensor-derived temperature when predicting bumblebee foraging. These methods generate novel micrometeorological variables in synchrony with biological recordings, enabling new insights from an increasingly global network of wildlife cameras."
ProteinFlow: a Python Library to Pre-Process Protein Structure Data for Deep Learning Applications,"ABSTRACTOver the past few years, deep learning tools for protein design have made significant advances in the field of bioengineering, opening up new opportunities for drug discovery, disease prevention or industrial biotechnology. However, despite the growing interest and excitement surrounding these tools, progress in the field is hindered by a lack of standardized datasets for benchmarking. Most models are trained on data from the Protein Data Bank (PDB), the largest repository of experimentally determined biological macromolecular structures. But filtering and processing this data involves many hyperparameter choices that are often not harmonized across the research community. Moreover, the task of splitting protein data into training and validation subsets with minimal data leakage is not trivial and often overlooked. Here we present ProteinFlow, a computational pipeline to pre-process protein sequence and structural data for deep learning applications. The pipeline is fully configurable and allows the extraction of all levels of protein organization (primary to quaternary), allowing end-users to cater the dataset for a multitude of downstream tasks, such as protein sequence design, protein folding modeling or protein-protein interaction prediction. In addition, we curate a feature-rich benchmarking dataset based on the latest annual release of the PDB and a selection of preprocessing parameters that are widely used across the research community. We showcase its utility by benchmarking a state-of-the-art (SOTA) deep learning model for protein sequence design. The open source code is packaged as a python library and can be accessed on https://github.com/adaptyvbio/ProteinFlow."
A deep learning classification task for brain navigation during functional ultrasound imaging,"Positioning and navigation are essential components of neuroimaging as they improve the quality and reliability of data acquisition, leading to advances in diagnosis, treatment outcomes, and fundamental understanding of the brain. Functional ultrasound (fUS) imaging is an emerging technology providing high-resolution images of the brain vasculature, allowing for the monitoring of brain activity. However, as the technology is relatively new, there is no standardized tool for inferring the position in the brain from the vascular images. This study presents a deep learning-based framework designed to address this challenge. Our approach uses an image classification task coupled with a regression on the resulting probabilities to determine the position of a single image. We conducted experiments using a dataset of 51 rat brain scans to evaluate its performance. The training positions were extracted at intervals of 375 µm, resulting in a positioning error of 176 µm. Further GradCAM analysis revealed that the predictions were primarily driven by subcortical vascular structures. Finally, we assessed the robustness of our method in a cortical stroke where the brain vasculature is severely impaired. Remarkably, no specific increase in the number of misclassifications was observed, confirming the method’s reliability in challenging conditions. Overall, our framework provides accurate and flexible positioning, not relying on a pre-registered reference but on conserved vascular patterns."
Automated Deep Learning-Based Diagnosis and Molecular Characterization of Acute Myeloid Leukemia using Flow Cytometry,"ABSTRACTCurrent flow cytometric analysis of blood and bone marrow samples for diagnosis of acute myeloid leukemia (AML) relies heavily on manual intervention in both the processing and analysis steps, introducing significant subjectivity into resulting diagnoses and necessitating highly trained personnel. Furthermore, concurrent molecular characterization via cytogenetics and targeted sequencing can take multiple days, delaying patient diagnosis and treatment. Attention-based multi-instance learning models (ABMILMs) are deep learning models which make accurate predictions and generate interpretable insights regarding the classification of a sample from individual events/cells; nonetheless, these models have yet to be applied to flow cytometry data. In this study, we developed a computational pipeline using ABMILMs for the automated diagnosis of AML cases based exclusively on flow cytometric data. Analysis of 1,820 flow cytometry samples shows that this pipeline provides accurate diagnoses of acute leukemia [AUROC 0.961] and accurately differentiates AML versus B- and T- lymphoblastic leukemia [AUROC 0.965]. Models for prediction of 9 cytogenetic aberrancies and 32 pathogenic variants in AML provide accurate predictions, particularly for t(15;17)(PML::RARA) [AUROC 0.929], t(8;21)(RUNX1::RUNX1T1) [AUROC 0.814], and NPM1 variants [AUROC 0.807]. Finally, we demonstrate how these models generate interpretable insights into which individual flow cytometric events and markers deliver optimal diagnostic utility, providing hematopathologists with a data visualization tool for improved data interpretation, as well as novel biological associations between flow cytometric marker expression and cytogenetic/molecular variants in AML. Our study is the first to illustrate the feasibility of using deep learning-based analysis of flow cytometric data for automated AML diagnosis and molecular characterization."
Joint Trajectory Inference for Single-cell Genomics Using Deep Learning with a Mixture Prior,"Trajectory inference methods are essential for analyzing the developmental paths of cells in single-cell sequencing datasets. It provides insights into cellular differentiation, transitions, and lineage hierarchies, helping unravel the dynamic processes underlying development, disease progression, and tissue regeneration. However, many existing tools for trajectory inference lack a cohesive statistical model and reliable uncertainty quantification, limiting their utility and robustness. In this paper, we introduce VITAE (Variational Inference for Trajectory by AutoEncoder), a novel statistical approach that integrates a latent hierarchical mixture model with variational autoencoders to infer trajectories. The statistical hierarchical model underpinning the approach enhances interpretability, facilitating the exploration of differential gene expression patterns along the trajectory, while the posterior approximations generated by the variational autoencoder ensure computational efficiency, flexibility, and scalability. Notably, VITAE uniquely enables simultaneous trajectory inference and data integration across multiple datasets, enhancing accuracy in both tasks. We show that VITAE outperforms other state-of-the-art trajectory inference methods on both real and synthetic data under various trajectory topologies. Furthermore, we apply VITAE to jointly analyze three distinct single-cell RNA sequencing datasets of the mouse neocortex, unveiling comprehensive developmental lineages of projection neurons. VITAE effectively mitigates batch effects within and across datasets, aligning cells to elucidate clear trajectories and uncover finer structures that might be overlooked in individual datasets. Additionally, we showcase VITAE’s efficacy in integrative analyses of multi-omic datasets with continuous cell population structures."
NuFold: A Novel Tertiary RNA Structure Prediction Method Using Deep Learning with Flexible Nucleobase Center Representation,"RNA is not only playing a core role in the central dogma as mRNA between DNA and protein, but also many non-coding RNAs have been discovered to have unique and diverse biological functions. As genome sequences become increasingly available and our knowledge of RNA sequences grows, the study of RNA’s structure and function has become more demanding. However, experimental determination of three-dimensional RNA structures is both costly and time-consuming, resulting in a substantial disparity between RNA sequence data and structural insights. In response to this challenge, we propose a novel computational approach that harnesses state-of-the-art deep learning architecture NuFold to accurately predict RNA tertiary structures. This approach aims to offer a cost-effective and efficient means of bridging the gap between RNA sequence information and structural comprehension. NuFold implements a nucleobase center representation, which allows it to reproduce all possible nucleotide conformations accurately."
GeneSegNet: a deep learning framework for cell segmentation by integrating gene expression and imaging,"When analyzing data from in situ RNA detection technologies, cell segmentation is an essential step in identifying cell boundaries, assigning RNA reads to cells, and studying the gene expression and morphological features of cells. We developed a deep-learning-based method, GeneSegNet, that integrates both gene expression and imaging information to perform cell segmentation. GeneSegNet also employs a recursive training strategy to deal with noisy training labels. We show that GeneSegNet significantly improves cell segmentation performances over existing methods that either ignore gene expression information or underutilize imaging information."
Deep-learning and transfer learning identify new breast cancer survival subtypes from single-cell imaging data,"ABSTRACTQuantitative models that explicitly capture single-cell resolution cell-cell interaction features to predict patient survival at population scale are currently missing. Here, we computationally extracted hundreds of features describing single-cell based cell-cell interactions and cellular phenotypes from a large, published cohort of cyto-images of breast cancer patients. We applied these features to a neural-network based Cox-nnet survival model and obtained high accuracy in predicting patient survival in test data (Concordance Index > 0.8). We identified seven survival subtypes using the top survival features, which present distinct profiles of epithelial, immune, fibroblast cells, and their interactions. We identified atypical subpopulations of TNBC patients with moderate prognosis (marked by GATA3 over-expression) and Luminal A patients with poor prognosis (marked by KRT6 and ACTA2 over-expression and CDH1 under-expression). These atypical subpopulations are validated in TCGA-BRCA and METABRIC datasets. This work provides important guidelines on bridging single-cell level information towards population-level survival prediction.STATEMENT OF TRANSLATIONAL RELEVANCE Our findings from a breast cancer population cohort demonstrate the clinical utility of using the single-cell level imaging mass cytometry (IMC) data as a new type of patient prognosis prediction marker. Not only did the prognosis prediction achieve high accuracy with a Concordance index score greater than 0.8, it also enabled the discovery of seven survival subtypes that are more distinguishable than the molecular subtypes. These new subtypes present distinct profiles of epithelial, immune, fibroblast cells, and their interactions. Most importantly, this study identified and validated atypical subpopulations of TNBC patients with moderate prognosis (GATA3 over-expression) and Luminal A patients with poor prognosis (KRT6 and ACTA2 over-expression and CDH1 under-expression), using multiple large breast cancer cohorts."
A Neural Speech Decoding Framework Leveraging Deep Learning and Speech Synthesis,"Decoding human speech from neural signals is essential for brain-computer interface (BCI) technologies restoring speech function in populations with neurological deficits. However, it remains a highly challenging task, compounded by the scarce availability of neural signals with corresponding speech, data complexity, and high dimensionality, and the limited publicly available source code. Here, we present a novel deep learning-based neural speech decoding framework that includes an ECoG Decoder that translates electrocorticographic (ECoG) signals from the cortex into interpretable speech parameters and a novel differentiable Speech Synthesizer that maps speech parameters to spectrograms. We develop a companion audio-to-audio auto-encoder consisting of a Speech Encoder and the same Speech Synthesizer to generate reference speech parameters to facilitate the ECoG Decoder training. This framework generates natural-sounding speech and is highly reproducible across a cohort of 48 participants. Among three neural network architectures for the ECoG Decoder, the 3D ResNet model has the best decoding performance (PCC=0.804) in predicting the original speech spectrogram, closely followed by the SWIN model (PCC=0.796). Our experimental results show that our models can decode speech with high correlation even when limited to only causal operations, which is necessary for adoption by real-time neural prostheses. We successfully decode speech in participants with either left or right hemisphere coverage, which could lead to speech prostheses in patients with speech deficits resulting from left hemisphere damage. Further, we use an occlusion analysis to identify cortical regions contributing to speech decoding across our models. Finally, we provide open-source code for our two-stage training pipeline along with associated preprocessing and visualization tools to enable reproducible research and drive research across the speech science and prostheses communities."
Deep learning predictions of TCR-epitope interactions reveal epitope-specific chains in dual alpha T cells,"T cells have the ability to eliminate infected and cancer cells and play an essential role in cancer immunotherapy. T-cell activation is elicited by the binding of the T-cell receptor (TCR) to epitopes displayed on MHC molecules, and the TCR specificity is determined by the sequence of its α and β chains. Here, we collected and curated a dataset of 17,715 αβTCRs interacting with dozens of class I and class II epitopes. We used this curated data to develop MixTCRpred, a deep learning TCR-epitope interaction predictor. MixTCRpred accurately predicts TCRs recognizing several viral and cancer epitopes. MixTCRpred further provides a useful quality control tool for multiplexed single-cell TCR sequencing assays of epitope-specific T cells and pinpoints a substantial fraction of putative contaminants in public databases. Analysis of epitope-specific dual α T cells demonstrates that MixTCRpred can identify α chains mediating epitope recognition. Applying MixTCRpred to TCR repertoires from COVID-19 patients reveals enrichment of clonotypes predicted to bind an immunodominant SARS-CoV-2 epitope. Overall, MixTCRpred provides a robust tool to predict TCRs interacting with specific epitopes and interpret TCR-sequencing data from both bulk and epitope-specific T cells."
Rapid protein stability prediction using deep learning representations,"Predicting the thermodynamic stability of proteins is a common and widely used step in protein engineering, and when elucidating the molecular mechanisms behind evolution and disease. Here, we present RaSP, a method for making rapid and accurate predictions of changes in protein stability by leveraging deep learning representations. RaSP performs on-par with biophysics-based methods and enables saturation mutagenesis stability predictions in less than a second per residue. We use RaSP to calculate ∼ 300 million stability changes for nearly all single amino acid changes in the human proteome, and examine variants observed in the human population. We find that variants that are common in the population are substantially depleted for severe destabilization, and that there are substantial differences between benign and pathogenic variants, highlighting the role of protein stability in genetic diseases. RaSP is freely available—including via a Web interface—and enables large-scale analyses of stability in experimental and predicted protein structures."
Deep learning versus geometric morphometrics for archaeobotanical domestication study and subspecific identification,"Taxonomical identification of archaeological fruit and seed is of prime importance for any archaeobotanical studies. We compared the relative performance of deep learning and geometric morphometrics at identifying pairs of plant taxa. We used their seeds and fruit stones that are the most abundant recovered organs in archaeobotanical assemblages, and whose morphological identification, chiefly between wild and domesticated types, allow to document their domestication and biogeographical history. We used existing modern datasets of four plant taxa (date palm, barley, olive and grapevine) corresponding to photographs of two orthogonal views of their seeds that were analysed separately to offer a larger spectrum of shape diversity. On these eight datasets, we compared the performance of a deep learning approach, here convolutional neural networks (CNN), to that of a geometric morphometric approach, here outline analyses using elliptical Fourier transforms (EFT). Sample sizes were at minimum eight hundred seeds in each class, which is quite small when training deep learning models but of typical magnitude for archaeobotanical studies. Our objectives were twofold: i) to test whether deep learning can beat geometric morphometrics in taxonomic identification and if so, ii) to test which minimal sample size is required. We ran simulations on the full datasets and also on subsets, starting from 50 images in each binary class. For CNN networks, we deliberately used a candid approach relying on pre-parameterised VGG16 network. For EFT, we used a state-of-the art morphometrical pipeline. The main difference rests in the data used by each model: CNN used bare photographs where EFT used (x, y) outline coordinates. This “pre-distilled” geometrical description of seed outlines is often the most time-consuming part of morphometric studies. Results show that CNN beats EFT in most cases, even for very small datasets. We finally discuss the potential of CNN for archaeobotany, why outline analyses and morphometrics have not yet said their last word by providing quantitative descriptions, and how bioarchaeological studies could embrace both approaches, used in a complementary way, to better assess and understand the past history of species."
MalariaSED: a deep learning framework to decipher the regulatory contributions of noncoding variants in malaria parasites,"Malaria remains one of the deadliest infectious diseases. Transcriptional regulation effects of noncoding variants in this unusual genome of malaria parasites remain elusive. We developed a sequence-based, ab initio deep learning framework, MalariaSED, for predicting chromatin profiles in malaria parasites. The MalariaSED performance was validated by published ChIP-qPCR and TF motifs results. Applying MalariaSED to ∼1.3 million variants shows that geographically differentiated noncoding variants are associated with parasite invasion and drug resistance. Further analysis reveals chromatin accessibility changes at Plasmodium falciparum rings are partly associated with artemisinin resistance. MalariaSED illuminates the potential functional roles of noncoding variants in malaria parasites."
EMO: Predicting Non-coding Mutation-induced Up- and Down-regulation of Risk Gene Expression using Deep Learning,"Motivation Understanding how changes in non-coding DNAs regulate gene expression remains a formidable challenge with profound implications for advancing human genetics and disease research. Accurate prediction of the up- and down-regulation of gene expression quantitative trait loci (eQTL) can offer a potential solution to expedite the identification of non-coding variants associations with phenotypes. However, despite existing methods for predicting the impact of non-coding mutations on changes in gene expression, the current SOTA tool ‘Enformer’ still cannot accurately predict the sign of eQTLs. Moreover, the constraints of tissue specificity necessitate the utilization of distinct training models for each particular tissue type within existing methods. This hinders the extension of predictive capacities to the level of single-cell resolution.Results In this work, we introduce a novel transformer-based pretrained method, called EMO, to predict the up- and down-regulation of gene expression driven by single non-coding mutations from DNA sequences and ATAC-seq data. It extended the effective prediction range to 1Mbp between the non-coding mutation and the transcription start site (TSS) of the affected gene, with competitive prediction performance across various sequence lengths, outperforming the retrained Enformer structures. We fine-tuned EMO on the eQTLs of two brain tissues to evaluate its robustness through external validation. We also evaluated the transfer ability of EMO into the single-cell resolution by fine-tuning it on six types of immune single-cell eQTL, achieving satisfactory performance in all cell types (AUC > 0.860). EMO also showed its potential in handling disease-associated eQTLs.Availability and implementation The source code is freely available at https://github.com/Liuzhe30/EMO."
A deep-learning-based screening platform in aging-relevant human motor neurons to identify therapeutic compounds for amyotrophic lateral sclerosis,"Age is the primary risk factor for most neurodegenerative diseases including amyo-trophic lateral sclerosis (ALS). Despite the clear importance of age on the development and progression of ALS, age is rarely considered a factor in cellular or animal models of ALS. The recent advent of direct reprogramming methodologies, whereby somatic cells such as fibroblasts can be converted into neurons while retaining the age signature of the host, has facilitated the study of age-relevant human cells in vitro for the first time. Despite the promise of this technology, age is a complex, multidimensional, and dy-namic phenotype that makes the interpretation of the interplay between age and dis-ease a great challenge. To circumvent these challenges, we developed a screening platform for directly reprogrammed neurons in an age-relevant human cellular model to better model and identify disease-modifying targets and pathways for ALS. This plat-form uses deep learning image analysis to screen compounds for efficacy against ALS-associated cellular phenotypes and efficiently classifies ALS-like phenotypic signatures as well as predicts the age of the original fibroblast donor. Notably, our work identified NCB-0846, a TNIK/MAP4K7 inhibitor, as a novel compound with the ability to revert ALS-like phenotypes. Moreover, we show that chronic dosing of NCB-0846 in the SOD1G93A mouse model of ALS significantly reduced serum neurofilament-L levels. Our findings establish the power of a platform that combines direct reprogramming of human cells and deep learning as a powerful tool for combatting aging and age-related diseases."
Bacterial colony size growth estimation by deep learning,"ABSTRACTThe bacterial growth rate is important for pathogenicity and food safety. Therefore, the study of bacterial growth rate over time can provide important data from a medical and veterinary point of view. We trained convolutional neural networks (CNNs) on manually annotated solid medium cultures to detect bacterial colonies as accurately as possible. Predictions of bacterial colony size and growth rate were estimated from image sequences of independent Staphylococcus aureus cultures using trained CNNs. A simple linear model for control cultures with less than 150 colonies estimated that the mean growth rate was 60.3 μm/h for the first 24 h. Analyzing with a mixed effect model that also takes into account the effect of culture, smaller values of change in colony size were obtained (control: 51.0 μm/h, rifampicin pretreated: 36.5μm/h). An increase in the number of neighboring colonies clearly reduces the colony growth rate in the control group but less typically in the rifampicin-pretreated group. Based on our results, CNN-based bacterial colony detection and the subsequent analysis of bacterial colony growth dynamics might become an accurate and efficient tool for bacteriological work and research."
Self-supervised deep learning uncovers the semantic landscape of drug-induced latent mitochondrial phenotypes,"SUMMARYImaging-based high-content screening aims to identify substances that modulate cellular phenotypes. Traditional approaches screen compounds for their ability to shift disease phenotypes toward healthy phenotypes, but these end point-based screens lack an atlas-like mapping between phenotype and cell state that covers the full spectrum of possible phenotypic responses. In this study, we present MitoSpace: a novel mitochondrial phenotypic atlas that leverages self-supervised deep learning to create a semantically meaningful latent space from images without relying on any data labels for training. Our approach employs a dataset of ∼100,000 microscopy images of Cal27 and HeLa cells treated with 25 drugs affecting mitochondria, but can be generalized to any cell type, cell organelle, or drug library with no changes to the methodology. We demonstrate how MitoSpace enhances our understanding of the range of mitochondrial phenotypes induced by pharmacological interventions. We find that i) self-supervised learning can automatically uncover the semantic landscape of drug induced latent mitochondrial phenotypes and can map individual cells to the correct functional area of the drug they are treated with, ii) the traditional classification of mitochondrial morphology along a fragmented to fused axis is more complex than previously thought, with additional axes being identified, and iii) latent spaces trained in a self-supervised manner are superior to those trained with supervised models, and generalize to other cell types and drug conditions without explicit training on those cell types or drug conditions. Future applications of MitoSpace include creating mitochondrial biomarkers for drug discovery and determining the effects of unknown drugs and diseases for diagnostic purposes."
Deep Learning for Protein Structure Prediction: Advancements in Structural Bioinformatics,"Motivation Accurate prediction of protein structures is crucial for understanding protein function, stability, and interactions, with far-reaching implications in drug discovery and protein engineering. As the fields of structural bioinformatics and artificial intelligence continue to converge, a standardized model for protein structure prediction is still yet to be seen as even large models like AlphaFold continue to change architectures. To this end, we provide a comprehensive literature review highlighting the latest advancements and challenges in deep learning-based structure prediction, as well as a benchmark system for structure prediction and visualization of amino acid protein sequences.Results We present ProteiNN, a Transformer-based model for end-to-end single-sequence protein structure prediction, motivated by the need for accurate and efficient methods to decipher protein structures and their roles in biological processes and a system to perform prediction on user-input protein sequences. The model leverages the transformer architecture’s powerful representation learning capabilities to predict protein secondary and tertiary structures directly from integer-encoded amino acid sequences. Our results demonstrate that ProteiNN is effective in predicting secondary structures, though further improvements are necessary to enhance the model’s performance in predicting higher-level structures. This work thus showcases the potential of transformer-based architectures in structure prediction and lays the foundation for future research in structural bioinformatics and related fields.Availability and implementation The source code of ProteiNN is available at https://github.com/danielathome19/ProteiNN-Structure-Predictor."
FluoroTensor: identification and tracking of colocalised molecules and their stoichiometries in multi-colour single molecule imaging via deep learning,"The identification of photobleaching steps in single molecule fluorescence imaging is a well-established procedure for analysing the stoichiometries of molecular complexes. Nonetheless, the method is challenging with protein fluorophores because of the high levels of noise, rapid bleaching and very variable signal intensities, all of which complicate methods based on statistical analyses of intensities to identify bleaching steps. It has recently been shown that deep learning by convolutional neural networks can yield an accurate analysis with a relatively short computational time. We describe here an improved use of such an approach that detects bleaching events even in the first time point of observation, and we have included this within an integrated software package incorporating fluorescence spot detection, colocalisation, tracking, FRET and photobleaching step analyses of single molecules or complexes. This package, known as FluoroTensor, is written in Python with a self-explanatory user interface."
Deep Learning disconnectomes to accelerate and improve long-term predictions for post-stroke symptoms,"Deep learning as a truly transformative force is revolutionizing a wide range of fields, making a significant difference in medical imaging, where recent advancements have yielded some truly remarkable outcomes. In a connected brain, maps of white matter damage — otherwise known as disconnectomes — are essential for capturing the effects of focal lesions. However, the current tools for obtaining such information are prohibitively slow and not admitted for clinical usage. Here, we have explored the potential of deep-learning models to accurately generate disconnectomes in a population of stroke survivors. We trained a 3D U-Net algorithm to produce deep-disconnectomes from binary lesion masks. This artificial neural network was able to capture most information obtained in conventional disconnectomes, i.e., statistical maps filtering normative white-matter networks, but output a deep-disconnectome 170 times faster – compared to disconnectome computation with the state-of-the-art BCBToolkit software. Moreover, the deep-disconnectomes were challenged to predict cognitive and behavioral outcomes one-year post-stroke. In an additional cohort of N=139 stroke survivors, N=86 neuropsychological scores were predicted from deep-disconnectomes achieving, on average, 85.2% of accuracy and R2= 0.208. The deep-disconnectomes predictivity power outperformed the conventional disconnectome predictions for clinical scores.In summary, we have achieved a significant milestone for clinical neuroimaging by accelerating and ameliorating the creation of disconnectome maps using deep learning. By integrating deep learning into the management of stroke, one of the most prevailing catalysts for acquired disabilities, we deepen our understanding of its impact on the brain. This novel approach may offer potential avenues for acute intervention, ultimately enhancing patients’ overall quality of life."
Escalating High-dimensional Imaging using Combinatorial Channel Multiplexing and Deep Learning,"Understanding tissue structure and function requires tools that quantify the expression of multiple proteins at single-cell resolution while preserving spatial information. Current imaging technologies use a separate channel for each individual protein, inherently limiting their throughput and scalability. Here, we present CombPlex (COMBinatorial multiPLEXing), a combinatorial staining platform coupled with an algorithmic framework to exponentially increase the number of proteins that can be measured from C up to 2C − 1, and is applicable to any mass spectrometry-based or fluorescence-based microscopy platform. In CombPlex, every protein can be imaged in several channels, and every channel contains agglomerated images of several proteins. These combinatorically-compressed images are then decompressed to individual protein-images using deep learning and optimization. We perform feasibility experiments in silico and achieve accurate (F1=0.98, R=0.99) reconstruction for compressing the stains of twenty-two proteins to five imaging channels. We test our approach experimentally and obtain accurate (F1=0.97, R=0.93) images of seven proteins using three channels, both in fluorescence microscopy and in mass-based imaging. We demonstrate that combinatorial staining coupled with deep-learning decompression can serve to escalate the number of proteins measured using any imaging modality, without the need for specialized instrumentation. Coupling CombPlex with instruments for high-dimensional imaging could pave the way to image hundreds of proteins at single-cell resolution in intact tissue sections."
Caliban: Accurate cell tracking and lineage construction in live-cell imaging experiments with deep learning,"While live-cell imaging is a powerful approach for studying the dynamics of cellular systems, converting these imaging data into quantitative, single-cell records of cellular behavior has been a longstanding challenge. Deep learning methods have proven capable of performing cell segmentation—a critical task for analyzing live-cell imaging data—but their performance in cell tracking has been limited by a lack of dynamic datasets with temporally consistent single-cell labels. We bridge this gap through integrated development of labeling and deep learning methodology. We present a new framework for scalable, human-in-the-loop labeling of live-cell imaging movies, which we use to label a large collection of movies of fluorescently labeled cell nuclei. We use these data to create a new deep-learning-based cell-tracking method that achieves state-of-the-art performance in cell tracking. We have made all of the data, code, and software publicly available with permissive open-source licensing through the DeepCell project’s web portal https://deepcell.org."
Label-free deep learning-based species classification of bacteria imaged by phase-contrast microscopy,"Reliable detection and classification of bacteria and other pathogens in the human body, animals, food, and water is crucial for improving and safeguarding public health. For instance, identifying the species and its antibiotic susceptibility is vital for effective bacterial infection treatment. Here we show that phase contrast time-lapse microscopy combined with deep learning is sufficient to discriminate four species of bacteria relevant to human health. The classification is performed on living bacteria and does not require fixation or staining, meaning that the bacterial species can be determined as the bacteria reproduce in a microfluidic device, enabling parallel determination of susceptibility to antibiotics. We assess the performance of convolutional neural networks and vision transformers, where the best model attained a class-average accuracy exceeding 98%. Our successful proof-of-principle results suggest that the methods should be challenged with data covering more species and clinically relevant isolates for future clinical use.Author Summary Bacterial infections are a leading cause of premature death worldwide, and growing antibiotic resistance is making treatment increasingly challenging. To effectively treat a patient with a bacterial infection, it is essential to quickly detect and identify the bacterial species and determine its susceptibility to different antibiotics. Prompt and effective treatment is crucial for the patient’s survival. A microfluidic device functions as a miniature “lab-on-chip” for manipulating and analyzing tiny amounts of fluids, such as blood or urine samples from patients. Microfluidic chips with chambers and channels have been designed for quickly testing bacterial susceptibility to different antibiotics by analyzing bacterial growth. Identifying bacterial species has previously relied on killing the bacteria and applying species-specific fluorescent probes. We introduce deep learning models as a fast and cost-effective method for identifying bacteria species directly from phase-contrast microscopy images of living bacteria simultaneously as growth is analyzed. We envision this method being employed concurrently with antibiotic susceptibility tests in future applications, significantly enhancing bacterial infection treatments."
Deep learning-assisted single-molecule detection of protein post-translational modifications with a biological nanopore,"Protein post-translational modifications (PTMs) play a crucial role in countless biological processes, profoundly modulating protein properties on both the spatial and temporal scales. Protein PTMs have also emerged as reliable biomarkers for several diseases. However, only a handful of techniques are available to accurately measure their levels, capture their complexity at a single molecule level and characterize their multifaceted roles in health and disease. Nanopore sensing provides high sensitivity for the detection of low-abundance proteins, holding the potential to impact single-molecule proteomics and PTM detection in particular. Here, we demonstrate the ability of a biological nanopore, the pore-forming toxin aerolysin, to detect and distinguish α-synuclein-derived peptides bearing single or multiple PTMs, namely phosphorylation, nitration and oxidation occurring at different positions and in various combinations. The characteristic current signatures of the α-synuclein peptide and its PTM variants could be confidently identified using a deep learning model for signal processing. We further demonstrate that this framework can quantify α-synuclein peptides at picomolar concentration and detect the C-terminal peptides generated by digestion of full-length α-synuclein. Collectively, our work highlights the unique advantage of using nanopore as a tool for simultaneous detection of multiple PTMs and paves the way for their use in biomarker discovery and diagnostics."
scMeFormer: a transformer-based deep learning model for imputing DNA methylation states in single cells enhances the detection of epigenetic alterations in schizophrenia,"DNA methylation (DNAm), a crucial epigenetic mark, plays a key role in gene regulation, mammalian development, and various human diseases. Single-cell technologies enable the profiling of DNAm states at cytosines within the DNA sequence of individual cells, but they often suffer from limited coverage of CpG sites. In this study, we introduce scMeFormer, a transformer-based deep learning model designed to impute DNAm states for each CpG site in single cells. Through comprehensive evaluations, we demonstrate the superior performance of scMeFormer compared to alternative models across four single-nucleus DNAm datasets generated by distinct technologies. Remarkably, scMeFormer exhibits high-fidelity imputation, even when dealing with significantly reduced coverage, as low as 10% of the original CpG sites. Furthermore, we applied scMeFormer to a single-nucleus DNAm dataset generated from the prefrontal cortex of four schizophrenia patients and four neurotypical controls. This enabled the identification of thousands of differentially methylated regions associated with schizophrenia that would have remained undetectable without imputation and added granularity to our understanding of epigenetic alterations in schizophrenia within specific cell types. Our study highlights the power of deep learning in imputing DNAm states in single cells, and we expect scMeFormer to be a valuable tool for single-cell DNAm studies."
Unraveling Neuronal Identities Using SIMS: A Deep Learning Label Transfer Tool for Single-Cell RNA Sequencing Analysis,"Large single-cell RNA datasets have contributed to unprecedented biological insight. Often, these take the form of cell atlases and serve as a reference for automating cell labeling of newly sequenced samples. Yet, classification algorithms have lacked the capacity to accurately annotate cells, particularly in complex datasets. Here we present SIMS (Scalable, Interpretable Ma-chine Learning for Single-Cell), an end-to-end data-efficient machine learning pipeline for discrete classification of single-cell data that can be applied to new datasets with minimal coding. We benchmarked SIMS against common single-cell label transfer tools and demonstrated that it performs as well or better than state of the art algorithms. We then use SIMS to classify cells in one of the most complex tissues: the brain. We show that SIMS classifies cells of the adult cerebral cortex and hippocampus at a remarkably high accuracy. This accuracy is maintained in trans-sample label transfers of the adult hu-man cerebral cortex. We then apply SIMS to classify cells in the developing brain and demonstrate a high level of accuracy at predicting neuronal sub-types, even in periods of fate refinement, shedding light on genetic changes affecting specific cell types across development. Finally, we apply SIMS to single cell datasets of cortical organoids to predict cell identities and unveil genetic variations between cell lines. SIMS identifies cell-line differences and misannotated cell lineages in human cortical organoids derived from different pluripotent stem cell lines. When cell types are obscured by stress signals, label transfer from primary tissue improves the accuracy of cortical organoid annotations, serving as a reliable ground truth. Altogether, we show that SIMS is a versatile and robust tool for cell-type classification from single-cell datasets."
Improved estimation of molecular evolution coupling stochastic simulations and deep learning,"Models have always been central to inferring molecular evolution and to reconstructing phylogenetic trees. Their use typically involves the development of a mechanistic framework reflecting our understanding of the underlying biological processes, such as nucleotide substitutions, and the estimation of model parameters by maximum likelihood or Bayesian inference. However, deriving and optimizing the likelihood of the data is not always possible under complex evolutionary scenarios or tractable for large datasets, often leading to unrealistic simplifying assumptions in the fitted models. To overcome this issue, we couple stochastic simulations of genome evolution with a new supervised deep learning model to infer key parameters of molecular evolution. Our model is designed to directly analyze multiple sequence alignments and estimate per-site evolutionary rates and divergence, without requiring a known phylogenetic tree. The accuracy of our predictions matches that of likelihood-based phylogenetic inference, when rate heterogeneity follows a simple gamma distribution, but it strongly exceeds it under more complex patterns of rate variation, such as codon models. Our approach is highly scalable and can be efficiently applied to genomic data, as we show on a dataset of 26 million nucleotides from the clownfish clade. Our simulations also show that the per-site rates obtained by deep learning increase the likelihood of the true tree and could therefore lead to more accurate phylogenetic inference. We propose that future advancements in phylogenetic analysis will benefit from a semi-supervised learning approach that combines deep-learning estimation of substitution rates, which allows for more flexible models of rate variation, and probabilistic inference of the phylogenetic tree, which guarantees interpretability and a rigorous assessments of statistical support."
Cross-Sampling Rate Transfer Learning for Enhanced Raw EEG Deep Learning Classifier Performance in Major Depressive Disorder Diagnosis,"ABSTRACTTransfer learning offers a route for developing robust deep learning models on small raw electroencephalography (EEG) datasets. Nevertheless, the utility of applying representations learned from large datasets with a lower sampling rate to smaller datasets with higher sampling rates remains relatively unexplored. In this study, we transfer representations learned by a convolutional neural network on a large, publicly available sleep dataset with a 100 Hertz sampling rate to a major depressive disorder (MDD) diagnosis task at a sampling rate of 200 Hertz. Importantly, we find that the early convolutional layers contain representations that are generalizable across tasks. Moreover, our approach significantly increases mean model accuracy from 82.33% to 86.99%, increases the model’s use of lower frequencies, (θ-band), and increases its robustness to channel loss. We expect this analysis to provide useful guidance and enable more widespread use of transfer learning in EEG deep learning studies."
A robust and flexible deep-learning workflow for animal tracking,"Developments in automated animal tracking software are increasing the efficiency of data collection and improving the standardization of behavioural measurements. There are now several open-source tools for tracking laboratory animals, but often these are only accurate under limited conditions (e.g. uniform lighting and background, uncluttered scenes, unobstructed focal animal). Tracking fish presents a particular challenge for these tools because movement at the water’s surface introduces significant noise. Partial occlusion of the focal animal can also be troublesome, particularly when tracking the whole organism. We conducted a behavioural experiment that required us to track the trajectory of a fish as it swam through a field of obstacles. In addition to measuring the body’s trajectory, we also needed to record the position of the obstacles, and to identify when the fish passed through the ‘virtual gates’ between adjacent obstacles and/or the aquarium wall. We automated data collection by employing a range of computer vision and computational geometry algorithms (e.g. object detection and tracking, optical flow, parallel plane homology mapping, Voronoi tessellation). Our workflow is divided into several discrete steps, and provides a set of modular software building blocks that can be adapted to analyse other experimental designs. A detailed tutorial is provided, together with all the data and code required to reproduce our results."
Deep learning classification of ex vivo human colon tissues using spectroscopic OCT,"Screening programs for colorectal cancer (CRC) have had a profound impact on the morbidity and mortality of this disease by detecting and removing early cancers and precancerous adenomas with colonoscopy. However, CRC continues to be the third leading cause of cancer-related mortality in both men and woman, partly because of limitations in colonoscopy-based screening. Thus, novel strategies to improve the efficiency and effectiveness of screening colonoscopy are urgently needed. Here, we propose to address this need using an optical biopsy technique based on spectroscopic optical coherence tomography (OCT). The depth resolved images obtained with OCT are analyzed as a function of wavelength to measure optical tissue properties. The optical properties can be used as input to machine learning algorithms as a means to classify adenomatous tissue in the colon. In this study, biopsied tissue samples from the colonic epithelium are analyzed ex vivo using spectroscopic OCT and tissue classifications are generated using a novel deep learning architecture, informed by machine learning methods including LSTM and KNN. The overall classification accuracy obtained was 88.9%, 76.0% and 97.9% in discriminating tissue type for these methods. Further, we apply an approach using false coloring of en face OCT images based on SOCT parameters and deep learning predictions to enable visual identification of tissue type. This study advances the spectroscopic OCT towards clinical utility for analyzing colonic epithelium for signs of adenoma."
Poor Generalization by Current Deep Learning Models for Predicting Binding Affinities of Kinase Inhibitors,"The extreme surge of interest over the past decade surrounding the use of neural networks has inspired many groups to deploy them for predicting binding affinities of drug-like molecules to their receptors. A model that can accurately make such predictions has the potential to screen large chemical libraries and help streamline the drug discovery process. However, despite reports of models that accurately predict quantitative inhibition using protein kinase sequences and inhibitors’ SMILES strings, it is still unclear whether these models can generalize to previously unseen data. Here, we build a Convolutional Neural Network (CNN) analogous to those previously reported and evaluate the model over four datasets commonly used for inhibitor/kinase predictions. We find that the model performs comparably to those previously reported, provided that the individual data points are randomly split between the training set and the test set. However, model performance is dramatically deteriorated when all data for a given inhibitor is placed together in the same training/testing fold, implying that information leakage underlies the models’ performance. Through comparison to simple models in which the SMILES strings are tokenized, or in which test set predictions are simply copied from the closest training set data points, we demonstrate that there is essentially no generalization whatsoever in this model. In other words, the model has not learned anything about molecular interactions, and does not provide any benefit over much simpler and more transparent models. These observations strongly point to the need for richer structure-based encodings, to obtain useful prospective predictions of not-yet-synthesized candidate inhibitors."
"Deep Learning for Protein–peptide binding Prediction: Incorporating Sequence, Structural and Language Model Features","ABSTRACTProtein-peptide interactions play a crucial role in various cellular processes and are implicated in abnormal cellular behaviors leading to diseases such as cancer. Therefore, understanding these interactions is vital for both functional genomics and drug discovery efforts. Despite a significant increase in the availability of protein-peptide complexes, experimental methods for studying these interactions remain laborious, time-consuming, and expensive. Computational methods offer a complementary approach but often fall short in terms of prediction accuracy. To address these challenges, we introduce PepCNN, a deep learning-based prediction model that incorporates structural and sequence-based information from primary protein sequences. By utilizing a combination of half-sphere exposure, position specific scoring matrices, and pre-trained transformer language model, PepCNN outperforms state-of-the-art methods in terms of specificity, precision, and AUC. The PepCNN software and datasets are publicly available at https://github.com/abelavit/PepCNN.git."
Application of a 1H Brain MRS Benchmark Dataset to Deep Learning for Out-of-Voxel Artifacts,"Neural networks are potentially valuable for many of the challenges associated with MRS data. The purpose of this manuscript is to describe the AGNOSTIC dataset, which contains 259,200 synthetic 1H MRS examples for training and testing neural networks. AGNOSTIC was created using 270 basis sets that were simulated across 18 field strengths and 15 echo times. The synthetic examples were produced to resemble in vivo brain data with combinations of metabolite, macromolecule, residual water signals, and noise. To demonstrate the utility, we apply AGNOSTIC to train two Convolutional Neural Networks (CNNs) to address out-of-voxel (OOV) echoes. A Detection Network was trained to identify the point-wise presence of OOV echoes, providing proof of concept for real-time detection. A Prediction Network was trained to reconstruct OOV echoes, allowing subtraction during post-processing. Complex OOV signals were mixed into 85% of synthetic examples to train two separate CNNs for the detection and prediction of OOV signals. AGNOSTIC is available through Dryad and all Python 3 code is available through GitHub. The Detection network was shown to perform well, identifying 95% of OOV echoes. Traditional modeling of these detected OOV signals was evaluated and may prove to be an effective method during linear-combination modeling. The Prediction Network greatly reduces OOV echoes within FIDs and achieved a median log10 normed-MSE of –1.79, an improvement of almost two orders of magnitude."
PyHFO: Lightweight Deep Learning-powered End-to-End High-Frequency Oscillations Analysis Application,"In the context of epilepsy studies, intracranially-recorded interictal high-frequency oscillations (HFOs) in EEG signals are emerging as promising spatial neurophysiological biomarkers for epileptogenic zones. While significant efforts have been made in identifying and understanding these biomarkers, deep learning is carving novel avenues for biomarker detection and analysis. Yet, transitioning such methodologies to clinical environments is difficult due to the rigorous computational needs of processing EEG data via deep learning. This paper presents our development of an advanced end to end software platform, PyHFO, aimed at bridging this gap. PyHFO provides an integrated and user-friendly platform that includes time-efficient HFO detection algorithms such as short-term energy (STE) and Montreal Neurological Institute and Hospital (MNI) detectors and deep learning models for artifact and HFO with spike classification. This application functions seamlessly on conventional computer hardware. Our platform has been validated to adeptly handle datasets from 10-minute EEG recordings captured via grid/strip electrodes in 19 patients. Through implementation optimization, PyHFO achieves speeds up to 50 times faster than the standard HFO detection method. Users can either employ our pre-trained deep learning model for their analyses or use their EEG data to train their model. As such, PyHFO holds great promise for facilitating the use of advanced EEG data analysis tools in clinical practice and large-scale research collaborations."
AutoHiC: a deep-learning method for automatic and accurate chromosome-level genome assembly,"An accurate genome at the chromosome level is the key to unraveling the mysteries of gene function and unlocking the mechanisms of disease. Irrespective of the sequencing methodology adopted, Hi-C aided scaffolding serves as a principal avenue for generating genome assemblies at the chromosomal level. However, the results of such scaffolding are often flawed and require extensive manual refinement. In this paper, we introduce AutoHiC, an innovative deep learning-based tool designed to identify and rectify genome assembly errors. Diverging from conventional approaches, AutoHiC harnesses the power of high-dimensional Hi-C data to enhance genome continuity and accuracy through a fully automated workflow and iterative error correction mechanism. AutoHiC was trained on Hi-C data from more than 300 species (approximately five hundred thousand interaction maps) in DNA Zoo and NCBI. Its confusion matrix results show that the average error detection accuracy is over 90%, and the area under the precision-recall curve is close to 1, making it a powerful error detection capability. The benchmarking results demonstrate AutoHiC’s ability to substantially enhance genome continuity and significantly reduce error rates, providing a more reliable foundation for genomics research. Furthermore, AutoHiC generates comprehensive result reports, offering users insights into the assembly process and outcomes. In summary, AutoHiC represents a breakthrough in automated error detection and correction for genome assembly, effectively promoting more accurate and comprehensive genome assemblies."
PoseR - A deep learning toolbox for decoding animal behavior,"The actions of animals provide a window into how their minds work. Recent advances in deep learning are providing powerful approaches to recognize patterns of animal movement from video recordings, including markerless pose estimation models. However, tools to efficiently parse coordinates of animal position and pose into meaningful semantic behavioral labels are lacking. Here, we present PoseRecognition (PoseR), a behavioral decoder leveraging state- of-the-art action recognition models using spatio-temporal graph convolutional networks. We show that it can be used to decode animal behavior quickly and accurately from pose estimations, using zebrafish larvae and mice as model organisms. PoseR can be accessed using a Napari plugin, which facilitates efficient behavioral extraction, annotation, model training and deployment. We have simplified the workflow of behavioral analysis after pose estimation, transforming coordinates of animal position and pose into meaningful semantic behavioral labels, using methods designed for fast and accurate behavioral extraction, annotation, model training and deployment. Furthermore, we contribute a novel method for unsupervised clustering of behaviors and provide open-source access to our zebrafish datasets and models. The design of our tool ensures scalability and versatility for use across multiple species and contexts, improving the efficiency of behavioral analysis across fields."
A Deep Learning method for classification of HNSCC and HPV patients using single-cell transcriptomics,"Head and Neck Squamous Cell Carcinoma (HNSCC) is the seventh most highly prevalent cancer type worldwide. Early detection of HNSCC is one of the important challenges in managing the treatment of the cancer patients. Existing techniques for detecting HNSCC are costly, expensive, and invasive in nature. In this study, we aimed to address this issue by developing classification models using machine learning and deep learning techniques, focusing on single-cell transcriptomics to distinguish between HNSCC and normal samples. Additionally, we built models to classify HNSCC samples into HPV-positive (HPV+) and HPV-negative (HPV-) categories. The models developed in this study have been trained on 80% of the GSE181919 dataset and validated on the remaining 20%. To develop an efficient model, we performed feature selection using mRMR method to shortlist a small number of genes from a plethora of genes. Artificial Neural Network based model trained on 100 genes outperformed the other classifiers with an AUROC of 0.91 for HNSCC classification for the validation set. The same algorithm achieved an AUROC of 0.83 for the classification of HPV+ and HPV-patients on the validation set. We also performed Gene Ontology (GO) enrichment analysis on the 100 shortlisted genes and found that most genes were involved in binding and catalytic activities. To facilitate the scientific community, a software package has been developed in Python which allows users to identify HNSCC in patients along with their HPV status. It is available at https://webs.iiitd.edu.in/raghava/hnscpred/.Key PointsApplication of single cell transcriptomics in cancer diagnosisDevelopment of models for predicting HNSCC patientsClassification of HPV+ and HPV-HNSCC patientsIdentification of gene biomarkers from single cell sequencingA standalone software package HNSCpred for predicting HNSCC patientsAuthor’s BiographyAkanksha Jarwal is currently pursuing an M. Tech. in Computational Biology at the Department of Computational Biology, Indraprastha Institute of Information Technology, New Delhi, India.Anjali Dhall is currently pursuing a Ph.D. in Computational Biology at the Department of Computational Biology, Indraprastha Institute of Information Technology, New Delhi, India.Akanksha Arora is currently pursuing a Ph.D. in Computational Biology at the Department of Computational Biology, Indraprastha Institute of Information Technology, New Delhi, India.Sumeet Patiyal is currently pursuing a Ph.D. in Computational Biology at the Department of Computational Biology, Indraprastha Institute of Information Technology, New Delhi, India.Aman Srivastava is currently pursuing an M. Tech. in Computational Biology at the Department of Computational Biology, Indraprastha Institute of Information Technology, New Delhi, India.Gajendra P. S. Raghava is currently working as a Professor and Head of the Department of Computational Biology, Indraprastha Institute of Information Technology, New Delhi, India."
A deep learning phenotyping method for genetic analysis of 3D micro-CT data,"The number of Genome-Wide Association Studies (GWAS) has been growing rapidly in recent years due to developments in genotyping and sequencing platforms. When applied to quantitative traits, these and other statistical genetics approaches require large amounts of consistently and accurately measured phenotypes. Here, we introduce a computational toolbox based on deep convolutional neural networks that we have developed to phenotype quantitative traits describing morphology from micro-CT-scan image datasets. We illustrate the use of this Deep Learning Phenotyper (DLP) on a sample set of craniofacial CT scans of 118 samples from two very closely related species of Lake Malawi cichlid fish, Maylandia zebra and Cynotilapia zebroides. We show that the pipeline constructed and implemented here is capable of measuring morphological skeletal phenotypes with high accuracy. We also demonstrate how this pipeline can be integrated with existing GWAS frameworks to identify candidate association loci. We believe the methods we present here will be valuable for groups studying quantitative morphological traits not only in fishes, but in other vertebrates using CT scan datasets."
Implementation considerations for deep learning with diffusion MRI streamline tractography,"One area of medical imaging that has recently experienced innovative deep learning advances is diffusion MRI (dMRI) streamline tractography with recurrent neural networks (RNNs). Unlike traditional imaging studies which utilize voxel-based learning, these studies model dMRI features at points in continuous space off the voxel grid in order to propagate streamlines, or virtual estimates of axons. However, implementing such models is nontrivial, and an open-source implementation is not yet widely available. Here, we describe a series of considerations for implementing tractography with RNNs and demonstrate they allow one to approximate a deterministic streamline propagator with comparable performance to existing algorithms. We release this trained model and the associated implementations leveraging popular deep learning libraries. We hope the availability of these resources will lower the barrier of entry into this field, spurring further innovation."
Reconstruction of compartmentalized genome-scale metabolic models using deep learning for over 800 fungi,"Eukaryotic metabolism is organized into subcellular compartments enclosed by lipid-membranes. Since most metabolites do not move freely across the membranes, the compartmentalization influences metabolic pathway connectivities. Thus, compartmentalizing the pathways also in genome-scale metabolic models (GEMs) is essential for accurate predictions of eukaryotic cells’ metabolic phenotypes. Compartmentalization has manually been introduced into the model Eukaryote GEMs like for yeast Saccharomyces cerevisiae. Non-model organisms’ GEMs can be automatically reconstructed from genome data. However, the existing GEM reconstruction methods do not introduce compartmentalization into the models. To that end, we integrated our novel deep learning protein localization prediction and protein functional annotation into a top-down GEM reconstruction for automatically creating species-specific compartmentalized GEMs. We developed also a universal fungal GEM for top-down reconstruction of species-specifically compartmentalized GEMs and reconstructed models for 834 species. The novel protein localization prediction outperformed the state of the art in classifying proteins into multiple compartments and integrating the enzyme localization predictions to functional annotations improved the top-down model reconstruction. Interestingly, the clustering of the fungal GEMs reconstructed with predicted species-specific enzyme localization resembled more closely the phylogenetic relationships of the species than that of the GEMS without the compartmentalization. Compartmentalization of metabolism in fungi differs from other eukaryotes but the enzyme subcellular localizations vary also among fungal species. The Fungal kingdom encompasses species important for human health, environment, and industrial biotechnology. The reconstructed fungal GEM set offers valuable tools for e.g., predicting metabolic phenotypes of e.g., mushrooms or single-cellular fungi, the roles of eukaryotes in microbial communities, designs optimizing eukaryotic hosts for industrial chemical production, and identifying drug targets against pathogenic fungi. Beyond fungi, the compartmentalized GEM reconstruction method allows combining other universal GEMs for developing cell type specific GEMs for higher eukaryotes including plants, insects, and mammals."
SC2Spa: a deep learning based approach to map transcriptome to spatial origins at cellular resolution,"Integrating single cell RNAseq (scRNAseq) and spatial transcriptomics (ST) data is still challenging especially when the spatial resolution is poor. For cellular resolution spatial mapping, we have developed deep learning-based SC2Spa to learn the intricate spatial mapping rules from the transcriptome to its location from ST data. Benchmarking tests show that SC2Spa uniquely recapitulates tissue architecture from scRNAseq. SC2Spa successfully mapped scRNAseq even to various low resolution Visium data. SC2Spa identified spatially variable genes and suggested negative regulatory relationships between genes. SC2Spa armored with deep learning provides a new way to map the transcriptome to its spatial location and perform subsequent analyses."
Automated segmentation by deep learning of neuritic plaques and neurofibrillary tangles in brain sections of Alzheimer’s Disease Patients,"Alzheimer’s Disease (AD) is a neurodegenerative disorder with complex neuropathological features, such as phosphorylated tau (p-tau) positive neurofibrillary tangles (NFTs) and neuritic plaques (NPs). The quantitative evaluation of p-tau pathology is a key element for the diagnosis of AD and other tauopathies. Assessment of tauopathies relies on semi-quantitative analysis and does not consider lesions heterogeneity (e.g., load and density of NFTs vs NPs).In this study, we developed a deep learning-based workflow for automated annotation and segmentation of NPs and NFTs from AT8-immunostained whole slide images (WSIs) of AD brain sections. Fifteen WSIs of frontal cortex from four biobanks with different tissue quality, staining intensity and scanning formats were used for the present study. We first applied an artificial intelligence (AI-)-driven iterative procedure to improve the generation of pathologist validated training datasets for NPs and NFTs. This procedure increased the annotation quality by more than 50%, especially for NPs when present in high density. Using this procedure, we obtained an expert validated annotation database with 5013 NPs and 5143 NFTs. As a second step, we trained two U-Net convolutional neural networks (CNNs) for accurate detection and segmentation of NPs or NFTs. The workflow achieved a high accuracy and consistency, with a mean Dice similarity coefficient of 0.81 for NPs and 0.77 for NFTs. The workflow also showed good generalization performance across different patients with different staining and tissue quality. Our study demonstrates that artificial intelligence can be used to correct and enhance annotation quality especially for complex objects, even when intermingled and present in high density, in brain tissue. Furthermore, the expert validated databases allowed to generate highly accurate models for segmenting discrete brain lesions using a commercial software. Our annotation database will be publicly available to facilitate human digital pathology applied to AD."
Integrating AlphaFold and deep learning for atomistic interpretation of cryo-EM maps,"Interpretation of cryo-electron microscopy (cryo-EM) maps requires building and fitting 3-D atomic models of biological molecules. AlphaFold-predicted models generate initial 3-D coordinates; however, model inaccuracy and conformational heterogeneity often necessitate labor-intensive manual model building and fitting into cryo-EM maps. In this work, we designed a protein modelbuilding workflow, which combines a deep-learning cryo-EM map feature enhancement tool, CryoFEM (Cryo-EM Feature Enhancement Model) and AlphaFold. A benchmark test using 36 cryo-EM maps shows that CryoFEM achieves state-of-the-art performance in optimizing the Fourier Shell Correlations between the maps and the ground truth models. Furthermore, in a subset of 17 datasets where the initial AlphaFold predictions are less accurate, the workflow significantly improves their model accuracy. Our work demonstrates that the integration of modern deep learning image enhancement and AlphaFold may lead to automated model building and fitting for the atomistic interpretation of cryo-EM maps."
Identifying keystone species in microbial communities using deep learning,"Previous studies suggested that microbial communities harbor keystone species whose removal can cause a dramatic shift in microbiome structure and functioning. Yet, an efficient method to systematically identify keystone species in microbial communities is still lacking. This is mainly due to our limited knowledge of microbial dynamics and the experimental and ethical difficulties of manipulating microbial communities. Here, we propose a Data-driven Keystone species Identification (DKI) framework based on deep learning to resolve this challenge. Our key idea is to implicitly learn the assembly rules of microbial communities from a particular habitat by training a deep learning model using microbiome samples collected from this habitat. The well-trained deep learning model enables us to quantify the community-specific keystoneness of each species in any microbiome sample from this habitat by conducting a thought experiment on species removal. We systematically validated this DKI framework using synthetic data generated from a classical population dynamics model in community ecology. We then applied DKI to analyze human gut, oral microbiome, soil, and coral microbiome data. We found that those taxa with high median keystoneness across different communities display strong community specificity, and many of them have been reported as keystone taxa in literature. The presented DKI framework demonstrates the power of machine learning in tackling a fundamental problem in community ecology, paving the way for the data-driven management of complex microbial communities."
ClairS: a deep-learning method for long-read somatic small variant calling,"Identifying somatic variants in tumor samples is a crucial task, which is often performed using statistical methods and heuristic filters applied to short-read data. However, with the increasing demand for long-read somatic variant calling, existing methods have fallen short. To address this gap, we present ClairS, the first deep-learning-based, long-read somatic small variant caller. ClairS was trained on massive synthetic somatic variants with diverse coverages and variant allele frequencies (VAF), enabling it to accurately detect a wide range of somatic variants from paired tumor and normal samples. We evaluated ClairS using the latest Nanopore Q20+ HCC1395-HCC1395BL dataset. With 50-fold/25-fold tumor/normal, ClairS achieved a 93.01%/86.86% precision/recall rate for Single Nucleotide Variation (SNVs), and 66.54%/66.89% for somatic insertions and deletions (Indels). Applying ClairS to short-read datasets from multiple sources showed comparable or better performance than Strelka2 and Mutect2. Our findings suggest that improved read phasing enabled by long-read sequencing is key to accurate long-read SNV calling, especially for variants with low VAF. Through experiments across various coverage, purity, and contamination settings, we demonstrated that ClairS is a reliable somatic variant caller. ClairS is open-source at https://github.com/HKU-BAL/ClairS."
Deep Learning Enhanced Tandem Repeat Variation Identification via Multi-Modal Conversion of Nanopore Reads Alignment,"Identification of tandem repeat (TR) variations plays a crucial role in advancing our understanding of genetic diseases, forensic analysis, evolutionary studies, and crop improvement, thereby contributing to various fields of research and practical applications. However, traditional TR identification methods are often limited to processing genomes obtained through sequence assembly and cannot directly start detection from sequencing reads. Furthermore, the inflexibility of detection mode and parameters hinders the accuracy and completeness of the identification, rendering the results unsatisfactory. These shortcomings result in existing TR variation identification methods being associated with high computational cost, limited detection sensitivity, precision and comprehensiveness. Here, we propose DeepTRs, a novel method for identifying TR variations, which enables direct TR variation identification from raw Nanopore sequencing reads and achieves high sensitivity, accuracy, and completeness results through the multi-modal conversion of Nanopore reads alignment and deep learning. Comprehensive evaluations demonstrate that DeepTRs outperform existing methods."
3D single-cell shape analysis using geometric deep learning,"Aberrations in 3D cell morphogenesis are linked to diseases such as cancer. Yet there is little systems-level understanding of cell shape determination in 3D, largely because there is a paucity of data-driven methods to quantify and describe 3D cell shapes. We have addressed this need using unsupervised geometric deep learning to learn shape representations of over 95,000 melanoma cells imaged by 3D high-throughput light-sheet microscopy. We used a dynamic graph convolutional foldingnet autoencoder with improved deep embedded clustering to simultaneously learn lower-dimensional representations and classes of 3D cell shapes. We describe a landscape of 3D cell morphology using deep learning-derived 3D quantitative morphological signatures (3DQMS) across different substrate geometries, following treatment by different clinically relevant small molecules and systematic gene depletion in high-throughput. By data integration, we predict modes of action for different small molecules providing mechanistic insights and blueprints for biological re-engineering. Finally, we provide explainability and interpretability for deep learning models."
A Deep Learning Approach to Detecting Temporal Characteristics of Cortical Regions,"One view of the neocortical architecture is that every region functions based on a universal computational principle. Contrary to this, we postulated that each cortical region has its own specific algorithm and functional properties. This idea led us to hypothesize that unique temporal patterns should be associated with each region, with the functional commonalities and variances among regions reflecting in the temporal structure of their neural signals. To investigate these hypotheses, we employed deep learning to predict electrodes locations in the macaque brain using single-channel ECoG signals. To do this, we first divided the brain into seven regions based on anatomical landmarks, and trained a deep learning model to predict the electrode location from the ECoG signals. Remarkably, the model achieved an average accuracy of 33.6%, significantly above the chance level of 14.3%. All seven regions exhibited above-chance prediction accuracy. The model’s feature vectors identified two main clusters: one including higher visual areas and temporal cortex, and another encompassing the remaining other regions.These results bolster the argument for unique regional dynamics within the cortex, highlighting the diverse functional specializations present across cortical areas."
Using deep-learning to obtain calibrated individual disease and ADL damage transition probabilities between successive ELSA waves,"We predictively model damage transition probabilities for binary health outputs of 19 diseases and 25 activities of daily living states (ADLs) between successive waves of the English Longitudinal Study of Aging (ELSA). Model selection between deep neural networks (DNN), random forests, and logistic regression found that a simple one-hidden layer 128-node DNN was best able to predict future health states (AUC ≥ 0.91) and average damage probabilities (R2 ≥ 0.92). Feature selection from 134 explanatory variables found that 33 variables are sufficient to predict all disease and ADL states well. Deciles of predicted damage transition probabilities were well calibrated, but correlations between predicted health states were stronger than observed. The hazard ratios (HRs) between high-risk deciles and the average were between 3 and 10; high prevalence damage transitions typically had smaller HRs. Model predictions were good across all individual ages. A simple one-hidden layer DNN predicts multiple binary diseases and ADLs with well calibrated damage and repair transition probabilities."
DLTKcat: deep learning based prediction of temperature dependent enzyme turnover rates,"The enzyme turnover rate, kcat, quantifies enzyme kinetics by indicating the maximum efficiency of enzyme catalysis. Despite its importance, kcat values remain scarce in databases for most organisms, primarily due to the cost of experimental measurements. To predict kcat and account for its strong temperature dependence, DLTKcat was developed in this study and demonstrated superior performance (log10-scale RMSE = 0.88, R2 = 0.66) than previously published models. Through two case studies, DLTKcat showed its ability to predict the effect of protein sequence mutations and temperature changes on kcat values. Although its quantitative accuracy is not high enough yet to model the responses of cellular metabolism to temperature changes, DLTKcat has the potential to eventually become a computational tool to describe the temperature dependence of biological systems."
High-Throughput and Accurate 3D Scanning of Cattle Using Time-of-Flight Sensors and Deep Learning,"We introduce a high throughput 3D scanning solution specifically designed to precisely measure cattle phenotypes. This scanner leverages an array of depth sensors, i.e. time-of-flight (Tof) sensors, each governed by dedicated embedded devices. The system excels at generating high-fidelity 3D point clouds, thus facilitating an accurate mesh that faithfully reconstructs the cattle geometry on the fly. In order to evaluate the performance of our system, we have implemented a two-fold validation process. Initially, we test the scanner’s competency in determining volume and surface area measurements within a controlled environment featuring known objects. Secondly, we explore the impact and necessity of multi-device synchronization when operating a series of time-of-flight sensors. Based on the experimental results, the proposed system is capable of producing high-quality meshes of untamed cattle for livestock studies."
Predicting metabolic response to dietary intervention using deep learning,"Due to highly personalized biological and lifestyle characteristics, different individuals may have different metabolic responses to specific foods and nutrients. In particular, the gut microbiota, a collection of trillions of microorganisms living in our gastrointestinal tract, is highly personalized and plays a key role in our metabolic responses to foods and nutrients. Accurately predicting metabolic responses to dietary interventions based on individuals’ gut microbial compositions holds great promise for precision nutrition. Existing prediction methods are typically limited to traditional machine learning models. Deep learning methods dedicated to such tasks are still lacking. Here we develop a new method McMLP (Metabolic response predictor using coupled Multilayer Perceptrons) to fill in this gap. We provide clear evidence that McMLP outperforms existing methods on both synthetic data generated by the microbial consumer-resource model and real data obtained from six dietary intervention studies. Furthermore, we perform sensitivity analysis of McMLP to infer the tripartite food-microbe-metabolite interactions, which are then validated using the ground-truth (or literature evidence) for synthetic (or real) data, respectively. The presented tool has the potential to inform the design of microbiota-based personalized dietary strategies to achieve precision nutrition."
Deep learning reduces data requirements and allows real-time measurements in Imaging Fluorescence Correlation Spectroscopy,"Imaging Fluorescence Correlation Spectroscopy (Imaging FCS) is a powerful tool to extract information on molecular mobilities, actions and interactions in live cells, tissues and organisms. Nevertheless, several limitations restrict its applicability. First, FCS is data hungry, requiring 50,000 frames at 1 ms time resolution to obtain accurate parameter estimates. Second, the data size makes evaluation slow. Thirdly, as FCS evaluation is model-dependent, data evaluation is significantly slowed unless analytic models are available. Here we introduce two convolutional neural networks (CNNs) – FCSNet and Im-FCSNet – for correlation and intensity trace analysis, respectively. FCSNet robustly predicts parameters in 2D and 3D live samples. ImFCSNet reduces the amount of data required for accurate parameter retrieval by at least one order of magnitude and makes correct estimates even in moderately defocused samples. Both CNNs are trained on simulated data, are model-agnostic, and allow autonomous, real-time evaluation of Imaging FCS measurements."
The Effect of Synthetic Training Data on the Performance of a Deep Learning Based Markerless Biomechanics System,"As markerless motion capture technologies develop and mature, there is an increasing demand from the biomechanics community to provide kinematic data with the same level of accuracy as current gold standard methods. The purpose of this study was to evaluate how adding synthetic data to the training dataset of a deep learning based markerless biomechanics system impacts the accuracy of kinematic measurements during two functional movements. Synchronized video from multiple camera views was captured along with marker-based data from 9 subjects who performed 3 repetitions of countermovement jumps and squats. Including synthetic data to the training reduced lower limb error on average by 65.1% and 70.1% for the countermovement jump and squat movements, respectively. These results demonstrate the promising utility of supplementing the training of a deep learning markerless motion capture system with synthetic data."
Compound activity prediction with dose-dependent transcriptomic profiles and deep learning,"Predicting compound activity in assays is a long-standing challenge in drug discovery. Computational models based on compound-induced gene-expression signatures from a single profiling assay have shown promise towards predicting compound activity in other, seemingly unrelated, assays. Applications of such models include predicting mechanisms-of-action (MoA) for phenotypic hits, identifying off-target activities, and identifying polypharmacologies. Here, we introduce Transcriptomics-to-Activity Transformer (TAT) models that leverage gene-expression profiles observed over compound treatment at multiple concentrations to predict compound activity in other biochemical or cellular assays. We built TAT models based on gene-expression data from a RASL-Seq assay to predict the activity of 2,692 compounds in 262 dose response assays. We obtained useful models for 51% of the assays as determined through a realistic held-out set. Prospectively, we experimentally validated the activity predictions of a TAT model in a malaria inhibition assay. With a 63% hit rate, TAT successfully identified several sub-micromolar malaria inhibitors. Our results thus demonstrate the potential of transcriptomic responses over compound concentration and the TAT modeling framework as a cost-efficient way to identify the bioactivities of promising compounds across many assays."
CRISPR-DIPOFF: An Interpretable Deep Learning Approach for CRISPR Cas-9 Off-Target Prediction,"CRISPR Cas-9 is a groundbreaking gene-editing tool that harnesses bacterial defense systems to alter DNA sequences accurately. This innovative technology holds vast promise in multiple domains like biotechnology, agriculture, and medicine. However, such power does not come without its own peril, and one such issue is the potential for unintended modifications (Off-Target), which highlights the need for accurate prediction and mitigation strategies. Though previous studies have demonstrated improvement in Off-Target prediction capability with the application of deep learning, they often struggle with the precision-recall trade-off, limiting their effectiveness and do not provide proper interpretation of the complex decision-making process of their models. To address these limitations, we have thoroughly explored deep learning networks, particularly the recurrent neural network (RNN) and transformer based models, leveraging their established success in handling sequence data. Furthermore, we have employed genetic algorithm for hyperparameter tuning to optimize these models’ performance. The results from our experiments demonstrate significant performance improvement compared to the current state-of-the-art in Off-Target prediction, highlighting the efficacy of our approach. Furthermore, leveraging the power of the integrated gradient method, we make an effort to interpret our models resulting in a detailed analysis and understanding of the underlying factors that contribute to Off-Target predictions, in particular the presence of two sub-regions in the seed region of sgRNA which extends the established biological hypothesis of Off-Target effects. To the best of our knowledge, our model can be considered as the first model combining high efficacy, interpretability, and a desirable balance between precision and recall."
Accurate identification of cancer cells in complex pre-clinical models using deep-learning: a transfection-free approach,"3D co-cultures are key tools for in vitro biomedical research as they recapitulate more closely the in vivo environment, while allowing control of the density and type of cells included in the analysis, as well as the experimental conditions in which they are maintained. More widespread application of these models is hampered however by the limited technologies available for their analysis. The separation of the contribution of the different cell types, in particular, is a fundamental challenge.In this work, we present ORACLE, a deep neural network trained to distinguish between ovarian cancer and healthy cells based on the shape of their nucleus. The extensive validation that we have conducted includes multiple cell lines and patient derived cultures to characterise the effect of all the major potential confounding factors. High accuracy and reliability were maintained throughout the analysis demonstrating ORACLE effectiveness with this detection and classification task.ORACLE is freely available (https://github.com/MarilisaCortesi/ORACLE/tree/main) and can be used to recognise both ovarian cancer cell lines and primary patient-derived cells. This feature sets ORACLE apart from currently available analysis methods and opens the possibility of analysing in vitro co-cultures comprised solely of patient-derived cells."
CellGO: A novel deep learning-based framework and webserver for cell type-specific gene function interpretation,"Interpreting the function of genes and gene sets identified from omics experiments remains a challenge, as current pathway analysis tools often fail to account for complex interactions across genes and pathways under specific tissues and cell types. We introduce CellGO, a tool for cell type-specific gene functional analysis. CellGO employs a deep learning model to simulate signaling propagation within a cell, enabling the development of a heuristic pathway activity measuring system to identify cell type-specific active pathways given a single gene or a gene set. It is featured with additional functions to uncover pathway communities and the most active genes within pathways to facilitate mechanistic interpretation. This study demonstrated that CellGO can effectively capture cell type-specific pathways even when working with mixed cell-type markers. CellGO’s performance was benchmarked using gene knockout datasets, and its implementation effectively infers the cell type-specific pathogenesis of risk genes associated with neurodevelopmental and neurodegenerative disorders, suggesting its potential in understanding complex polygenic diseases. CellGO is accessible through a python package and a four-mode web interface for interactive usage with pretrained models on 71 single-cell datasets from human and mouse fetal and postnatal brains."
From Proteins to Ligands: Decoding Deep Learning Methods for Binding Affinity Prediction,"Accurate in silico prediction of protein-ligand binding affinity is important in the early stages of drug discovery. Deep learning-based methods exist but have yet to overtake more conventional methods such as giga-docking largely due to their lack of generalisability. To improve generalizability we need to understand what these models learn from input protein and ligand data. We systematically investigated a sequence-based deep learning framework to assess the impact of protein and ligand encodings on predicting binding affinities for commonly used kinase data sets. The role of proteins is studied using convolutional neural network-based encodings obtained from sequences and graph neural network-based encodings enriched with structural information from contact maps. Ligand-based encodings are generated from graph-neural networks. We test different ligand perturbations by randomizing node and edge properties. For proteins we make use of 3 different protein contact generation methods (AlphaFold2, Pconsc4, and ESM-1b) and compare these with a random control. Our investigation shows that protein encodings do not substantially impact the binding predictions, with no statistically significant difference in binding affinity for KIBA in the investigated metrics (concordance index, Pearson’s R Spearman’s Rank, and RMSE). Significant differences are seen for ligand encodings with random ligands and random ligand node properties, suggesting a much bigger reliance on ligand data for the learning tasks. Using different ways to combine protein and ligand encodings, did not show a significant change in performance.Download figureOpen in new tab"
From Context to Code: Rational De Novo DNA Design and Predicting Cross-Species DNA Functionality Using Deep Learning Transformer Models,"ABSTRACTSynthetic biology currently operates under a framework dominated by trial-and-error approaches, which hinders the effective engineering of organisms and the expansion of large-scale biomanufacturing. Motivated by the success of computational designs in areas like architecture and aeronautics, we aspire to transition to a more efficient and predictive methodology in synthetic biology. In this study, we report a DNA Design Platform that relies on the predictive power of Transformer-based deep learning architectures. The platform transforms the conventional paradigms in synthetic biology by enabling the context-sensitive and host-specific engineering of 5′ regulatory elements—promoters and 5′ untranslated regions (UTRs) along with an array of codon-optimised coding sequence (CDS) variants. This allows us to generate context-sensitive 5′ regulatory sequences and CDSs, achieving an unparalleled level of specificity and adaptability in different target hosts. With context-aware design, we significantly broaden the range of possible gene expression profiles and phenotypic outcomes, substantially reducing the need for laborious high-throughput screening efforts. Our context-aware, AI-driven design strategy marks a significant advancement in synthetic biology, offering a scalable and refined approach for gene expression optimisation across a diverse range of expression hosts. In summary, this study represents a substantial leap forward in the field, utilising deep learning models to transform the conventional design, build, test, learn-cycle into a more efficient and predictive framework."
De novo Protein Sequence Design Based on Deep Learning and Validation on CalB Hydrolase,"Protein design is central to nearly all protein engineering problems, as it can enable the creation of proteins with new biological function, such as improving the catalytic efficiency of enzymes. As one of the key tasks of protein design, fixed-backbone protein sequence design aims to design novel sequence that would fold into a given protein backbone structure. However, current sequence design methods have limitations in terms of low sequence diversity and experimental validation of designed protein function, which cannot meet the needs of functional protein design. We firstly constructed Graphormer-based Protein Design (GPD) model that directly applies Transformer to graph-based representation of 3D protein structure, and added Gaussian noise and sequence random mask to node features to improve the sequence recovery and diversity. Additionally, functional filtering based on the structure folding, solubility, and function were performed to improve the success rate in experiments. The process of “sequence design-functional filtering -functional experiment” was carried out for CalB hydrolase. The experimental results showed that the specify activity of designed protein improved 1.7 times than CalB wild type. This design and filtering platform will be a valuable tool for generating industrial enzymes and protein drugs with specific functions."
ISMI-VAE: A Deep Learning Model for Classifying Disease Cells Using Gene Expression and SNV Data,"Various studies have linked several diseases, including cancer and Covid-19, to single nucleotide variations (SNV). Although scRNA-seq technology can provide SNV and gene expression data, few studies have integrated and analyzed these multimodal data. To address this issue, this paper introduces Interpretable Single-cell Multimodal Data Integration Based on Variational Autoencoder (ISMI-VAE). ISMI-VAE leverages latent variable models that utilize the characteristics of SNV and gene expression data to overcome high noise levels, and uses deep learning techniques to integrate multimodal information, map them to a low-dimensional space, and classify disease cells. Moreover, ISMI-VAE introduces an attention mechanism to reflect feature importance and analyze genetic features that could potentially cause disease. Experimental results on three cancer data sets and one Covid-19 data set demonstrate that ISMI-VAE surpasses the baseline method in terms of both effectiveness and interpretability, and can effectively identify disease-causing gene features."
Spatial Omics Driven Crossmodal Pretraining Applied to Graph-based Deep Learning for Cancer Pathology Analysis,"Graph-based deep learning has shown great promise in cancer histopathology image analysis by contextualizing complex morphology and structure across whole slide images to make high quality downstream outcome predictions (ex: prognostication). These methods rely on informative representations (i.e., embeddings) of image patches comprising larger slides, which are used as node attributes in slide graphs. Spatial omics data, including spatial transcriptomics, is a novel paradigm offering a wealth of detailed information. Pairing this data with corresponding histological imaging localized at 50-micron resolution, may facilitate the development of algorithms which better appreciate the morphological and molecular underpinnings of carcinogenesis. Here, we explore the utility of leveraging spatial transcriptomics data with a contrastive crossmodal pretraining mechanism to generate deep learning models that can extract molecular and histological information for graph-based learning tasks. Performance on cancer staging, lymph node metastasis prediction, survival prediction, and tissue clustering analyses indicate that the proposed methods bring improvement to graph based deep learning models for histopathological slides compared to leveraging histological information from existing schemes, demonstrating the promise of mining spatial omics data to enhance deep learning for pathology workflows."
"scDILT: a model-based and constrained deep learning framework for single-cell Data Integration, Label Transferring, and clustering","ABSTRACTThe scRNA-seq technology enables high-resolution profiling and analysis of individual cells. The increasing availability of datasets and advancements in technology have prompted researchers to integrate existing annotated datasets with newly sequenced datasets for a more comprehensive analysis. It is important to ensure that the integration of new datasets does not alter the cell clusters defined in the old/reference datasets. Although several methods have been developed for scRNA-seq data integration, there is currently a lack of tools that can simultaneously achieve the aforementioned objectives. Therefore, in this study, we have introduced a novel tool called scDILT, which leverages a conditional autoencoder and deep embedding clustering to effectively remove batch effects among different datasets. Moreover, scDILT utilizes homogeneous constraints to preserve the cell-type/clustering patterns observed in the reference datasets, while employing heterogeneous constraints to map cells in the new datasets to the annotated cell clusters in the reference datasets. We have conducted extensive experiments to demonstrate that scDILT outperforms other methods in terms of data integration, as confirmed by evaluations on simulated and real datasets. Furthermore, we have shown that scDILT can be successfully applied to integrate multi-omics single-cell datasets. Based on these findings, we conclude that scDILT holds great promise as a tool for integrating single-cell datasets derived from different batches, experiments, times, or interventions."
Splam: a deep-learning-based splice site predictor that improves spliced alignments,"The process of splicing messenger RNA to remove introns plays a central role in creating genes and gene variants. Here we describe Splam, a novel method for predicting splice junctions in DNA based on deep residual convolutional neural networks. Unlike some previous models, Splam looks at a relatively limited window of 400 base pairs flanking each splice site, motivated by the observation that the biological process of splicing relies primarily on signals within this window. Additionally, Splam introduces the idea of training the network on donor and acceptor pairs together, based on the principle that the splicing machinery recognizes both ends of each intron at once. We compare Splam’s accuracy to recent state-of-the-art splice site prediction methods, particularly SpliceAI, another method that uses deep neural networks. Our results show that Splam is consistently more accurate than SpliceAI, with an overall accuracy of 96% at predicting human splice junctions. Splam generalizes even to non-human species, including distant ones like the flowering plant Arabidopsis thaliana. Finally, we demonstrate the use of Splam on a novel application: processing the spliced alignments of RNA-seq data to identify and eliminate errors. We show that when used in this manner, Splam yields substantial improvements in the accuracy of downstream transcriptome analysis of both poly(A) and ribo-depleted RNA-seq libraries. Overall, Splam offers a faster and more accurate approach to detecting splice junctions, while also providing a reliable and efficient solution for cleaning up erroneous spliced alignments."
GraphComm: A Graph-based Deep Learning Method to Predict Cell-Cell Communication in single-cell RNAseq data,"Cell-cell interactions coordinate various functions across cell-types in health and disease. Novel single-cell techniques allow us to investigate cellular crosstalk at single-cell resolution. Cell-cell communication (CCC) is mediated by underlying gene-gene networks, however most current methods are unable to account for complex inter-connections within the cell as well as incorporate the effect of pathway and protein complexes on interactions. This results in the inability to infer overarching signalling patterns within a dataset as well as limit the ability to successfully explore other data types such as spatial cell dimension. Therefore, to represent transcriptomic data as intricate networks connecting cells to ligands and receptors for relevant cell-cell communication inference as well as incorporating descriptive information independent of gene expression, we present GraphComm - a new graph-based deep learning method for predicting cell-cell communication in single-cell RNAseq datasets. GraphComm improves CCC inference by capturing detailed information such as cell location and intracellular signalling patterns from a database of more than 30,000 protein interaction pairs. With this framework, GraphComm is able to predict biologically relevant results in datasets previously validated for CCC,datasets that have undergone chemical or genetic perturbations and datasets with spatial cell information."
Deep learning-guided selection of antibody therapies with enhanced resistance to current and prospective SARS-CoV-2 Omicron variants,"ABSTRACTMost COVID-19 antibody therapies rely on binding the SARS-CoV-2 receptor binding domain (RBD). However, heavily mutated variants such as Omicron and its sublineages, which are characterized by an ever increasing number of mutations in the RBD, have rendered prior antibody therapies ineffective, leaving no clinically approved antibody treatments for SARS-CoV-2. Therefore, the capacity of therapeutic antibody candidates to bind and neutralize current and prospective SARS-CoV-2 variants is a critical factor for drug development. Here, we present a deep learning-guided approach to identify antibodies with enhanced resistance to SARS-CoV-2 evolution. We apply deep mutational learning (DML), a machine learning-guided protein engineering method to interrogate a massive sequence space of combinatorial RBD mutations and predict their impact on angiotensin-converting enzyme 2 (ACE2) binding and antibody escape. A high mutational distance library was constructed based on the full-length RBD of Omicron BA.1, which was experimentally screened for binding to the ACE2 receptor or neutralizing antibodies, followed by deep sequencing. The resulting data was used to train ensemble deep learning models that could accurately predict binding or escape for a panel of therapeutic antibody candidates targeting diverse RBD epitopes. Furthermore, antibody breadth was assessed by predicting binding or escape to synthetic lineages that represent millions of sequences generated using in silico evolution, revealing combinations with complementary and enhanced resistance to viral evolution. This deep learning approach may enable the design of next-generation antibody therapies that remain effective against future SARS-CoV-2 variants."
Can deep learning predict human intelligence from structural brain MRI?,"ABSTRACTCan brain structure predict human intelligence? T1-weighted structural brain magnetic resonance images (sMRI) have been correlated with intelligence. Nevertheless, population-level association does not fully account for individual variability in intelligence. To address this, individual prediction studies emerge recently. However, they are mostly on predicting fluid intelligence (the ability to solve new problems). Studies are lacking to predict crystallized intelligence (the ability to accumulate knowledge) or general intelligence (fluid and crystallized intelligence combined). This study tests whether deep learning of sMRI can predict an individual subject’s verbal, comprehensive, and full-scale intelligence quotients (VIQ, PIQ, FSIQ), which reflect both fluid and crystallized intelligence. We performed a comprehensive set of 432 experiments, using different input images, six deep learning models, and two outcome settings, on 850 autistic and healthy subjects 6-64 years of age. Results show promise with statistical significance, and also open up questions inviting further future studies."
Single-nucleus multiomic atlas of frontal cortex in amyotrophic lateral sclerosis with a deep learning-based decoding of alternative polyadenylation mechanisms,"The understanding of how different cell types contribute to amyotrophic lateral sclerosis (ALS) pathogenesis is limited. Here we generated a single-nucleus transcriptomic and epigenomic atlas of the frontal cortex of ALS cases with C9orf72 (C9) hexanucleotide repeat expansions and sporadic ALS (sALS). Our findings reveal shared pathways in C9-ALS and sALS, characterized by synaptic dysfunction in excitatory neurons and a disease-associated state in microglia. The disease subtypes diverge with loss of astrocyte homeostasis in C9-ALS, and a more substantial disturbance of inhibitory neurons in sALS. Leveraging high depth 3’-end sequencing, we found a widespread switch towards distal polyadenylation (PA) site usage across ALS subtypes relative to controls. To explore this differential alternative PA (APA), we developed APA-Net, a deep neural network model that uses transcript sequence and expression levels of RNA-binding proteins (RBPs) to predict cell-type specific APA usage and RBP interactions likely to regulate APA across disease subtypes."
Deep Learning from Phylogenies for Diversification Analyses,"ABSTRACTBirth-death models are widely used in combination with species phylogenies to study past diversification dynamics. Current inference approaches typically rely on likelihood-based methods. These methods are not generalizable, as a new likelihood formula must be established each time a new model is proposed; for some models such formula is not even tractable. Deep learning can bring solutions in such situations, as deep neural networks can be trained to learn the relation between simulations and parameter values as a regression problem. In this paper, we adapt a recently developed deep learning method from pathogen phylodynamics to the case of diversification inference, and we extend its applicability to the case of the inference of state-dependent diversification models from phylogenies associated with trait data. We demonstrate the accuracy and time efficiency of the approach for the time constant homogeneous birth-death model and the Binary-State Speciation and Extinction model. Finally, we illustrate the use of the proposed inference machinery by reanalyzing a phylogeny of primates and their associated ecological role as seed dispersers. Deep learning inference provides at least the same accuracy as likelihood-based inference while being faster by several orders of magnitude, offering a promising new inference approach for deployment of future models in the field."
Harnessing Deep Learning to Analyze Cryptic Morphological Variability of Marchantia polymorpha,"Characterizing phenotypes is a fundamental aspect of biological sciences, although it can be challenging due to various factors. For instance, the liverwort (Marchantia polymorpha), a model system for plant biology, exhibits morphological variability, making it difficult to identify and quantify distinct phenotypic features using objective measures. To address this issue, we utilized a deep learning-based image classifier that can handle plant images directly without manual extraction of phenotypic features, and analyzed bright-field images of M. polymorpha. This dioicous plant species exhibits morphological differences between male and female wild accessions at an early stage of gemmaling growth, although it remains elusive whether the differences are attributable to sexual dimorphism or autosomal genetic variation. To dissect the genomic factors, we established a male and female set of recombinant inbred lines (RILs) from a set of male and female wild accessions. We then trained deep-learning models to classify the sexes of the RILs and the wild accessions. Our results showed that the trained classifiers accurately classified male and female gemmalings of wild accessions in the first week of growth, confirming the intuition of plant researchers in a reproducible and objective manner. In contrast, the RILs were less distinguishable, indicating that the differences between the parental wild accessions arose from autosomal variations instead of sexual dimorphism. Furthermore, we validated our trained models by an “explainable AI” technique that highlights image regions relevant to the classification. Our findings demonstrate that the classifier-based approach provides a powerful tool for analyzing plant species that lack standardized phenotyping metrics."
tUbe net: a generalisable deep learning tool for 3D vessel segmentation,"Deep learning has become an invaluable tool for bioimage analysis but, while open-source cell annotation software such as cellpose are widely used, an equivalent tool for three-dimensional (3D) vascular annotation does not exist. With the vascular system being directly impacted by a broad range of diseases, there is significant medical interest in quantitative analysis for vascular imaging. However, existing deep learning approaches for this task are specialised to particular tissue types or imaging modalities. We present a new deep learning model for segmentation of vasculature that is generalisable across tissues, modalities, scales and pathologies. To create a generalisable model, a 3D convolutional neural network was trained using data from multiple modalities including optical imaging, computational tomography and photoacoustic imaging. Through this varied training set, the model was forced to learn common features of vessels cross-modality and scale. Following this, the general model was fine-tuned to different applications with a minimal amount of manually labelled ground truth data. It was found that the general model could be specialised to segment new datasets, with a high degree of accuracy, using as little as 0.3% of the volume of that dataset for fine-tuning. As such, this model enables users to produce accurate segmentations of 3D vascular networks without the need to label large amounts of training data."
A comprehensive evaluation of generalizability of deep-learning based Hi-C resolution improvement methods,"Motivation Hi-C is a widely used technique to study the 3D organization of the genome. Due to its high sequencing cost, most of the generated datasets are of coarse resolution, which makes it impractical to study finer chromatin features such as Topologically Associating Domains (TADs) and chromatin loops. Multiple deep-learning-based methods have recently been proposed to increase the resolution of these data sets by imputing Hi-C reads (typically called upscaling). However, the existing works evaluate these methods on either synthetically downsampled or a small subset of experimentally generated sparse Hi-C datasets, making it hard to establish their generalizability in the real-world use case. We present our framework - Hi-CY - that compares existing Hi-C resolution upscaling methods on seven experimentally generated low-resolution Hi-C datasets belonging to various levels of read sparsities originating from three cell lines on a comprehensive set of evaluation metrics. Hi-CY also includes four downstream analysis tasks, such as TAD and chromatin loops recall, to provide a thorough report on the generalizability of these methods.Results We observe that existing deep-learning methods fail to generalize to experimentally generated sparse Hi-C datasets showing a performance reduction of up to 57 %. As a potential solution, we find that retraining deep-learning based methods with experimentally generated Hi-C datasets improves performance by up to 31%. More importantly, Hi-CY shows that even with retraining, the existing deep-learning based methods struggle to recover biological features such as chromatin loops and TADs when provided with sparse Hi-C datasets. Our study, through Hi-CY framework, highlights the need for rigorous evaluation in future. We identify specific avenues for improvements in the current deep learning-based Hi-C upscaling methods, including but not limited to using experimentally generated datasets for training.Availability https://github.com/rsinghlab/Hi-CYAuthor Summary We evaluate deep learning-based Hi-C upscaling methods with our framework Hi-CY using seven datasets originating from three cell lines evaluated using three correlation metrics, four Hi-C similarity metrics, and four downstream analysis tasks, including TAD and chromatin loop recovery. We identify a distributional shift between Hi-C contact matrices generated from downsampled and experimentally generated sparse Hi-C datasets. We use Hi-CY to establish that the existing methods trained with downsampled Hi-C datasets tend to perform significantly worse on experimentally generated Hi-C datasets. We explore potential strategies to alleviate the drop in performance such as retraining models with experimentally generated datasets. Our results suggest that retraining improves performance up to 31 % on five sparse GM12878 datsets but provides marginal improvement in cross cell-type setting. Moreover, we observe that regardless of the training scheme, all deep-learning based methods struggle to recover biological features such as TADs and chromatin loops when provided with very sparse experimentally generated datasets as inputs."
PiDeeL: Pathway-Informed Deep Learning Model for Survival Analysis and Pathological Classification of Gliomas,"Online assessment of tumor characteristics during surgery is important and has the potential to establish an intraoperative surgeon feedback mechanism. With the availability of such feedback, surgeons could decide to be more liberal or conservative regarding the resection of the tumor. While there are methods to perform metabolomics-based online tumor pathology prediction, their model complexity and, in turn, the predictive performance is limited by the small dataset sizes. Furthermore, the information conveyed by the feedback provided on the tumor tissue could be improved both in terms of content and accuracy. In this study, we propose a metabolic pathway-informed deep learning model, PiDeeL, to perform survival analysis and pathology assessment based on metabolite concentrations. We show that incorporating pathway information into the model architecture substantially reduces parameter complexity and achieves better survival analysis and pathological classification performance. With these design decisions, we show that PiDeeL improves tumor pathology prediction performance of the state-of-the-art in terms of the Area Under the ROC Curve (AUC-ROC) by 3.38% and the Area Under the Precision-Recall Curve (AUC-PR) by 4.06%. Similarly, with respect to the time-dependent concordance index (c-index), we observe that PiDeeL achieves better survival analysis performance (improvement up to 4.3%) when compared to the state-of-the-art. Moreover, we show that importance analyses performed on input metabolite features as well as pathway-specific hidden-layer neurons of PiDeeL provide insights into tumor metabolism. We foresee that the use of this model in the surgery room will help surgeons adjust the surgery plan on the fly and will result in better prognosis estimates tailored to surgical procedures.Availability The code is released at https://github.com/ciceklab/PiDeeL. The data used in this study is released at https://zenodo.org/record/7228791.Contact cicek{at}cs.bilkent.edu.trSupplementary information Supplementary data are available at Briefings in Bioinformatics online."
Deep learning and CRISPR-Cas13d ortholog discovery for optimized RNA targeting,"Transcriptome engineering technologies that can effectively and precisely perturb mammalian RNAs are needed to accelerate biological discovery and RNA therapeutics. However, the broad utility of programmable CRISPR-Cas13 ribonucleases has been hampered by an incomplete understanding of the design rules governing guide RNA activity as well as cellular toxicity resulting from off-target or collateral RNA cleavage. Here, we sought to characterize and develop Cas13d systems for efficient and specific RNA knockdown with low cellular toxicity in human cells. We first quantified the performance of over 127,000 RfxCas13d (CasRx) guide RNAs in the largest-scale screen to date and systematically evaluated three linear, two ensemble, and two deep learning models to build a guide efficiency prediction algorithm validated across multiple human cell types in orthogonal validation experiments (https://www.RNAtargeting.org). Deep learning model interpretation revealed specific sequence motifs at spacer position 15-24 along with favored secondary features for highly efficient guides. We next identified 46 novel Cas13d orthologs through metagenomic mining for activity and cytotoxicity screening, discovering that the metagenome-derived DjCas13d ortholog achieves low cellular toxicity and high transcriptome-wide specificity when deployed against high abundance transcripts or in sensitive cell types, including human embryonic stem cells, neural progenitor cells, and neurons. Finally, our Cas13d guide efficiency model successfully generalized to DjCas13d, highlighting the utility of a comprehensive approach combining machine learning with ortholog discovery to advance RNA targeting in human cells."
DeepDynaForecast: Phylogenetic-informed graph deep learning for epidemic transmission dynamic prediction,"In the midst of an outbreak or sustained epidemic, reliable prediction of transmission risks and patterns of spread is critical to inform public health programs. Projections of growth or decline among specific risk groups can aid in optimizing interventions, particularly when resources are limited. Phylogenetic trees have been widely used in the detection of transmission chains and high-risk populations. Moreover, tree topology and the incorporation of population parameters (phylodynamics) can be useful to reconstruct the evolutionary dynamics of an epidemic across space and time among individuals. We now demonstrate the utility of phylodynamic trees for infection forecasting in addition to backtracking, developing a phylogeny-based deep learning system, called DeepDynaForecast. Our approach leverages a primal-dual graph learning structure with shortcut multi-layer aggregation, and it is suited for the early identification and prediction of transmission dynamics in emerging high-risk groups. We demonstrate the accuracy of DeepDynaForecast using simulated outbreak data and the utility of the learned model using empirical, large-scale data from the human immunodeficiency virus epidemic in Florida between 2012 and 2020. Our framework is available as open-source software (MIT license) at: https://github.com/lab-smile/DeepDynaForcast.Author Summary During an outbreak or sustained epidemic, accurate prediction of patterns in transmission risk can reliably inform public health strategies. Projections indicating growth or decline of transmission for specific risk groups can significantly enhance the optimization of interventions, especially when resources are limited. To address this, we present DeepDynaForecast, a cutting-edge deep learning algorithm designed for forecasting pathogen transmission dynamics. Uniquely, DeepDynaForecast was trained on in-depth simulation data and used more information from the phylogenetic tree of pathogen sequence data than any other algorithm in the field to date, allowing classification of samples according to their dynamics (growth, static, or decline) with incredible accuracy. We evaluated the model’s performance using both simulated outbreak data and empirical, large-scale data from the HIV epidemic in Florida between 2012 and 2020. We conclude DeepDynaForecast represents a significant advancement in genomics-mediated pathogen transmission characterization and has the potential to catalyze new research directions within virology, molecular biology, and public health."
Virtual perturbations to assess explainability of deep-learning based cell fate predictors,"Explainable deep learning holds significant promise in extracting scientific insights from experimental observations. This is especially so in the field of bio-imaging, where the raw data is often voluminous, yet extremely variable and difficult to study. However, one persistent challenge in deep learning assisted scientific discovery is that the workings of artificial neural networks are often difficult to interpret. Here we present a simple technique for investigating the behaviour of trained neural networks: virtual perturbation. By making precise and systematic alterations to input data or internal representations thereof, we are able to discover causal relationships in the outputs of a deep learning model, and by extension, in the underlying phenomenon itself. As an exemplar, we use our recently described deep-learning based cell fate prediction model. We trained the network to predict the fate of less fit cells in an experimental model of mechanical cell competition. By applying virtual perturbation to the trained network, we discover causal relationships between a cell’s environment and eventual fate. We compare these with known properties of the biological system under investigation to demonstrate that the model faithfully captures insights previously established by experimental research."
Predicting long-term collective animal behavior with deep learning,"Deciphering the social interactions that govern collective behavior in animal societies has greatly benefited from advancements in modern computing. Computational models diverge into two kinds of approaches: analytical models and machine learning models. This work introduces a deep learning model for social interactions in the fish species Hemigrammus rhodostomus, and compares its results to experiments and to the results of a state-of-the-art analytical model. To that end, we propose a systematic methodology to assess the faithfulness of a model, based on the introduction of a set of stringent observables. We demonstrate that machine learning models of social interactions can directly compete against their analytical counterparts. Moreover, this work demonstrates the need for consistent validation across different timescales and highlights which design aspects critically enables our deep learning approach to capture both short- and long-term dynamics. We also show that this approach is scalable to other fish species."
Synergizing Geometric Deep Learning and Data-Centric Methods for Improved Protein Structural Alignment,"Motivation Structures are replacing the role of sequences. Traditional bioinformatics research focused on sequences because they were easily obtained. Advances in techniques like cryo-electron microscopy, molecular modeling, docking algorithms, and structure prediction software have shifted the focus to structures. Given the importance of deep learning in many of these breakthroughs, it makes sense to also explore how it can modernize classic bioinformatics tools. However, empirical findings have shown that machine learning based methods have many pitfalls resulting in overoptimistic conclusions, including data leakage between test and training data. Thus, there is a need for new innovations to make neural networks more intelligible.Results We have developed vanGOGH, a geometric deep learning-based structural alignment approach that performs on par with the state-of-the-art without ever having been trained on a pair of naturally found homologs. We adopted a data-centric approach to address deep learning and data limitations by augmenting protein templates into synthetic homologs for training.Our method allowed us to supplement homolog data by knowledge-driven augmentation, self-learning of relevant structural features by supervised examples and protein alignment that is competitive with state-of-the art methods.Availability GNN framework: https://github.com/DeepRank/deeprank-core/tree/main/deeprankcoreContact Li.Xue@radboudumc.nl"
DeepETPicker: Fast and accurate 3D particle picking for cryo-electron tomography using weakly supervised deep learning,"ABSTRACTPicking particles of biological macromolecules from their cryo-electron tomograms is critical to solving their 3D structures in situ. To reach sub-nanometre resolution, large numbers of particles often need to be picked, a laborious and time-consuming task if performed manually. To date, however, the adoption of automated particle-picking methods remains limited because of the limitations in their accuracy, processing speed and, for those based on learning models, manual annotation cost. To overcome the limitations, we develop DeepETPicker, a deep learning model for fast and accurate picking of 3D particles from cryo-electron tomograms. The training of DeepETPicker requires only weak supervision with low numbers of simplified Gaussian-type labels, reducing the burden of manual annotation of tomograms under very low signal-to-noise ratios. The simplified labels combined with the customized and lightweight model architecture of DeepETPicker as well as GPU-accelerated pooling enable substantially improved accuracy and accelerated processing speed. When tested on simulated as well as real tomograms, DeepETPicker outperforms the competing state-of-the-art methods by achieving the highest overall accuracy and speed, which translate into better quality of picked particles and higher resolutions of final reconstruction maps. DeepETPicker is provided in open source with a user-friendly interface to support automated particle picking for high-resolution cryo-electron tomography in situ."
Deep Learning Approaches to the Phylogenetic Placement of Extinct Pollen Morphotypes,"The phylogenetic interpretation of pollen morphology is limited by our inability to recognize the evolutionary history embedded in pollen features. Deep learning offers tools for connecting morphology to phylogeny. Using neural networks, we developed an explicitly phylogenetic toolkit for analyzing the overall shape, internal structure, and texture of a pollen grain. Our analysis pipeline determines whether testing specimens are from unknown species based on uncertainty estimates. Features of novel specimens are passed to a multi-layer perceptron network trained to transform these features into predicted phylogenetic distances from known taxa. We used these predicted distances to place specimens in a phylogeny using Bayesian inference. We trained and evaluated our models using optical superresolution micrographs of 30 Podocarpus species. We then used trained models to place nine fossil Podocarpidites specimens within the phylogeny. In doing so, we demonstrate that the phylogenetic history encoded in pollen morphology can be recognized by neural networks and that deep-learned features can be used in phylogenetic placement. Our approach makes extinction and speciation events that would otherwise be masked by the limited taxonomic resolution of the fossil pollen record visible to palynological analysis.Significance Statement Machine learned features from deep neural networks can do more than categorize and classify biological images. We demonstrate that these features can also be used to quantify morphological differences among pollen taxa, discover novel morphotypes, and place fossil specimens on a phylogeny using Bayesian inference. Deep learning can be used to characterize and identify and morphological features with evolutionary significance. These features can then be used to infer phylogenetic distance. This approach fundamentally changes how fossil pollen morphology can be interpreted, allowing greater evolutionary inference of fossil pollen specimens. The analysis framework, however, is not specific to pollen and can be generalized to other taxa and other biological images."
scHiCyclePred: a deep learning framework for predicting cell cycle phases from single-cell Hi-C data using multi-scale interaction information,"While scRNA-seq offers gene expression snapshots, it misses the spatial context of chromatin organization crucial for cell cycle regulation. Single-cell Hi-C, capturing chromatin’s three-dimensional (3D) architecture, fills this void, revealing interactions between genomic regions that transcript-only data might overlook. We introduce scHiCyclePred, a model that utilizes single-cell Hi-C’s multi-scale interaction data to predict cell cycle phases by extracting chromatin’s 3D features. This fusion-prediction model integrates three feature sets into a unified vector. Remarkably, scHiCyclePred outperforms methods like NAGANO and CIRCLET and traditional machine learning techniques across various metrics. Our insights into 3D chromatin dynamics during the cell cycle further underscore its utility. By offering a more comprehensive view of cell cycle dynamics through chromatin structure, scHiCyclePred stands to significantly advance our understanding in cellular biology and holds potential to catalyze breakthroughs in disease research. Access scHiCyclePred at github.com/HaoWuLab-Bioinformatics/scHiCyclePred."
Deep learning permits imaging of multiple structures with the same fluorophores,"Fluorescence microscopy is a powerful tool for life sciences, which employs fluorescent tags to label and observe cellular structures and their dynamics. However, due to the spectral overlap between different dyes, a limited number of structures can be separately labeled and imaged for live cell applications. Here we propose a novel double-structure network (DBSN) that consists of multiple connected models, which can extract six subcellular structures from three images with only two separate fluorescent labels. DBSN combines the intensity-balance models to compensate for uneven fluorescent labels for different structures and the structure-separation models to extract multiple different structures with the same fluorescent labels. Therefore, DBSN permits the imaging of multiple structures with only one fluorescent label. It significantly reduces photobleaching, breaks the bottleneck of the existing technologies, and would have vast applications in cell biology."
EMDiffuse: a diffusion-based deep learning method augmenting ultrastructural imaging and volume electron microscopy,"Electron microscopy (EM) revolutionized the way to visualize cellular ultrastructure. Volume EM (vEM) has further broadened its three-dimensional nanoscale imaging capacity. However, intrinsic trade-offs between imaging speed and quality of EM restrict the attainable imaging area and volume. Isotropic imaging with vEM for large biological volumes remains unachievable. Here we developed EMDiffuse, a suite of algorithms designed to enhance EM and vEM capabilities, leveraging the cutting-edge image generation diffusion model. EMDiffuse demonstrates outstanding denoising and super-resolution performance, generates realistic predictions without unwarranted smoothness, improves predictions’ resolution by ∼30%, and exhibits excellent transferability by taking only one pair of images to fine-tune. EMDiffuse also pioneers the isotropic vEM reconstruction task, generating isotropic volume similar to that obtained using advanced FIB-SEM even in the absence of isotropic training data. We demonstrated the robustness of EMDiffuse by generating isotropic volumes from six public datasets obtained from different vEM techniques and instruments. The generated isotropic volume enables accurate organelle reconstruction, making 3D nanoscale ultrastructure analysis faster and more accessible and extending such capability to larger volumes. More importantly, EMDiffuse features self-assessment functionalities and guarantees reliable predictions for all tasks. We envision EMDiffuse to pave the way for more in-depth investigations into the intricate subcellular nanoscale structures within large areas and volumes of biological systems."
Prediction of Alzheimer’s Disease from Single Cell Transcriptomics Using Deep Learning,"Alzheimer’s disease (AD) is a progressive neurological disorder characterized by brain cell death, brain atrophy, and cognitive decline. Early diagnosis of AD remains a significant challenge in effectively managing this debilitating disease. In this study, we aimed to harness the potential of single-cell transcriptomics data from 12 Alzheimer’s patients and 9 normal controls (NC) to develop a predictive model for identifying AD patients. The dataset comprised gene expression profiles of 33,538 genes across 169,469 cells, with 90,713 cells belonging to AD patients and 78,783 cells belonging to NC individuals. Employing machine learning and deep learning techniques, we developed prediction models. Initially, we performed data processing to identify genes expressed in most cells. These genes were then ranked based on their ability to classify AD and NC groups. Subsequently, two sets of genes, consisting of 35 and 100 genes, respectively, were used to develop machine learning-based models. Although these models demonstrated high performance on the training dataset, their performance on the validation/independent dataset was notably poor, indicating potential overoptimization. To address this challenge, we developed a deep learning method utilizing dropout regularization technique. Our deep learning approach achieved an AUC of 0.75 and 0.84 on the validation dataset using the sets of 35 and 100 genes, respectively. Furthermore, we conducted gene ontology enrichment analysis on the selected genes to elucidate their biological roles and gain insights into the underlying mechanisms of Alzheimer’s disease. While this study presents a prototype method for predicting AD using single-cell genomics data, it is important to note that the limited size of the dataset represents a major limitation. To facilitate the scientific community, we have created a website to provide with code and service. It is freely available at https://webs.iiitd.edu.in/raghava/alzscpred.Key PointsPredictive Model for Alzheimer’s Disease Using Single Cell Transcriptomics DataOveroptimization of models trained on single-cell genomics data.Application of dropout regularization technique of ANN for reducing overoptimizationRanking of genes based on their ability to predict patients’ Alzheimer’s DiseaseStandalone software package for predicting Alzheimer’s DiseaseAuthor’s BiographyAman Srivastava is pursuing M. Tech. in Computational Biology from Department of Computational Biology, Indraprastha Institute of Information Technology, New Delhi, India.Anjali Dhall is currently working as Ph.D. in Computational Biology from Department of Computational Biology, Indraprastha Institute of Information Technology, New Delhi, India.Sumeet Patiyal is currently working as Ph.D. in Computational Biology from Department of Computational Biology, Indraprastha Institute of Information Technology, New Delhi, India.Akanksha Arora is currently working as Ph.D. in Computational Biology from Department of Computational Biology, Indraprastha Institute of Information Technology, New Delhi, India.Akanksha Jarwal is pursuing M. Tech. in Computational Biology from Department of Computational Biology, Indraprastha Institute of Information Technology, New Delhi, India.Gajendra P. S. Raghava is currently working as Professor and Head of Department of Computational Biology, Indraprastha Institute of Information Technology, New Delhi, India."
TSpred: a robust prediction framework for TCR-epitope interactions based on an ensemble deep learning approach using paired chain TCR sequence data,"ABSTRACTPrediction of T-cell receptor (TCR)-epitope interactions is important for many applications such as cancer immunotherapy. However, due to the scarcity of available data, it is known to be a challenging task particularly for novel epitopes. Here, we propose TSpred, a new ensemble deep learning approach for the pan-specific prediction of TCR binding specificity based on paired chain TCR data. This method combines the predictive power of CNN and the attention mechanism to capture the patterns underlying TCR-epitope interactions. In particular, we design a reciprocal attention mechanism which contributes to higher model generalizability to unseen epitopes. We perform a comprehensive evaluation of our model and observe that TSpred achieves state-of-the-art performances in both seen and unseen epitope specificity prediction tasks. Our model performs consistently well across both of the two widely used negative sampling strategies, while avoiding the potential bias associated with each strategy. Also, compared to other predictors, it is more robust to bias related to peptide imbalance in the dataset. In addition, the reciprocal attention component of our model allows for model interpretability by capturing structurally important binding regions. Results indicate that TSpred is a robust and reliable method for the task of TCR-epitope binding prediction."
Discovery of novel multi-functional peptides by using protein language models and graph-based deep learning,"Functional peptides are one kind of short protein fragments that have a wide range of beneficial functions for living organisms. The majority of previous research focused on mono-functional peptides, but a growing number of multi-functional peptides have been discovered. Although enormous experimental efforts endeavor to assay multi-functional peptides, only a small fraction of millions of known peptides have been explored. Effective and precise techniques for identifying multi-functional peptides can facilitate their discovery and mechanistic understanding. In this article, we presented a novel method, called iMFP-LG, for identifying multi-functional peptides based on protein language models (pLMs) and graph attention networks (GATs). Comparison results showed iMFP-LG significantly outperforms state-of-the-art methods on both multifunctional bioactive peptides and multi-functional therapeutic peptides datasets. The interpretability of iMFP-LG was also illustrated by visualizing attention patterns in pLMs and GATs. Regarding to the outstanding performance of iMFP-LG on the identification of multi-functional peptides, we employed iMFP-LG to screen novel candidate peptides with both ACP and AMP functions from millions of known peptides in the UniRef90. As a result, 8 candidate peptides were identified, and 1 candidate that exhibits significant antibacterial and anticancer effect was confirmed through molecular structure alignment and biological experiments. We anticipate iMFP-LG can assist in the discovery of multi-functional peptides and contribute to the advancement of peptide drug design.Availability and implementation The models and associated code are available at: https://github.com/chen-bioinfo/iMFP-LG.Supplementary information Supplementary data are available online."
Investigating the ability of deep learning-based structure prediction to extrapolate and/or enrich the set of antibody CDR canonical forms,"Deep learning models have been shown to accurately predict protein structure from sequence, allowing researchers to explore protein space from the structural viewpoint. In this paper we explore whether “novel” features, such as distinct loop conformations can arise from these predictions despite not being present in the training data.Here we have used ABodyBuilder2, a deep learning antibody structure predictor, to predict the structures of ∼1.5M paired antibody sequences. We examined the predicted structures of the canonical CDR loops and found that most of these predictions fall into the already described CDR canonical form structural space. We also found a small number of “new” canonical clusters composed of heterogeneous sequences united by a common sequence motif and loop conformation. Analysis of these novel clusters showed their origins to be either shapes seen in the training data at very low frequency or shapes seen at high frequency but at a shorter sequence length.To evaluate explicitly the ability of ABodyBuilder2 to extrapolate, we retrained several models whilst with-holding all antibody structures of a specific CDR loop length or canonical form. These “starved” models showed evidence of generalisation across CDRs of different lengths, but they did not extrapolate to loop conformations which were highly distinct from those present in the training data. However, the models were able to accurately predict a canonical form even if only a very small number of examples of that shape were in the training data.Our results suggest that deep learning protein structure prediction methods are unable to make completely out-of-domain predictions for CDR loops. However, in our analysis we also found that even minimal amounts of data of a structural shape allow the method to recover its original predictive abilities. We have made the ∼1.5 M predicted structures used in this study available to download at https://doi.org/10.5281/zenodo.10280181."
Generalization of deep learning models for predicting spatial gene expression profiles using histology images: A breast cancer case study,"Spatial transcriptomics is a breakthrough technology that enables spatially-resolved measurement of molecular profiles in tissues, opening the opportunity for integrated analyses of morphology and transcriptional profiles through paired imaging and gene expression data. However, the high cost of generating data has limited its widespread adoption. Predicting gene expression profiles from histology images only can be an effective and cost-efficient in-silico spatial transcriptomics solution but is computationally challenging and current methods are limited in model performance. To advance research in this emerging and important field, this study makes the following contributions. We first provide a systematic review of deep learning methods for predicting gene expression profiles from histology images, highlighting similarities and differences in algorithm, model architecture, and data processing pipelines. Second, we performed extensive experiments to evaluate the generalization performance of the reviewed methods on several spatial transcriptomics datasets for breast cancer, where the datasets are generated using different technologies. Lastly, we propose several ideas for model improvement and empirically investigate their effectiveness. Our results shed insight on key features in a neural network model that either improve or not the performance of in-silico spatial transcriptomics, and we highlight challenges in developing algorithms with strong generalization performance.Key MessagesWe comprehensively compared the performance of existing methods for predicting spatial gene expression profiles from histology imagesWe assessed the roles of different algorithms, model architectures, and data processing pipelines to model performanceWe performed extensive experiments to evaluate the generalization of the models on in-distribution and out-of-distribution spatial transcriptomics datasetsWe proposed several strategies for improving existing models and empirically investigated their effectiveness"
MMD-DTA: A multi-modal deep learning framework for drug-target binding affinity and binding region prediction,"The prediction of drug-target affinity (DTA) plays an important role in the development of drugs and the discovery of potential drug targets. In recent years, computer-assisted DTA prediction has become an important method in this field. In this work, we propose a multi-modal deep learning framework for drug-target binding affinity and binding region prediction, namely MMD-DTA. The model can predict DTA while unsupervised learning of drug-target binding regions. The experimental results show that MMD-DTA performs better than the existing models on the main evaluation metrics. In addition, external validation results show that MMD-DTA improves the generalization ability of the model by integrating sequence information and structural information of drugs and targets, and the model trained on the benchmark dataset can be well generalized to independent virtual screening tasks. Visualization of drug-target binding region prediction shows the powerful interpretability of MMD-DTA, which has important implications for exploring the functional regions of drug molecules acting on proteins."
Optimizing Glycemic Control in Type 1 Diabetic Patients using a Deep Learning-Based Artificial Pancreas with a Secure Glucagon and Insulin Delivery System,"Type 1 diabetes impacts millions worldwide, with some patients facing rapid fluctuations in their blood sugar levels. These fluctuations can negatively impact an individual’s quality of life and if untreated, can lead to nerve damage, coma, and death. While current methods have helped address hyperglycemia (high blood sugar), there has been less success with hypoglycemia (low blood sugar) and glucagon administration. To bridge this gap, an artificial pancreas with a novel insulin and glucagon pump was developed. Initiating the system, a personalized mobile app enables users to input meal carbohydrate and insulin bolus data. The data is then transmitted to a deep learning model that incorporates Continuous Glucose Monitor readings, along with carbohydrate and insulin data from the app. The two-layer Long Short-Term Memory network, developed in Python, accurately forecasts blood sugar levels on Ohio University’s OhioT1DM patient dataset and the UVa/Padova simulation’s data for a 30 minute-interval. An algorithm then utilizes the predictions to calculate optimal insulin and glucagon doses using metabolization formulas. To ensure system security, data is transmitted through a cloud-based MQ Telemetry Transport server and secured with industry-standard authentication and encryption methods. Finally, a microcontroller-based prototype accurately dispenses insulin and glucagon doses. The system kept in-silico patients at optimal levels for 38% longer and reduced dangerous levels by 22% compared to conventional controllers on an FDA-approved preclinical trial alternative simulation. By addressing both hypo and hyperglycemia, this real-time medical device can be a transformative tool for individuals with diabetes, enabling them to live healthier and more fulfilling lives."
Heterogeneity analysis of acute exacerbations of chronic obstructive pulmonary disease and a deep learning framework with weak supervision and privacy protection,"Background Chronic obstructive pulmonary disease (COPD) affects 5-10% of the adult US population and is a major cause of mortality. Acute exacerbations of COPD (AECOPDs) are a major driver of COPD morbidity and mortality, but there are no cost-effective methods to identify early AECOPDs when treatment is most likely to reduce the severity and duration of AECOPDs.Methods We conducted the first long-term (> 12 months), real-time monitoring studies of AECOPD with wearable sensors and self-reporting. We applied a deep learning-based autoencoder for feature extractions, then applied K-means clustering to detect heterogeneity. Accordingly, we proposed a weakly supervised active learning framework to develop anomaly detection models for robust identification of early AECOPD, and a clustered federated learning approach to personalize the anomaly detection models for early detection of heterogeneous subtypes of AECOPD. We evaluated this model by comparing it with other unsupervised learning models and federated learning models.Findings We identified two clusters based on the Silhouette score and SHAP analysis. We also found out that a single subject could have exacerbation events from both clusters, indicating that there is not only subject-level heterogeneity but also event-level heterogeneity. Our weakly supervised framework outperformed unsupervised methods by 0.06 in average precision with 25 human annotation labels per subject. Our federated learning framework outperformed standard federated learning methods by 0.14 in F1 score and 0.17 in average precision.Interpretation We showed subject-level and event-level heterogeneity in AECOPD using mobile and wearable device data and developed a practical AECOPD detection frame-work with limited human annotated labels and keeping data private in each device."
Pancreatic cancer risk predicted from disease trajectories using deep learning,"Pancreatic cancer is an aggressive disease that typically presents late with poor patient outcomes. There is a pronounced medical need for early detection of pancreatic cancer, which can be addressed by identifying high-risk populations. Here we apply artificial intelligence (AI) methods to a dataset of 6 million patient records with 24,000 pancreatic cancer cases in the Danish National Patient Registry (DNPR) and, for comparison, a dataset of three million records with 3,900 pancreatic cancer cases in the United States Department of Veterans Affairs (US-VA) healthcare system. In contrast to existing methods that do not use temporal information, we explicitly train machine learning models on the time sequence of diseases in patient clinical histories and test the ability to predict cancer occurrence in time intervals of 3 to 60 months after risk assessment.For cancer occurrence within 36 months, the performance of the best model (AUROC=0.88, DNPR), trained and tested on disease trajectories, exceeds that of a model without longitudinal information (AUROC=0.85, DNPR). Performance decreases when disease events within a 3 month window before cancer diagnosis are excluded from training (AUROC[3m]=0.83). Independent training and testing on the US-VA dataset reaches comparable performance (AUROC=0.78, AUROC[3m]=0.76). These results raise the state-of-the-art level of performance of cancer risk prediction on real-world data sets and provide support for the design of prediction-surveillance programs based on risk assessment in a large population followed by affordable surveillance of a relatively small number of patients at highest risk. Use of AI on real-world clinical records has the potential to shift focus from treatment of late-stage to early-stage cancer, benefiting patients by improving lifespan and quality of life."
Diagnosis with Confidence: Deep Learning for Reliable Classification of Squamous Lesions of the Upper Aerodigestive Tract,"Background Diagnosis of head and neck (HN) squamous dysplasias and carcinomas is critical for patient care cure and follow-up. It can be challenging, especially for grading intraepithelial lesions. Despite recent simplification in the last WHO grading system, the inter- and intra-observer variability remains substantial, particularly for non-specialized pathologists, exhibiting the need for new tools to support pathologists.Methods In this study we investigated the potential of deep learning to assist the pathologist with automatic and reliable classification of HN lesions following the 2022 WHO classification system. We created, for the first time, a large-scale database of histological samples (>2000 slides) intended for developing an automatic diagnostic tool. We developed and trained a weakly supervised model performing classification from whole slide images (WSI). We evaluated our model on both internal and external test sets and we defined and validated a new confidence score to assess the predictions which can be used to identify difficult cases.Results Our model demonstrated high classification accuracy across all lesion types on both internal and external test sets (respectively average AUC: 0.878 (95% CI:[0.834-0.918]) and 0.886 (95% CI: [0.813-0.947])) and the confidence score allowed for accurate differentiation between reliable and uncertain predictions.Conclusions Our results demonstrate that the model, associated with confidence measurements, can help in the difficult task of classifying head and neck squamous lesions by limiting variability and detecting ambiguous cases, taking us one step closer to a wider adoption of AI-based assistive tools."
Deep learning microstructure estimation of developing brains from diffusion MRI: a newborn and fetal study,"ABSTRACTDiffusion-weighted magnetic resonance imaging (dMRI) is widely used to assess the brain white matter. Fiber orientation distribution functions (FODs) are a common way of representing the orientation and density of white matter fibers. However, with standard FOD computation methods, accurate estimation of FODs requires a large number of measurements that usually cannot be acquired for newborns and fetuses. We propose to overcome this limitation by using a deep learning method to map as few as six diffusion-weighted measurements to the target FOD. To train the model, we use the FODs computed using multi-shell high angular resolution measurements as target. Extensive quantitative evaluations show that the new deep learning method, using significantly fewer measurements, achieves comparable or superior results to standard methods such as Constrained Spherical Deconvolution. We demonstrate the generalizability of the new deep learning method across scanners, acquisition protocols, and anatomy on two clinical datasets of newborns and fetuses. Additionally, we compute agreement metrics within the HARDI newborn dataset, and validate fetal FODs with post-mortem histological data. The results of this study show the advantage of deep learning in inferring the microstructure of the developing brain from in-vivo dMRI measurements that are often very limited due to subject motion and limited acquisition times, but also highlight the intrinsic limitations of dMRI in the analysis of the developing brain microstructure. These findings, therefore, advocate for the need for improved methods that are tailored to studying the early development of human brain."
StructuralDPPIV: A novel deep learning model based on atom-structure for predicting dipeptidyl peptidase-IV inhibitory peptides,"Motivation Diabetes is a chronic metabolic disorder that has been a major cause of blindness, kidney failure, heart attacks, stroke, and lower limb amputation across the world. To alleviate the impact of diabetes, researchers have developed the next generation of anti-diabetic drugs, known as dipeptidyl peptidase IV inhibitory peptides (DPP-IV-IPs). However, the discovery of these promising drugs has been restricted due to the lack of effective peptide-mining tools.Results Here, we presented StructuralDPPI V, a deep learning model designed for DPP-IV-IP identification, which takes advantage of both molecular graph features in amino acid and sequence information. Experimental results on the independent test dataset and two wet experiment datasets show that our model outperforms the other state-of-art methods. Moreover, to better study what StructuralDPPIV learns, we used CAM technology and perturbation experiment to analyze our model, which yielded interpretable insights into the reasoning behind prediction results.Availability The project code is available at https://github.com/WeiLab-BioChem/Structural-DPP-IV.Contact weileyi{at}sdu.edu.cn, ran.su{at}tju.edu.cn"
Personal transcriptome variation is poorly explained by current genomic deep learning models,"Genomic deep learning models can predict genome-wide epigenetic features and gene expression levels directly from DNA sequence. While current models perform well at predicting gene expression levels across genes in different cell types from the reference genome, their ability to explain expression variation between individuals due to cis-regulatory genetic variants remains largely unexplored. Here we evaluate four state-of-the-art models on paired personal genome and transcriptome data and find limited performance when explaining variation in expression across individuals."
Deep Learning of Ligand-bound RNA Tertiary Structures Diverges from Learning Unbound Ones: A Case Study Using The gRNAde Software,"Modeling the relationship between the native RNA sequence and its in-vivo structure is challenging, partly due to the flexible nature of the RNA molecular structure. In addition, the RNA structure can take on different conformations in the presence of specific molecules, metabolites, temperatures or other signaling and environmental factors, making it difficult to construct a universal statistical model for the sequence-structure relationship of the RNA. Using a Geometric-Vector-Perceptron Graph Neural Network architecture, Joshi, et al. predict the RNA sequence from its given 3D structure with good performance and on a dataset including RNA structures of different type and length, namely RNAsolo. In this work, using the Authors open-source software package, gRNAde, we confirm their results on a more updated version of RNAsolo and for structure of different resolution, confirming the ability of the algorithm to capture RNA structural features and generalize to sequences of different lengths. We did observe, however, that performance on riboswitches is lower than expected that RNAs whose structure has been resolved while being bound to a ligand, such as riboswitches, may require a statistical model that diverges from those of native structures."
SpheroScan: A User-Friendly Deep Learning Tool for Spheroid Image Analysis,"Background In recent years, three-dimensional (3D) spheroid models have become increasingly popular in scientific research as they provide a more physiologically relevant microenvironment that mimics in vivo conditions. The use of 3D spheroid assays has proven to be advantageous as it offers a better understanding of the cellular behavior, drug efficacy, and toxicity as compared to traditional two-dimensional cell culture methods. However, the use of 3D spheroid assays is impeded by the absence of automated and user-friendly tools for spheroid image analysis, which adversely affects the reproducibility and throughput of these assays.Results To address these issues, we have developed a fully automated, web-based tool called SpheroScan, which uses the deep learning framework called Mask Regions with Convolutional Neural Networks (R-CNN) for image detection and segmentation. To develop a deep learning model that could be applied to spheroid images from a range of experimental conditions, we trained the model using spheroid images captured using IncuCyte Live-Cell Analysis System and a conventional microscope. Performance evaluation of the trained model using validation and test datasets shows promising results.Conclusion SpheroScan allows for easy analysis of large numbers of images and provides interactive visualization features for a more in-depth understanding of the data. Our tool represents a significant advancement in the analysis of spheroid images and will facilitate the widespread adoption of 3D spheroid models in scientific research. The source code and a detailed tutorial for SpheroScan are available at https://github.com/FunctionalUrology/SpheroScan.Key PointsA deep learning model was trained to detect and segment spheroids in images from microscopes and Incucytes.The model performed well on both types of images with the total loss decreasing significantly during the training process.A web tool called SpheroScan was developed to facilitate the analysis of spheroid images, which includes prediction and visualization modules.SpheroScan is efficient and scalable, making it possible to handle large datasets with ease.SpheroScan is user-friendly and accessible to researchers, making it a valuable resource for the analysis of spheroid image data."
Deep learning pipeline reveals key moments in human embryonic development predictive of live birth in IVF,"Demand for IVF treatment is growing, however success rates remain low partly due to the difficulty in selecting the best embryo to be transferred. Current manual assessments are subjective and can lead to significant inter-operator variability. Deep learning techniques could lead to improved embryo assessment and live birth prediction, however previous attempts neglect early developmental stages and often require vast amounts of data. Here, we demonstrate that even with limited data it is possible to train convolutional neural networks to classify developmental stage at high accuracies and predict live birth from various time-points throughout development. We identify key windows that are optimal for assessing embryo viability and demonstrate the importance of incorporating information from earlier stages. Our outcome predictor models are competitive with, and potentially outperform, human expert selection. The pipeline produced here could lead to an improved, standardised approach to embryo selection compatible with multiple transfer strategies."
A Deep Learning Approach for Modelling the Complex Relationship between Environmental Factors and Biological Features,"Environmental factors play a pivotal role in shaping the genetic and phenotypic diversity among organisms. Understanding the influence of the environment on a biological phenomenon is essential for deciphering the mechanisms resulting in trait differences among organisms. In this study, we present a novel approach utilizing an Artificial Neural Network (ANN) model to investigate the impact of environmental factors on a wide range of biological phenomena. Our proposed workflow includes hyperparameter optimization using model-based methods such as Bayesian and direct-search methods such as Random Search, and a new approach combining random search and linear models (RandomSearch+lm) to ensure a robust ANN architecture. Moreover, we employed a generalized version of the variable importance method to generate the feature importance metric using estimated weights from ANN. By applying this comprehensive ANN-based approach to functional genomics, we can gain valuable insights into the mechanisms underlying trait differentiation in organisms, while simultaneously enabling prediction and feature selection tasks. This methodology provides a robust and efficient framework for studying the complex relationships between environmental factors and biological features in biological systems."
BrainQCNet: a Deep Learning attention-based model for the automated detection of artifacts in brain structural MRI scans,"Analyses of structural MRI (sMRI) data depend on robust upstream data quality control (QC). It is also crucial that researchers seek to retain maximal amounts of data to ensure reproducible, generalizable models and to avoid wasted effort, including that of participants. The time-consuming and difficult task of manual QC evaluation has prompted the development of tools for the automatic assessment of brain sMRI scans. Existing tools have proved particularly valuable in this age of Big Data; as datasets continue to grow, reducing execution time for QC evaluation will be of considerable benefit. The development of Deep Learning (DL) models for artifact detection in structural MRI scans offers a promising avenue toward fast, accurate QC evaluation. In this study, we trained an interpretable Deep Learning model, ProtoPNet, to classify minimally preprocessed 2D slices of scans that had been manually annotated with a refined quality assessment (ABIDE 1; n = 980 scans). To evaluate the best model, we applied it to 2141 ABCD scans for which gold-standard manual QC annotations were available. We obtained excellent accuracy: 82.4% for good quality scans (Pass), 91.4% for medium to low quality scans (Fail). Further validation using 799 scans from ABIDE 2 and 750 scans from ADHD-200 confirmed the reliability of our model. Accuracy was comparable to or exceeded that of existing ML models, with fast processing and prediction time (1 min per scan, GPU machine, CUDA-compatible). Our attention model also performs better than traditional DL (i.e., convolutional neural network models) in detecting poor quality scans. To facilitate faster and more accurate QC prediction for the neuroimaging community, we have shared the model that returned the most reliable global quality scores as a BIDS-app (https://github.com/garciaml/BrainQCNet)."
A Scalable Framework for Closed-Loop Neuromodulation with Deep Learning,"Closed-loop neuromodulation measures dynamic neural or physiological activity to optimize interventions for clinical and nonclinical behavioral, cognitive, wellness, attentional, or general task performance enhancement. Conventional closed-loop stimulation approaches can contain biased biomarker detection (decoders and error-based triggering) and stimulation-type application. We present and verify a novel deep learning framework for designing and deploying flexible, data-driven, automated closed-loop neuromodulation that is scalable using diverse datasets, agnostic to stimulation technology (supporting multi-modal stimulation: tACS, tDCS, tFUS, TMS), and without the need for personalized ground-truth performance data. Our approach is based on identified periods of responsiveness – detected states that result in a change in performance when stimulation is applied compared to no stimulation. To demonstrate our framework, we acquire, analyze, and apply a data-driven approach to our open sourced GX dataset, which includes concurrent physiological (ECG, EOG) and neuronal (EEG) measures, paired with continuous vigilance/attention-fatigue tracking, and High-Definition transcranial electrical stimulation (HD-tES). Our framework’s decision process for intervention application identified 88.26% of trials as correct applications, showed potential improvement with varying stimulation types, or missed opportunities to stimulate, whereas 11.25% of trials were predicted to stimulate at inopportune times. With emerging datasets and stimulation technologies, our unifying and integrative framework; leveraging deep learning (Convolutional Neural Networks - CNNs); demonstrates the adaptability and feasibility of automated multimodal neuromodulation for both clinical and nonclinical applications."
Explaining Deep Learning-Based Representations of Resting State Functional Connectivity Data: Focusing on Interpreting Nonlinear Patterns in Autism Spectrum Disorder,"Background Resting state Functional Magnetic Resonance Imaging fMRI (rs-fMRI) has been used to study brain function in psychiatric disorders, yielding insight into brain organization. However, the high dimensionality of the rs-fMRI data presents challenges, and requires dimensionality reduction before applying machine learning techniques. Neural networks, specifically variational autoencoders (VAEs), have been instrumental in extracting low-dimensional latent representations of resting state functional connectivity patterns, addressing the complex nonlinear structure of rs-fMRI. However, interpreting those latent representations remains a challenge. This paper aims to address this gap by creating explainable VAE models and testing their utility using rs-fMRI data in autism spectrum disorder (ASD).Methods One-thousand one hundred and fifty participants (601 HC and 549 patients with ASD) were included in the analysis. We extracted functional connectivity correlation matrices from the preprocessed rs-fMRI data using Power atlas with 264 ROIs. Then VAEs were trained in an unsupervised fashion. Lastly, we introduce our latent contribution scores to explain the relationship between estimated representations and the original rs-fMRI brain measures.Results We quantified the latent contribution scores for the ASD and control groups at the network level. We found that both ASD and control groups share the top network connectivity that contribute to all estimated latent components. For example, latent 0 was driven by resting state functional connectivity patterns (rsFC) within ventral attention network in both the ASD and control. However, significant differences in the latent contribution scores between the ASD and control groups were discovered within the ventral attention network in latent 0 and the sensory/somatomotor network in latent 2.Conclusion This study introduced latent contribution scores to interpret nonlinear patterns identified by VAEs. These scores effectively capture changes in each observed rsFC features as estimated latent representation changes, enabling an explainable deep learning model to better understand the underlying neural mechanism of ASD."
Deep Learning Dynamic Allostery of G-Protein-Coupled Receptors,"G-protein-coupled receptors (GPCRs) are the largest superfamily of human membrane proteins and represent primary targets of ∼1/3 of currently marketed drugs. Allosteric modulators have emerged as more selective drug candidates compared with orthosteric agonists and antagonists. However, many X-ray and cryo-EM structures of GPCRs resolved so far exhibit negligible differences upon binding of positive and negative allosteric modulators (PAMs and NAMs). Mechanism of dynamic allosteric modulation in GPCRs remains unclear. In this work, we have systematically mapped dynamic changes in free energy landscapes of GPCRs upon binding of allosteric modulators using the Gaussian accelerated molecular dynamics (GaMD), Deep Learning (DL) and free energy prOfiling Workflow (GLOW). A total of 18 available high-resolution experimental structures of allosteric modulator-bound class A and B GPCRs were collected for simulations. A number of 8 computational models were generated to examine selectivity of the modulators by changing their target receptors to different subtypes. All-atom GaMD simulations were performed for a total of 66 µs on 44 GPCR systems in the presence/absence of the modulator. DL and free energy calculations revealed significantly reduced conformational space of GPCRs upon modulator binding. While the modulator-free GPCRs often sampled multiple low-energy conformational states, the NAMs and PAMs confined the inactive and active agonist-G protein-bound GPCRs, respectively, to mostly only one specific conformation for signaling. Such cooperative effects were significantly reduced for binding of the selective modulators to “non-cognate” receptor subtypes in the computational models. Therefore, comprehensive DL of extensive GaMD simulations has revealed a general dynamic mechanism of GPCR allostery, which will greatly facilitate rational design of selective allosteric drugs of GPCRs."
Vocabulary Matters: An Annotation Pipeline and Two Deep Learning Algorithms for Enzyme Named Entity Recognition,"Enzymes are indispensable substances in many biological processes. With biomedical literature growing exponentially, it becomes more difficult to review the literature effectively. Hence, text-mining techniques are needed to facilitate and speed up literature review. The aims of this study are to create a corpus with annotated enzymes to train and evaluate enzyme named-entity recognition (NER) models. A novel pipeline was built using a combination of dictionary matching and rulebased keyword searching to automatically annotate enzyme entities in over 4,800 biomedical full texts. Two Bidirectional Long Short-Term Memory (BiLSTM) networks using BioBERT and SciBERT as tokeniser and word embedding layers were trained on this corpus and evaluated on a manually annotated test set of 526 full-text publications. The dictionary- and rule-based annotation pipeline achieved an F1-score of 0.863 (precision 0.996, recall 0.762). The SciBERT-BiLSTM model (F1-score 0.965, precision 0.981, recall 0.954) largely out-performed the BioBERT-BiLSTM model (F1-score 0.955, precision 0.981, recall 0.937). This study contributed a novel dictionary- and rule-based automatic pipeline with almost perfect precision which runs in a matter of seconds on a standard laptop. Both deep learning (DL) models achieved state-of-the-art performance (F1>0.95) for enzyme NER, with the SciBERT-based model outperforming the BioBERT-based model in terms of recall, demonstrating the vocabulary used by models matters. The proposed pipeline with the DL models can facilitate more effective enzyme text-mining and information extraction research for literature review and are the first algorithms specifically for enzyme NER.Availability All codes are available for automatic annotation and model training (including data), with instructions on how to deploy the model on new text, from https://github.com/omicsNLP/enzymeNER."
Biophysical neural adaptation mechanisms enable deep learning models to capture dynamic retinal computation,"Neural adaptation is a universal feature of neural systems that modulates the output based on input conditions, enabling efficient encoding of sensory inputs without saturation or loss. In contrast, conventional artificial neural networks (ANNs) lack these adaptational mechanisms, resulting in inaccurate neural predictions under changing input conditions. Can embedding neural adaptive mechanisms in ANNs improve their performance and generate biologically-plausible models? To address this question, we introduce a new type of convolutional neural network (CNN) layer incorporating photoreceptor biophysics and adaptation mechanisms to model light-dependent photoreceptor sensitivity and kinetics. Under changing input light conditions, CNNs that include the new photoreceptor layer integrated as a front-end perform better than conventional CNN models at predicting: (1) monkey and rat retinal ganglion cell responses; and (2) context-dependent changes in neural sensitivity. This study demonstrates the potential of embedding neural adaptive mechanisms in deep learning models, enabling them to adapt dynamically to evolving inputs."
Functional microRNA-Targeting Drug Discovery by Graph-Based Deep Learning,"MicroRNAs are recognized as key drivers in many cancers, but targeting them with small molecules remains a challenge. We present RiboStrike, a deep learning framework that identifies small molecules against specific microRNAs. To demonstrate its capabilities, we applied it to microRNA-21 (miR-21), a known driver of breast cancer. To ensure the selected molecules only targeted miR-21 and not other microRNAs, we also performed a counter-screen against DICER, an enzyme involved in microRNA biogenesis. Additionally, we used auxiliary models to evaluate toxicity and select the best candidates. Using datasets from various sources, we screened a pool of nine million molecules and identified eight, three of which showed anti-miR-21 activity in both reporter assays and RNA sequencing experiments. One of these was also tested in mouse models of breast cancer, resulting in a significant reduction of lung metastases. These results demonstrate RiboStrike’s ability to effectively screen for microRNA-targeting compounds in cancer."
scDeepInsight: a supervised cell-type identification method for scRNA-seq data with deep learning,"Annotation of cell-types is a critical step in the analysis of single-cell RNA sequencing (scRNA-seq) data that allows the study of heterogeneity across multiple cell populations. Currently this is most commonly done using unsupervised clustering algorithms, which project single-cell expression data into a lower dimensional space and then cluster cells based on their distances from each other. However, as these methods do not use reference datasets, they can only achieve a rough classification of cell-types, and it is difficult to improve the recognition accuracy further. To effectively solve this issue we propose a novel supervised annotation method, scDeepInsight. The scDeepInsight method is capable of performing manifold assignments. It is competent in executing data integration through batch normalization, performing supervised training on the reference dataset, doing outlier detection and annotating cell-types on query datasets. Moreover, it can help identify active genes or marker genes related to cell-types. The training of the scDeepInsight model is performed in a unique way. Tabular scRNA-seq data are first converted to corresponding images through the DeepInsight methodology. DeepInsight can create a trainable image transformer to convert non-image RNA data to images by comprehensively comparing interrelationships among multiple genes. Subsequently, the converted images are fed into convolutional neural networks (CNNs) such as EfficientNet-b3. This enables automatic feature extraction to identify the cell-types of scRNA-seq samples. We benchmarked scDeepInsight with six other mainstream cell annotation methods. The average accuracy rate of scDeepInsight reached 87.5%, which is more than 7% higher compared with the state-of-the-art methods."
A deep learning network for parallel self-denoising and segmentation in visible light optical coherence tomography of human retina,"Visible light optical coherence tomography (VIS-OCT) of human retina is an emerging imaging modality that uses shorter wavelength in visible light range than conventional near infrared (NIR) light. It provides one-micron level axial resolution to better separate stratified retinal layers, as well as microvascular oximetry. However, due to the practical limitation of laser safety and comfort, the permissible illumination power is much lower than NIR OCT which can be challenging to obtain high quality VIS-OCT images and subsequent image analysis. Therefore, improving VIS-OCT image quality by denoising is an essential step in the overall workflow in VIS-OCT clinical applications. In this paper, we provide the first VIS-OCT retinal image dataset from normal eyes, including retinal layer annotation and “noisy-clean” image pairs. We propose an efficient co-learning deep learning framework for parallel self-denoising and segmentation simultaneously. Both tasks synergize within the same network and improve each other’s performance. The significant improvement of segmentation (2% higher Dice coefficient compared to segmentation-only process) for ganglion cell layer (GCL), inner plexiform layer (IPL) and inner nuclear layer (INL) is observed when available annotation drops to 25%, suggesting an annotation-efficient training. We also showed that the denoising model trained on our dataset generalizes well for a different scanning protocol."
Optimizing 5’UTRs for mRNA-delivered gene editing using deep learning,"mRNA therapeutics are revolutionizing the pharmaceutical industry, but methods to optimize the primary sequence for increased expression are still lacking. Here, we design 5’UTRs for efficient mRNA translation using deep learning. We perform polysome profiling of fully or partially randomized 5’UTR libraries in three cell types and find that UTR performance is highly correlated across cell types. We train models on all our datasets and use them to guide the design of high-performing 5’UTRs using gradient descent and generative neural networks. We experimentally test designed 5’UTRs with mRNA encoding megaTALTM gene editing enzymes for two different gene targets and in two different cell lines. We find that the designed 5’UTRs support strong gene editing activity. Editing efficiency is correlated between cell types and gene targets, although the best performing UTR was specific to one cargo and cell type. Our results highlight the potential of model-based sequence design for mRNA therapeutics."
When Geometric Deep Learning Meets Pretrained Protein Language Models,"Geometric deep learning has recently achieved great success in non-Euclidean domains, and learning on 3D structures of large biomolecules is emerging as a distinct research area. However, its efficacy is largely constrained due to the limited quantity of structural data. Meanwhile, protein language models trained on substantial 1D sequences have shown burgeoning capabilities with scale in a broad range of applications. Nevertheless, no preceding studies consider combining these different protein modalities to promote the representation power of geometric neural networks. To address this gap, we make the foremost step to integrate the knowledge learned by well-trained protein language models into several state-of-the-art geometric networks. Experiments are evaluated on a variety of protein representation learning benchmarks, including protein-protein interface prediction, model quality assessment, protein-protein rigid-body docking, and binding affinity prediction, leading to an overall improvement of 20% over baselines and the new state-of-the-art performance. Strong evidence indicates that the incorporation of protein language models’ knowledge enhances geometric networks’ capacity by a significant margin and can be generalized to complex tasks."
SoyDNGP: A Web-Accessible Deep Learning Framework for Genomic Prediction in Soybean Breeding,"Soybean is a globally significant crop, playing a vital role in human nutrition and agriculture. Its complex genetic structure and wide trait variation, however, pose challenges for breeders and researchers aiming to optimize its yield and quality. Addressing this biological complexity requires innovative and accurate tools for trait prediction. In response to this challenge, we have developed SoyDNGP, a Convolutional Neural Networks (CNN)-based model that offers significant advancements in the field of soybean trait prediction. Compared to existing methods, such as DeepGS and DNNGP, SoyDNGP boasts a distinct advantage due to its lower parameter volume and superior predictive accuracy. Through rigorous performance comparison, including prediction accuracy and model complexity, SoyDNGP consistently outperformed its counterparts. Furthermore, it effectively predicted complex traits with remarkable precision, demonstrating robust performance across different sample sizes and trait complexities. We also tested the versatility of SoyDNGP across multiple crop species, including Cotton, Maize, Rice, and Tomato. Our results showed its consistent and comparable performance, emphasizing SoyDNGP’s potential as a versatile tool for genomic prediction across a broad range of crops. To enhance its accessibility to users without extensive programming experience, we have designed a user-friendly web server, available at http://xtlab.hzau.edu.cn/SoyDNGP. The server provides two primary features: ‘Trait Lookup’, offering users the ability to access pre-existing trait predictions for over 500 soybean accessions, and ‘Trait Prediction’, allowing for the upload of VCF files for trait estimation. By providing a high-performing, accessible tool for trait prediction and genomic analysis, SoyDNGP opens up new possibilities in the quest for efficient and optimized soybean breeding."
PROTACable is an Integrative Computational Pipeline of 3-D Modeling and Deep Learning to Automate the De Novo Design of PROTACs,"Proteolysis-targeting chimeras (PROTACs) that engages two biological targets at once is a promising technology in degrading clinically relevant protein targets. Since factors that influence the biological activities of PROTACs are more complex than those of a small molecule drug, we explored a combination of computational chemistry and deep learning strategies to forecast PROTAC activity and enable automated design. A new method named PROTACable was developed for de novo design of PROTACs, which includes a robust 3-D modeling workflow to model PROTAC ternary complexes using a library of E3 ligase and linker and an SE(3)-equivariant graph transformer network to predict the activity of newly designed PROTACs. PROTACable is available at https://github.com/giaguaro/PROTACable/."
Training deep learning models for cell image segmentation with sparse annotations,"Deep learning is becoming more prominent in cell image analysis. However, collecting the annotated data required to train efficient deep-learning models remains a major obstacle. I demonstrate that functional performance can be achieved even with sparsely annotated data. Furthermore, I show that the selection of sparse cell annotations significantly impacts performance. I modified Cellpose and StarDist to enable training with sparsely annotated data and evaluated them in conjunction with ELE-PHANT, a cell tracking algorithm that internally uses U-Net based cell segmentation. These results illustrate that sparse annotation is a generally effective strategy in deep learning-based cell image segmentation. Finally, I demonstrate that with the help of the Segment Anything Model (SAM), it is feasible to build an effective deep learning model of cell image segmentation from scratch just in a few minutes."
Deep learning-based survival prediction using DNA methylation-derived 3D genomic information,"ABSTRACTThree-dimensional (3D) genome states are closely related to cancer development. Nonetheless, the 3D genome information has not been clinically utilized to the best of our knowledge, due to the costly production of Hi-C data which is a manifest source of 3D genome information. Therefore, there is a need for a novel metric computable from a 3D genome-related data which is more easily accessible for the clinical utilization of 3D genome information. We here propose a method to extract 3D genome-aware epigenetic features from DNA methylation data and use these features for a deep learning-based survival prediction. These features are derived from the 3D genome structures which are rebuilt from the DNA methylation data in an individual level. The results showed that usage of 3D genome-aware features contributed to more accurate risk prediction across seven cancer types, suggesting the effectiveness of the knowledge about 3D genome structure embedded in these features. The deeper biological investigation revealed that altered DNA methylation level in risk-high group could be related to the anomalously activated genes involved in cancer-related pathways. Altogether, the risks predicted from 3D genome-aware epigenetic features showed its significance as a survival predictor in seven cancer types, along with its biological importance."
LegNet: a best-in-class deep learning model for short DNA regulatory regions,"Motivation The increasing volume of data from high-throughput experiments including parallel reporter assays facilitates the development of complex deep learning approaches for DNA regulatory grammar.Results Here we introduce LegNet, an EfficientNetV2-inspired convolutional network for modeling short gene regulatory regions. By approaching the sequence-to-expression regression problem as a soft classification task, LegNet secured first place for the autosome.org team in the DREAM 2022 challenge of predicting gene expression from gigantic parallel reporter assays. Using published data, here we demonstrate that LegNet outperforms existing models and accurately predicts gene expression per se as well as the effects of single-nucleotide variants. Furthermore, we show how LegNet can be used in a diffusion network manner for the rational design of promoter sequences yielding the desired expression level.Availability and Implementation https://github.com/autosome-ru/LegNet. The GitHub repository includes the Python code under the MIT license to reproduce the results presented in the study and a Jupyter Notebook tutorial.Supplementary Information Online-only supplementary data are available at Bioinformatics online.Contact dmitrypenzar1996{at}gmail.com, ivan.kulakovskiy{at}gmail.com"
NEUROeSTIMator: Using Deep Learning to Quantify Neuronal Activation from Single-Cell and Spatial Transcriptomic Data,"ABSTRACTNeuronal activity-dependent transcription directs molecular processes that regulate synaptic plasticity, brain circuit development, behavioral adaptation, and long-term memory. Single cell RNA-sequencing technologies (scRNAseq) are rapidly developing and allow for the interrogation of activity-dependent transcription at cellular resolution. Here, we present NEUROeSTIMator, a deep learning model that integrates transcriptomic signals to estimate neuronal activation in a way that we demonstrate is associated with Patch-seq electrophysiological features and that is robust against differences in species, cell type, and brain region. We demonstrate this method’s ability to accurately detect neuronal activity in previously published studies of single cell activity-induced gene expression. Further, we applied our model in a spatial transcriptomic study to identify unique patterns of learning-induced activity across different brain regions. Altogether, our findings establish NEUROeSTIMator as a powerful and broadly applicable tool for measuring neuronal activation, whether as a critical covariate or a primary readout of interest."
A Pooled Cell Painting CRISPR Screening Platform Enables de novo Inference of Gene Function by Self-supervised Deep Learning,"Pooled CRISPR screening has emerged as a powerful method of mapping gene functions thanks to its scalability, affordability, and robustness against well or plate-specific confounders present in array-based screening 1–6. Most pooled CRISPR screens assay for low dimensional phenotypes (e.g. fitness, fluorescent markers). Higher-dimensional assays such as perturb-seq are available but costly and only applicable to transcriptomics readouts 7–11. Recently, pooled optical screening, which combines pooled CRISPR screening and microscopy-based assays, has been demonstrated in the studies of the NFkB pathway, essential human genes, cytoskeletal organization and antiviral response 12–15. While the pooled optical screening methodology is scalable and information-rich, the applications thus far employ hypothesis-specific assays. Here, we enable hypothesis-free reverse genetic screening for generic morphological phenotypes by re-engineering the Cell Painting 16 technique to provide compatibility with pooled optical screening. We validated this technique using well-defined morphological genesets (124 genes), compared classical image analysis and self-supervised learning methods using a mechanism-of-action (MoA) library (300 genes), and performed discovery screening with a druggable genome library (1640 genes) 17. Across these three experiments we show that the combination of rich morphological data and deep learning allows gene networks to emerge without the need for target-specific biomarkers, leading to better discovery of gene functions."
Combined topological data analysis and geometric deep learning reveal niches by the quantification of protein binding pockets,"ABSTRACTProtein pockets are essential for many proteins to carry out their functions. Locating and measuring protein pockets as well as studying the anatomy of pockets helps us further understand protein function. Most research studies focus on learning either local or global information from protein structures. However, there is a lack of studies that leverage the power of integrating both local and global representations of these structures. In this work, we combine topological data analysis (TDA) and geometric deep learning (GDL) to analyze the putative protein pockets of enzymes. TDA captures blueprints of the global topological invariant of protein pockets, whereas GDL decomposes the fingerprints to building blocks of these pockets. This integration of local and global views provides a comprehensive and complementary understanding of the protein structural motifs (niches for short) within protein pockets. We also analyze the distribution of the building blocks making up the pocket and profile the predictive power of coupling local and global representations for the task of discriminating between enzymes and non-enzymes. We demonstrate that our representation learning framework for macromolecules is particularly useful when the structure is known, and the scenarios heavily rely on local and global information."
IPEV: Identification of Prokaryotic and Eukaryotic Virus-derived sequences in virome using deep learning,"Background The virome obtained through virus-like particle enrichment contain a mixture of prokaryotic and eukaryotic virus-derived fragments. Accurate identification and classification of these elements are crucial for understanding their roles and functions in microbial communities. However, the rapid mutation rates of viral genomes pose challenges in developing high-performance tools for classification, potentially limiting downstream analyses.Findings We present IPEV, a novel method that combines trinucleotide pair relative distance and frequency with a 2D convolutional neural network for distinguishing prokaryotic and eukaryotic viruses in viromes. Cross-validation assessments of IPEV demonstrate its state-of-the-art precision, significantly improving the F1-score by approximately 22% on an independent test set compared to existing methods when query viruses share less than 30% sequence similarity with known viruses. Furthermore, IPEV outperforms other methods in terms of accuracy on most real virome samples when using sequence alignments as annotations. Notably, IPEV reduces runtime by 50 times compared to existing methods under the same computing configuration. We utilized IPEV to reanalyze longitudinal samples and found that the gut virome exhibits a higher degree of temporal stability than previously observed in persistent personal viromes, providing novel insights into the resilience of the gut virome in individuals.Conclusions IPEV is a high-performance, user-friendly tool that assists biologists in identifying and classifying prokaryotic and eukaryotic viruses within viromes. The tool is available at https://github.com/basehc/IPEV."
A Deep Learning Approach for Mental Health Quality Prediction Using Functional Network Connectivity and Assessment Data,"While one can characterize mental health using questionnaires, such tools do not provide direct insight into the underlying biology. By linking approaches that visualize brain activity to questionnaires in the context of individualized prediction, we can gain new insights into the biology and behavioral aspects of brain health. Resting-state fMRI (rs-fMRI) can be used to identify biomarkers of these conditions and study patterns of abnormal connectivity. In this work, we estimate mental health quality for individual participants using static functional network connectivity (sFNC) data from rs-fMRI. The deep learning model uses the sFNC data as input to predict four categories of mental health quality and visualize the neural patterns indicative of each group. We used guided gradient class activation maps (guided Grad-CAM) to identify the most discriminative sFNC patterns. The effectiveness of this model was validated using the UK Biobank dataset, in which we showed that our approach outperformed four alternative models by 4-18% accuracy. The proposed model’s performance evaluation yielded a classification accuracy of 76%, 78%, 88%, and 98% for the excellent, good, fair, and poor mental health categories, with poor mental health accuracy being the highest. The findings show distinct sFNC patterns across each group. The patterns associated with excellent mental health consist of the cerebellar-subcortical regions, whereas the most prominent areas in the poor mental health category are in the sensorimotor and visual domains. Thus the combination of rs-fMRI and deep learning opens a promising path for developing a comprehensive framework to evaluate and measure mental health. Moreover, this approach had the potential to guide the development of personalized interventions and enable the monitoring of treatment response. Overall this highlights the crucial role of advanced imaging modalities and deep learning algorithms in advancing our understanding and management of mental health."
AGILE Platform: A Deep Learning-Powered Approach to Accelerate LNP Development for mRNA Delivery,"Ionizable lipid nanoparticles (LNPs) have seen widespread use in mRNA delivery for clinical applications, notably in SARS-CoV-2 mRNA vaccines. Despite their successful use, expansion of mRNA therapies beyond COVID-19 is impeded by the absence of LNPs tailored to different target cell types. The traditional process of LNP development remains labor-intensive and cost-inefficient, relying heavily on trial and error. In this study, we present the AI-Guided Ionizable Lipid Engineering (AGILE) platform, a synergistic combination of deep learning and combinatorial chemistry. AGILE streamlines the iterative development of ionizable lipids, crucial components for LNP-mediated mRNA delivery. This approach brings forth three significant features: efficient design and synthesis of combinatorial lipid libraries, comprehensive in silico lipid screening employing deep neural networks, and adaptability to diverse cell lines. Using AGILE, we were able to rapidly design, synthesize, and evaluate new ionizable lipids for mRNA delivery in muscle and immune cells, selecting from a library of over 10,000 candidates. Importantly, AGILE has revealed cell-specific preferences for ionizable lipids, indicating the need for different tail lengths and head groups for optimal delivery to varying cell types. These results underscore the potential of AGILE in expediting the development of customized LNPs. This could significantly contribute to addressing the complex needs of mRNA delivery in clinical practice, thereby broadening the scope and efficacy of mRNA therapies.One Sentence Summary AI and combinatorial chemistry expedite ionizable lipid creation for mRNA delivery."
Deep learning from harmonized peptide libraries enables retention time prediction of diverse post translational modifications,"In proteomics experiments, peptide retention time (RT) is an orthogonal property to fragmentation when assessing detection confidence. Advances in deep learning enable accurate RT prediction for any peptide from sequence alone, including those yet to be experimentally observed. Here we present Chronologer, an open-source software tool for rapid and accurate peptide RT prediction. Using new approaches to harmonize and false-discovery correct across independently collected datasets, Chronologer is built on a massive database with >2.2 million peptides including 10 common post-translational modification (PTM) types. By linking knowledge learned across diverse peptide chemistries, Chronologer predicts RTs with less than two-thirds the error of other deep learning tools. We show how RT for rare PTMs, such as OGlcNAc, can be learned with high accuracy using as few as 10-100 example peptides in newly harmonized datasets. This iteratively updatable workflow enables Chronologer to comprehensively predict RTs for PTM-marked peptides across entire proteomes."
Multitask Learning of Longitudinal Circulating Biomarkers and Clinical Outcomes: Identification of Optimal Machine-Learning and Deep-Learning Models,"Many circulating biomarkers are assessed at different time intervals during clinical studies. Despite of the success of standard joint models in predicting clinical outcomes using low-dimensional longitudinal data (1-2 biomarkers), significant computational challenges are encountered when applying these techniques to high-dimensional biomarker datasets. Modern machine- or deep-learning models show potential for multiple biomarker processes, but systematic evaluations and applications to high-dimensional data in the clinical settings have yet to be reported. We aimed to enhance the scalability of joint modeling and provide guidance on optimal approaches for high-dimensional biomarker data and outcomes. We evaluated multiple deep-learning and machine-learning models using 24 clinical biomarkers and survival data from the SQUIRE trial, a phase 3 randomized clinical trial investigating necitumumab and standard gemcitabine/cisplatin treatment in patients with squamous non-small-cell lung cancer (NSCLC). Overall, we confirmed that longitudinal models enabled more accurate prediction of patients’ survival compared to those solely based on baseline information. Coupling multivariate functional principal component analysis (MFPCA) with Cox regression (MFPCA-Cox) provided the highest predictive discrimination and accuracy for the NSCLC patients with AUC values of 0.7 - >0.8 at various landmark time points and prediction timeframes, outperforming recent advanced Transformer and convolutional neural network deep-learning algorithms (TransformerJM and Match-Net, respectively). In conclusion, we identified that MFPCA-Cox represents a robust and versatile joint modeling algorithm for high-dimensional biomarker longitudinal data with irregular and missing data, capturing complex relationships within the data, yielding accurate predictions for both longitudinal biomarkers and survival outcomes, and gaining insights into the underlying dynamics."
Rank-based deep learning from citizen-science data to model plant communities,"In the age of big data, scientific progress is fundamentally limited by our capacity to extract critical information. We show that recasting multispecies distribution modeling as a ranking problem allows analyzing ubiquitous citizen-science observations with unprecedented efficiency. Based on 6.7M observations, we jointly modeled the distributions of 2477 plant species and species aggregates across Switzerland, using deep neural networks (DNNs). Compared to commonly-used approaches, multispecies DNNs predicted species distributions and especially community composition more accurately. Moreover, their setup allowed investigating understudied aspects of ecology: including seasonal variations of observation probability explicitly allowed approximating flowering phenology, especially for small, herbaceous species; reweighting predictions to mirror cover-abundance allowed mapping potentially canopy-dominant tree species nationwide; and projecting DNNs into the future allowed assessing how distributions, phenology, and dominance may change. Given their skill and their versatility, multispecies DNNs can refine our understanding of the distribution of plants and well-sampled taxa in general."
Multimodal Deep Learning Model Unveils Behavioral Dynamics of V1 Activity in Freely Moving Mice,"Despite their immense success as a model of macaque visual cortex, deep convolutional neural networks (CNNs) have struggled to predict activity in visual cortex of the mouse, which is thought to be strongly dependent on the animal’s behavioral state. Furthermore, most computational models focus on predicting neural responses to static images presented under head fixation, which are dramatically different from the dynamic, continuous visual stimuli that arise during movement in the real world. Consequently, it is still unknown how natural visual input and different behavioral variables may integrate over time to generate responses in primary visual cortex (V1). To address this, we introduce a multimodal recurrent neural network that integrates gaze-contingent visual input with behavioral and temporal dynamics to explain V1 activity in freely moving mice. We show that the model achieves state-of-the-art predictions of V1 activity during free exploration and demonstrate the importance of each component in an extensive ablation study. Analyzing our model using maximally activating stimuli and saliency maps, we reveal new insights into cortical function, including the prevalence of mixed selectivity for behavioral variables in mouse V1. In summary, our model offers a comprehensive deep-learning framework for exploring the computational principles underlying V1 neurons in freely-moving animals engaged in natural behavior."
Neuropsychiatric Disorder Subtyping Via Clustered Deep Learning Classifier Explanations,"Identifying subtypes of neuropsychiatric disorders based on characteristics of their brain activity has tremendous potential to contribute to a better understanding of those disorders and to the development of new diagnostic and personalized treatment approaches. Many studies focused on neuropsychiatric disorders examine the interaction of brain networks over time using dynamic functional network connectivity (dFNC) extracted from resting-state functional magnetic resonance imaging data. Some of these studies involve the use of either deep learning classifiers or traditional clustering approaches, but usually not both. In this study, we present a novel approach for subtyping individuals with neuropsychiatric disorders within the context of schizophrenia (SZ). We train an explainable deep learning classifier to differentiate between dFNC data from individuals with SZ and controls, obtaining a test accuracy of 79%. We next make use of cross-validation to obtain robust average explanations for SZ training participants across folds, identifying 5 SZ subtypes that each differ from controls in a distinct manner and that have different degrees of symptom severity. These subtypes specifically differ from one another in their interaction between the visual network and the subcortical, sensorimotor, and auditory networks and between the cerebellar network and the cognitive control and subcortical networks. Additionally, there are statistically significant differences in negative symptom scores between the subtypes. It is our hope that the proposed novel subtyping approach will contribute to the improved understanding and characterization of SZ and other neuropsychiatric disorders."
Disease associated human TCR characterization by deep-learning framework TCR-DeepInsight,"SUMMARYT cell function is defined by both T cell receptors (TCR) and T cell gene expression (GEX). Although single-cell technology enables the simultaneous capture of TCR and GEX information, the lack of a reference atlas and computational tools hinders our ability to uncover the fundamental TCR usage rules and to efficiently characterize disease-associated TCRs (dTCR). Here, through the collection of million-scale single-cell GEX-TCR reference atlas comprising 20 diverse disease conditions, we revealed the intrinsic features of TCR-MHC (Major Histocompatibility Complex) restriction in CD4/CD8 lineages. We observed the higher coherence for TCRα/β chains in memory T cells, and detected widely-existing public TCRα/β pairs across individuals. Building upon the reference atlas, we introduced TCR- DeepInsight, a deep-learning framework featuring a disease specificity scoring system that enables the characterization of dTCR clusters with similar GEX-TCR. Our study provides a valuable tool for researchers to analyze single-cell GEX-TCR data and identify dTCRs comprehensively and robustly."
Employing Deep Learning Model to Evaluate Speech Information in Vocoder Simulations of Auditory Implants,"Vocoder simulations have played a crucial role in the development of sound coding and speech processing techniques for auditory implant devices. Vocoders have been extensively used to model the effects of implant signal processing as well as individual anatomy and physiology on speech perception of implant users. Traditionally, such simulations have been conducted on human subjects, which can be time-consuming and costly. In addition, perception of vocoded speech varies significantly across individual subjects, and can be significantly affected by small amounts of familiarization or exposure to vocoded sounds. In this study, we propose a novel method that differs from traditional vocoder studies. Rather than using actual human participants, we use a speech recognition model to examine the influence of vocoder-simulated cochlear implant processing on speech perception. We used the OpenAI Whisper, a recently developed advanced open-source deep learning speech recognition model. The Whisper model’s performance was evaluated on vocoded words and sentences in both quiet and noisy conditions with respect to several vocoder parameters such as number of spectral bands, input frequency range, envelope cut-off frequency, envelope dynamic range, and number of discriminable envelope steps. Our results indicate that the Whisper model exhibited human-like robustness to vocoder simulations, with performance closely mirroring that of human subjects in response to modifications in vocoder parameters. Furthermore, this proposed method has the advantage of being far less expensive and quicker than traditional human studies, while also being free from inter-individual variability in learning abilities, cognitive factors, and attentional states. Our study demonstrates the potential of employing advanced deep learning models of speech recognition in auditory prosthesis research."
No Free Lunch from Deep Learning in Neuroscience: A Case Study through Models of the Entorhinal-Hippocampal Circuit,"Research in Neuroscience, as in many scientific disciplines, is undergoing a renaissance based on deep learning. Unique to Neuroscience, deep learning models can be used not only as a tool but interpreted as models of the brain. The central claims of recent deep learning-based models of brain circuits are that they make novel predictions about neural phenomena or shed light on the fundamental functions being optimized. We show, through the case-study of grid cells in the entorhinal-hippocampal circuit, that one may get neither. We begin by reviewing the principles of grid cell mechanism and function obtained from first-principles modeling efforts, then rigorously examine the claims of deep learning models of grid cells. Using large-scale architectural and hyperparameter sweeps and theory-driven experimentation, we demonstrate that the results of such models may be more strongly driven by particular, non-fundamental, and post-hoc implementation choices than fundamental truths about neural circuits or the loss function(s) they might optimize. We discuss why these models cannot be expected to produce accurate models of the brain without the addition of substantial amounts of inductive bias, an informal No Free Lunch result for Neuroscience. Based on first principles work, we provide hypotheses for what additional loss functions will produce grid cells more robustly. In conclusion, circumspection and transparency, together with biological knowledge, are warranted in building and interpreting deep learning models in Neuroscience."
iDeLUCS: A deep learning interactive tool for alignment-free clustering of DNA sequences,"Summary We present an interactive Deep Learning-based software tool for Unsupervised Clustering of DNA Sequences (iDeLUCS), that detects genomic signatures and uses them to cluster DNA sequences, without the need for sequence alignment or taxonomic identifiers. iDeLUCS is scalable and user-friendly: Its graphical user interface, with support for hardware acceleration, allows the practitioner to fine-tune the different hyper-parameters involved in the training process without requiring extensive knowledge of deep learning. The performance of iDeLUCS was evaluated on a diverse set of datasets: several real genomic datasets from organisms in kingdoms Animalia, Protista, Fungi, Bacteria, and Archaea, three datasets of viral genomes, a dataset of simulated metagenomic reads from microbial genomes, and multiple datasets of synthetic DNA sequences. The performance of iDeLUCS was compared to that of two classical clustering algorithms (k-means++ and GMM) and two clustering algorithms specialized in DNA sequences (MeShClust v3.0 and DeLUCS), using both intrinsic cluster evaluation metrics and external evaluation metrics. In terms of unsupervised clustering accuracy, iDeLUCS outperforms the two classical algorithms by an average of ∼ 20%, and the two specialized algorithms by an average of ∼ 12%, on the datasets of real DNA sequences analyzed. Overall, our results indicate that iDeLUCS is a robust clustering method suitable for the clustering of large and diverse datasets of unlabelled DNA sequences.Availability and implementation iDeLUCS is available at our github repository under the terms of the MIT licence.Contact pmillana{at}uwaterloo.caSupplementary information Supplementary data are available at Bioinformatics online."
Correlating Deep Learning-Based Automated Reference Kidney Histomorphometry with Patient Demographics and Creatinine,"Background Reference histomorphometric data of healthy human kidneys are largely lacking due to laborious quantitation requirements. Correlating histomorphometric features with clinical parameters through machine learning approaches can provide valuable information about natural population variance. To this end, we leveraged deep learning, computational image analysis, and feature analysis to investigate the relationship of histomorphometry with patient age, sex, and serum creatinine (SCr) in a multinational set of reference kidney tissue sections.Methods A panoptic segmentation neural network was developed and used to segment viable and sclerotic glomeruli, cortical and medullary interstitia, tubules, and arteries/arterioles in the digitized images of 79 periodic acid-Schiff-stained human nephrectomy sections showing minimal pathologic changes. Simple morphometrics (e.g., area, radius, density) were quantified from the segmented classes. Regression analysis aided in determining the relationship of histomorphometric parameters with age, sex, and SCr.Results Our deep-learning model achieved high segmentation performance for all test compartments. The size and density of nephrons and arteries/arterioles varied significantly among healthy humans, with potentially large differences between geographically diverse patients. Nephron size was significantly dependent on SCr. Slight, albeit significant, differences in renal vasculature were observed between sexes. Glomerulosclerosis percentage increased, and cortical density of arteries/arterioles decreased, as a function of age.Conclusions Using deep learning, we automated precise measurements of kidney histomorphometric features. In the reference kidney tissue, several histomorphometric features demonstrated significant correlation to patient demographics and SCr. Deep learning tools can increase the efficiency and rigor of histomorphometric analysis.Significance statement Although the importance of kidney morphometry is well explored in disease contexts, the definition of variance in reference tissue is not. Advancements in digital and computational pathology have rendered quantitative analysis of unprecedented tissue volumes via the single press of a button. The authors leverage the unique benefits of panoptic segmentation to perform the largest ever quantitation of reference kidney morphometry. Regression analysis identified several kidney morphometric features that varied significantly with patient age and sex, and the results suggested that the set size of nephrons might depend more intricately on creatinine than previously thought."
Deep learning and host variable embedding augment microbiome-based simultaneous detection of multiple diseases,"Microbiome has emerged as a promising indicator or predictor of human diseases. However, previous studies typically labeled each specimen as either healthy or with a specific disease, ignoring the prevalence of complications or comorbidities in actual cohorts, which may confound the microbial-disease associations. For instance, a patient may suffer from multiple diseases, making it challenging to detect their health status accurately. Furthermore, host phenotypes such as physiological characteristics and lifestyles can alter the microbiome structure, but this information has not yet been fully utilized in data models. To address these issues, we propose a highly explainable deep learning (DL) method called Meta-Spec. Using a deep neural network (DNN) based approach, it encodes and embeds the refined host variables with microbiome features, enabling the detection of multiple diseases and their correlations simultaneously. Our experiments showed that Meta-Spec outperforms regular machine learning (ML) strategies for multi-label disease screening in several cohorts. More importantly, Meta-Spec can successfully detect comorbidities that are often missed by regular ML approaches. In addition, due to its high interpretability, Meta-Spec captures key factors that shape disease patterns from host variables and microbial members. Hence, these efforts improve the feasibility and sensitivity of microbiome-based disease screening in practical scenarios, representing a significant step towards personalized medicine and better health outcomes."
Deep learning-based image-analysis identifies a DAT-negative subpopulation of dopaminergic neurons in the lateral Substantia nigra,"Here we present a deep learning-based image analysis platform (DLAP), tailored to autonomously quantify cell numbers, and fluorescence signals within cellular compartments, derived from RNAscope or immunohistochemistry. We utilized DLAP to analyse subtypes of tyrosine hydroxylase (TH)-positive dopaminergic midbrain neurons in mouse and human brain sections. These neurons modulate complex behaviour, and are differentially affected in Parkinson’s and other diseases. DLAP allows the analysis of large cell numbers, and facilitates the identification of small cellular subpopulations. Specifically, we identified a small subpopulation of TH-positive neurons (∼5%), mainly located in the very lateral Substantia nigra (SN), that was immunofluorescence-negative for the plasmalemma dopamine transporter (DAT), with ∼40% smaller cell bodies. These neurons were negative for aldehyde dehydrogenase 1A1, with a lower co-expression rate for dopamine-D2-autoreceptors, but a ∼7-fold higher likelihood of calbindin-d28k co-expression (∼70%). Our results have important implications, as DAT is crucial for dopamine-signalling, and is commonly used as a marker for dopaminergic SN neurons."
Deep learning for rapid and reproducible histology scoring of lung injury in a porcine model,"Acute respiratory distress syndrome (ARDS) is a life-threatening condition with mortality rates between 30-50%. Although in vitro models replicate some aspects of ARDS, small and large animal models remain the primary research tools due to the multifactorial nature of the disease. When using these animal models, histology serves as the gold standard method to confirm lung injury and exclude other diagnoses as high-resolution chest images are often not feasible. Semi-quantitative scoring performed by independent observers is the most common form of histologic analysis in pre-clinical animal models of ARDS. Despite progress in standardizing analysis procedures, objectively comparing histological injuries remains challenging, even for highly-trained pathologists. Standardized scoring simplifies the task and allows better comparisons between research groups and across different injury models, but it is time-consuming, and interobserver variability remains a significant concern. Convolutional neural networks (CNNs), which have emerged as a key tool in image analysis, could automate this process, potentially enabling faster and more reproducible analysis. Here we explored the reproducibility of human standardized scoring for an animal model of ARDS and its suitability for training CNNs for automated scoring at the whole slide level. We found large variations between human scorers, even for pre-clinical experts and board-certified pathologies in evaluating ARDS animal models. We demonstrate that CNNs (VGG16, EfficientNetB4) are suitable for automated scoring and achieve up to 83% F1-score and 78% accuracy. Thus, CNNs for histopathological classification of acute lung injury could help reduce human variability and eliminate a time-consuming manual research task with acceptable performance."
Deep learning-driven characterization of single cell tuning in primate visual area V4 unveils topological organization,"Deciphering the brain’s structure-function relationship is key to understanding the neuronal mechanisms underlying perception and cognition. The cortical column, a vertical organization of neurons with similar functions, is a classic example of primate neocortex structure-function organization. While columns have been identified in primary sensory areas using parametric stimuli, their prevalence across higher-level cortex is debated. A key hurdle in identifying columns is the difficulty of characterizing complex nonlinear neuronal tuning, especially with high-dimensional sensory inputs. Here, we asked whether area V4, a mid-level area of the macaque visual system, is organized into columns. We combined large-scale linear probe recordings with deep learning methods to systematically characterize the tuning of >1,200 V4 neurons using in silico synthesis of most exciting images (MEIs), followed by in vivo verification. We found that the MEIs of single V4 neurons exhibited complex features like textures, shapes, or even high-level attributes such as eye-like structures. Neurons recorded on the same silicon probe, inserted orthogonal to the cortical surface, were selective to similar spatial features, as expected from a columnar organization. We quantified this finding using human psychophysics and by measuring MEI similarity in a non-linear embedding space, learned with a contrastive loss. Moreover, the selectivity of the neuronal population was clustered, suggesting that V4 neurons form distinct functional groups of shared feature selectivity, reminiscent of cell types. These functional groups closely mirrored the feature maps of units in artificial vision systems, hinting at shared encoding principles between biological and artificial vision. Our findings provide evidence that columns and functional cell types may constitute universal organizing principles of the primate neocortex, simplifying the cortex’s complexity into simpler circuit motifs which perform canonical computations."
Forecasting the numbers of disease vectors with deep learning,"Arboviral diseases such as dengue, Zika, chikungunya or yellow fever are a worldwide concern. The abundance of vector species plays a key role in the emergence of outbreaks of these diseases, so forecasting these numbers is fundamental in preventive risk assessment. Here we describe and demonstrate a novel approach that uses state-of-the-art deep learning algorithms to forecast disease vector numbers. Unlike classical statistical and machine learning methods, deep learning models use time series data directly as predictors and identify the features that are most relevant from a predictive perspective. We demonstrate the application of this approach to predict temporal trends in the number of Aedes aegypti mosquito eggs across Madeira Island for the period 2013 to 2019. Specifically, we apply the deep learning models to predict whether, in the following week, the number of Ae. aegypti eggs will remain unchanged, or whether it will increase or decrease, considering different percentages of change. We obtained high predictive accuracy for all years considered (mean AUC = 0.92 ± 0.05 sd). We also found that the preceding numbers of eggs is a highly informative predictor of future numbers. Linking our approach to disease transmission or importation models will contribute to operational, early warning systems of arboviral disease risk."
"Deep Learning-Enabled, Detection of Rare Circulating Tumor Cell Clusters in Whole Blood Using Label-free, Flow Cytometry","Metastatic tumors have poor prognoses for progression-free and overall survival for all cancer patients. Rare circulating tumor cells (CTCs) and rarer circulating tumor cell clusters (CTCCs) are potential biomarkers of metastatic growth, with CTCCs representing an increased risk factor for metastasis. Current detection platforms are optimized for ex vivo detection of CTCs only. Microfluidic chips and size exclusion methods have been proposed for CTCC detection; however, they lack in vivo utility and real-time monitoring capability. Confocal backscatter and fluorescence flow cytometry (BSFC) has been used for label-free detection of CTCCs in whole blood based on machine learning (ML) enabled peak classification. Here, we expand to a deep-learning (DL) -based, peak detection and classification model to detect CTCCs in whole blood data. We demonstrate that DL-based BSFC has a low false alarm rate of 0.78 events/min with a high Pearson correlation coefficient of 0.943 between detected events and expected events. DL-based BSFC of whole blood maintains a detection purity of 72% and a sensitivity of 35.3% for both homotypic and heterotypic CTCCs starting at a minimum size of two cells. We also demonstrate through artificial spiking studies that DL-based BSFC is sensitive to changes in the number of CTCCs present in the samples and does not add variability in detection beyond the expected variability from Poisson statistics. The performance established by DL-based BSFC motivates its use for in vivo detection of CTCCs. Further developments of label-free BSFC to enhance throughput could lead to critical applications in the clinical detection of CTCCs and ex vivo isolation of CTCC from whole blood with minimal disruption and processing steps."
Influence of Temperate Forest Autumn Leaf Phenology on Segmentation of Tree Species from UAV Imagery Using Deep Learning,"Remote sensing of forests has become increasingly accessible with the use of unoccupied aerial vehicles (UAV), along with deep learning, allowing for repeated high-resolution imagery and the capturing of phenological changes at larger spatial and temporal scales. In temperate forests during autumn, leaf senescence occurs when leaves change colour and drop. However, the influence of leaf senescence in temperate forests on tree species segmentation using a Convolutional Neural Network (CNN) has not yet been evaluated. Here, we acquired high-resolution UAV imagery over a temperate forest in Quebec, Canada on seven occasions between May and October 2021. We segmented and labelled 23,000 tree crowns from 14 different classes to train and validate a CNN for each imagery acquisition. The CNN-based segmentation showed the highest F1-score (0.72) at the start of leaf colouring in early September and the lowest F1-score (0.61) at peak fall colouring in early October. The timing of the events occurring during senescence, such as leaf colouring and leaf fall, varied substantially between and within species and according to environmental conditions, leading to higher variability in the remotely sensed signal. Deciduous and evergreen tree species that presented distinctive and less temporally-variable traits between individuals were better classified. While tree segmentation in a heterogenous forest remains challenging, UAV imagery and deep learning show high potential in mapping tree species. Our results from a temperate forest with strong leaf colour changes during autumn senescence show that the best performance for tree species segmentation occurs at the onset of this colour change."
A deep learning framework for predicting the neutralizing activity of COVID-19 therapeutics and vaccines against evolving SARS-CoV-2 variants,"Understanding how viral variants evade neutralization is crucial for improving antibody-based treatments, especially with rapidly evolving viruses like SARS-CoV-2. Yet, conventional assays are limited in the face of rapid viral evolution, relying on a narrow set of viral isolates, and falling short in capturing the full spectrum of variants. To address this, we have developed a deep learning approach to predict changes in neutralizing antibody activity of COVID-19 therapeutics and vaccines against emerging viral variants. First, we trained a variational autoencoder (VAE) using all 67,885 unique SARS-CoV-2 spike protein sequences from the NCBI virus (up to October 31, 2022) database to encode spike protein variants into a latent space. Using this VAE and a curated dataset of 7,069 in vitro assay data points from the NCATS OpenData Portal, we trained a neural network regression model to predict fold changes in neutralizing activity of 40 COVID-19 therapeutics and vaccines against spike protein sequence variants, relative to their neutralizing activity against the ancestral strain (Wuhan-Hu-1). Our model also employs Bayesian inference to quantify prediction uncertainty, providing more nuanced and informative estimates. To validate the model’s predictive capacity, we assessed its performance on a test set of in vitro assay data collected up to eight months after the data included in the model training (N = 980). The model accurately predicted fold changes in neutralizing activity for this prospective dataset, with an R2 of 0.77. Expanding our methodology to include all available data from NCBI virus and NCATS OpenData Portal up to date, we assessed predicted changes in activity for current COVID-19 monoclonal antibodies and vaccines against newly identified SARS-CoV-2 lineages. Our predictions suggest that current therapeutic and vaccine-induced antibodies will have significantly reduced activity against newer XBB descendants, notably EG.5, FL.1.5.1, and XBB.1.16. Using the model, we were able to primarily attribute the observed predicted loss in activity to the F456L spike mutation found in EG.5 and FL.1.5.1 sequences. Conversely, mRNA-bivalent vaccines are predicted to be less susceptible to the recent BA.2.86 variant compared to new XBB descendants. These findings align closely with recent research, underscoring the potential of deep learning in shaping therapeutic and vaccine strategies for emerging viral variants."
CoCoNat: a novel method based on deep-learning for coiled-coil prediction,"Motivation Coiled-coil domains (CCD) are widespread in all organisms performing several crucial functions. Given their relevance, the computational detection of coiled-coil domains is very important for protein functional annotation. State-of-the art prediction methods include the precise identification of coiled-coil domain boundaries, the annotation of the typical heptad repeat pattern along the coiled-coil helices as well as the prediction of the oligomerization state.Results In this paper we describe CoCoNat, a novel method for predicting coiled-coil helix boundaries, residue-level register annotation and oligomerization state. Our method encodes sequences with the combination of two state-of-the-art protein language models and implements a three-step deep learning procedure concatenated with a Grammatical-Restrained Hidden Conditional Random Field (GRHCRF) for CCD identification and refinement. A final neural network (NN) predicts the oligomerization state. When tested on a blind test set routinely adopted, CoCoNat obtains a performance superior to the current state-of-the-art both for residue-level and segment-level coiled-coil detection. CoCoNat significantly outperforms the most recent state-of-the art method on register annotation and prediction of oligomerization states.Availability CoCoNat is available at https://coconat.biocomp.unibo.it.Contact pierluigi.martelli{at}unibo.it"
"Context-Dependent Design of Induced-fit Enzymes using Deep Learning Generates Well Expressed, Thermally Stable and Active Enzymes","The potential of engineered enzymes in practical applications is often constrained by limitations in their expression levels, thermal stability, and the diversity and magnitude of catalytic activities. De-novo enzyme design, though exciting, is challenged by the complex nature of enzymatic catalysis. An alternative promising approach involves expanding the capabilities of existing natural enzymes to enable functionality across new substrates and operational parameters. To this end we introduce CoSaNN (Conformation Sampling using Neural Network), a novel strategy for enzyme design that utilizes advances in deep learning for structure prediction and sequence optimization. By controlling enzyme conformations, we can expand the chemical space beyond the reach of simple mutagenesis. CoSaNN uses a context-dependent approach that accurately generates novel enzyme designs by considering non-linear relationships in both sequence and structure space. Additionally, we have further developed SolvIT, a graph neural network trained to predict protein solubility in E.Coli, as an additional optimization layer for producing highly expressed enzymes. Through this approach, we have engineered novel enzymes exhibiting superior expression levels, with 54% of our designs expressed in E.Coli, and increased thermal stability with more than 30% of our designs having a higher Tm than the template enzyme. Furthermore, our research underscores the transformative potential of AI in protein design, adeptly capturing high order interactions and preserving allosteric mechanisms in extensively modified enzymes. These advancements pave the way for the creation of diverse, functional, and robust enzymes, thereby opening new avenues for targeted biotechnological applications."
Domain-based multi-domain protein and complex structure prediction using inter-domain interactions from deep learning,"Accurately capturing domain-domain interactions is key to understanding protein function and designing structure-based drugs. Although AlphaFold2 has made a breakthrough on single domain, it should be noted that the structure modeling for multi-domain protein and complex remains a challenge. In this study, we developed a multi-domain and complex structure assembly protocol, named DeepAssembly, based on domain segmentation and single domain modeling algorithms. Firstly, DeepAssembly uses a population-based evolutionary algorithm to assemble multi-domain proteins by inter-domain interactions inferred from a developed deep learning network. Secondly, protein complexes are assembled by means of domains rather than chains using DeepAssembly. Experimental results show that on 219 multi-domain proteins, the average inter-domain distance precision by DeepAssembly is 22.7% higher than that of AlphaFold2. Moreover, DeepAssembly improves accuracy by 11.8% for 164 multi-domain structures with low confidence deposited in AlphaFold database. We apply DeepAssembly for the prediction of 247 heterodimers. We find that DeepAssembly generates models with acceptable quality (DockQ ≥ 0.23) for 32.4% of the dimers, suggesting a lighter way to assemble complex structures by treating domains as assembly units and using inter-domain interactions learned from monomer structures."
Fine-tuning TrailMap: The utility of transfer learning to improve the performance of deep learning in axon segmentation of light-sheet microscopy images,"Light-sheet microscopy has made possible the 3D imaging of both fixed and live biological tissue, with samples as large as the entire mouse brain. However, segmentation and quantification of that data remains a time-consuming manual undertaking. Machine learning methods promise the possibility of automating this process. This study seeks to advance the performance of prior models through optimizing transfer learning. We fine-tuned the existing TrailMap model using expert-labeled data from noradrenergic axonal structures in the mouse brain. By fine-tuning the final two layers of the neural network at a lower learning rate of the TrailMap model, we demonstrate an improved recall and an occasionally improved adjusted F1- score within our test dataset over using the originally trained TrailMap model.Availability and implementation: The software and data are freely available at https://github.com/pnnl/brain_ohsu and https://data.pnl.gov/group/204/nodes/dataset/35673, respectively."
Deep-learning based bioactive therapeutic peptides generation and screening,"Many bioactive peptides demonstrated therapeutic effects over-complicated diseases, such as antiviral, antibacterial, anticancer, etc. Similar to the generating de novo chemical compounds, with the accumulated bioactive peptides as a training set, it is possible to generate abundant potential bioactive peptides with deep learning. Such techniques would be significant for drug development since peptides are much easier and cheaper to synthesize than compounds. However, there are very few deep learning-based peptide generating models. Here, we have created an LSTM model (named LSTM_Pep) to generate de novo peptides and finetune learning to generate de novo peptides with certain potential therapeutic effects. Remarkably, the Antimicrobial Peptide Database has fully utilized in this work to generate various kinds of potential active de novo peptide. We proposed a pipeline for screening those generated peptides for a given target, and use Main protease of SARS-COV-2 as concept-of-proof example. Moreover, we have developed a deep learning-based protein-peptide prediction model (named DeepPep) for fast screening the generated peptides for the given targets. Together with the generating model, we have demonstrated iteratively finetune training, generating and screening peptides for higher predicted binding affinity peptides can be achieved. Our work sheds light on to the development of deep learning-based methods and pipelines to effectively generating and getting bioactive peptides with a specific therapeutic effect, and showcases how artificial intelligence can help discover de novo bioactive peptides that can bind to a particular target."
DeepMap: A deep learning-based model with a four-line code for prediction-based breeding in crops,"ABSTRACTPrediction of phenotype through genotyping data using the emerging machine or deep learning technology has been proven successful in genomic prediction. We present here a graphical processing unit (GPU) enabled DeepMap configurable deep learning-based python package for the genomic prediction of quantitative phenotype traits. We found that deep learning captures non-linear patterns more efficiently than conventional statistical methods. Furthermore, we suggest an additional module inclusion of epistasis interactions and training of the model on Graphical Processing Units (GPUs) in addition to Central Processing Unit (CPU) to enhance efficiency and increase the model’s performance. We developed and demonstrated the application of DeepMap using a 3K rice genome panel and 1K-Rice Custom Amplicon (1kRiCA) data for several phenotypic traits including days to 50% flowering (DTF), number of productive tillers (NPT), panicle length (PL), plant height (PH), and plot yield (PY). We have found that DeepMap outperformed the best existing state-of-the-art models by giving higher predictive correlation and low mean squared error for the datasets studied. This prediction performance was higher than other compared models in the range of 13-31%. Similarly for Dataset-2, significantly higher predictions were observed than the compared models (16-20% higher prediction ability). On Dataset-3, we have also shown the better and versatile performance of our model across crops (wheat, maize, and soybean) for yield and yield-related traits. This demonstrates the potentiality of the framework and ease of use for future research in crop improvement. The DeepMap is accessible at https://test.pypi.org/project/DeepMap-1.0/.Short Summary DeepMap is a deep learning-based breeder-friendly python package to perform genomic prediction. It utilizes epistatic interactions for data augmentation and outperforms the existing state-of-the-art machine/deep learning models such as Bayesian LASSO, GBLUP, DeepGS, and dualCNN. DeepMap developed for rice and tested across crops such as maize, wheat, soybean etc."
In silico evolution of protein binders with deep learning models for structure prediction and sequence design,"There has been considerable progress in the development of computational methods for designing protein-protein interactions, but engineering high-affinity binders without extensive screening and maturation remains challenging. Here, we test a protein design pipeline that uses iterative rounds of deep learning (DL)-based structure prediction (AlphaFold2) and sequence optimization (ProteinMPNN) to design autoinhibitory domains (AiDs) for a PD-L1 antagonist. Inspired by recent advances in therapeutic design, we sought to create autoinhibited (or masked) forms of the antagonist that can be conditionally activated by proteases. Twenty-three de novo designed AiDs, varying in length and topology, were fused to the antagonist with a protease sensitive linker, and binding to PD-L1 was tested with and without protease treatment. Nine of the fusion proteins demonstrated conditional binding to PD-L1 and the top performing AiDs were selected for further characterization as single domain proteins. Without any experimental affinity maturation, four of the AiDs bind to the PD-L1 antagonist with equilibrium dissociation constants (KDs) below 150 nM, with the lowest KD equal to 0.9 nM. Our study demonstrates that DL-based protein modeling can be used to rapidly generate high affinity protein binders.Significance statement Protein-protein interactions are critical to most processes in biology, and improved methods for designing protein binders will enable the creation of new research reagents, diagnostics, and therapeutics. In this study, we show that a deep learning-based method for protein design can create high-affinity protein binders without the need for extensive screening or affinity maturation."
BIBSNet: A Deep Learning Baby Image Brain Segmentation Network for MRI Scans,"Objectives Brain segmentation of infant magnetic resonance (MR) images is vitally important in studying developmental mental health and disease. The infant brain undergoes many changes throughout the first years of postnatal life, making tissue segmentation difficult for most existing algorithms. Here, we introduce a deep neural network BIBSNet (Baby and Infant Brain Segmentation Neural Network), an open-source, community-driven model that relies on data augmentation and a large sample size of manually annotated images to facilitate the production of robust and generalizable brain segmentations.Experimental Design Included in model training and testing were MR brain images on 84 participants with an age range of 0-8 months (median postmenstrual ages of 13.57 months). Using manually annotated real and synthetic segmentation images, the model was trained using a 10-fold cross-validation procedure. Testing occurred on MRI data processed with the DCAN labs infant-ABCD-BIDS processing pipeline using segmentations produced from gold standard manual annotation, joint-label fusion (JLF), and BIBSNet to assess model performance.Principal Observations Using group analyses, results suggest that cortical metrics produced using BIBSNet segmentations outperforms JLF segmentations. Additionally, when analyzing individual differences, BIBSNet segmentations perform even better.Conclusions BIBSNet segmentation shows marked improvement over JLF segmentations across all age groups analyzed. The BIBSNet model is 600x faster compared to JLF and can be easily included in other processing pipelines."
"A Modular, Adaptive, Deep-Learning-Based Brain-VR Interface","Brain-Computer Interfaces (BCIs) may open up new possibilities for Virtual Reality (VR) applications: BCIs may be used for active brain control of VR avatars, or to make VR content passively-adaptive based on information decoded from ongoing brain activity. Application domains for such Brain-VR Interfaces (BVRI) include medical and healthcare, entertainment, and education. Conversely, VR technology also opens up new possibilities for BCI research and development: E.g., gamified immersive BCI paradigms may improve subject engagement and long-term motivation, helping to study learning and adaptivity in the BCI-control context. Previously, we have demonstrated a first adaptive, deep-learning-based online BCI for the control of robotic assistants. Here, we describe the extension of this setup to a modular, extensible, VR-compatible online BCI setup. We describe how we integrated a classical active BCI control paradigm using motor imagery into a gamified interactive VR scenario, designed to enhance the long-term motivation of subjects. We also present an initial quality assessment of electroencephalographic (EEG) signals acquired with a dry-electrode system. We anticipate that the presented modular adaptive Brain-VR Interface will help to understand and facilitate (co-)adaptivity during long-term BCI usage."
ASTRA: a deep learning algorithm for fast semantic segmentation of large-scale astrocytic networks,"Changes in the intracellular calcium concentration are a fundamental fingerprint of astrocytes, the main type of glial cell. Astrocyte calcium signals can be measured with two-photon microscopy, occur in anatomically restricted subcellular regions, and are coordinated across astrocytic networks. However, current analytical tools to identify the astrocytic subcellular regions where calcium signals occur are time-consuming and extensively rely on user-defined parameters. These limitations limit reproducibility and prevent scalability to large datasets and fields-of-view. Here, we present Astrocytic calcium Spatio-Temporal Rapid Analysis (ASTRA), a novel software combining deep learning with image feature engineering for fast and fully automated semantic segmentation of two-photon calcium imaging recordings of astrocytes. We applied ASTRA to several two-photon microscopy datasets and found that ASTRA performed rapid detection and segmentation of astrocytic cell somata and processes with performance close to that of human experts, outperformed state-of-the-art algorithms for the analysis of astrocytic and neuronal calcium data, and generalized across indicators and acquisition parameters. We also applied ASTRA to the first report of two-photon mesoscopic imaging of hundreds of astrocytes in awake mice, documenting large-scale redundant and synergistic interactions in extended astrocytic networks. ASTRA is a powerful tool enabling closed-loop and large-scale reproducible investigation of astrocytic morphology and function."
SlumberNet: Deep learning classification of sleep stages using residual neural networks,"Sleep research is fundamental to understanding health and well-being, as proper sleep is essential for maintaining optimal physiological function. Here we present SlumberNet, a novel deep learning model based on residual network (ResNet) architecture, designed to classify sleep states in mice using electroencephalogram (EEG) and electromyogram (EMG) signals. Our model was trained and tested on data from mice undergoing baseline sleep, sleep deprivation, and recovery sleep, enabling it to handle a wide range of sleep conditions. Employing k-fold cross-validation and data augmentation techniques, SlumberNet achieved high levels of accuracy (∼98%) in predicting sleep stages and showed robust performance even with a small and diverse training dataset. Comparison of SlumberNet’s performance to manual sleep stage classification revealed a significant reduction in analysis time (∼50x faster), without sacrificing accuracy. Our study showcases the potential of deep learning to facilitate sleep research by providing a more efficient, accurate, and scalable method for sleep stage classification. Our work with SlumberNet demonstrates the power of deep learning in sleep research, and looking forward, SlumberNet could be adapted to human EEG analysis and sleep stage classification. Thus, SlumberNet could be a valuable tool in understanding both sleep physiology and disorders in mammals."
Building Trust in Deep Learning-based Immune Response Predictors with Interpretable Explanations,"The ability to predict whether a peptide will get presented on Major Histocompatibility Complex (MHC) class I molecules has profound implications in designing vaccines. Numerous deep learning-based predictors for peptide presentation on MHC class I molecules exist with high levels of accuracy. However, these MHC class I predictors are treated as black-box functions, providing little insight into their decision making. To build turst in these predictors, it is crucial to understand the rationale behind their decisions with human-interpretable explanations. We present MHCXAI, eXplainable AI (XAI) techniques to help interpret the outputs from MHC class I predictors in terms of input peptide features. In our experiments, we explain the outputs of four state-of-the-art MHC class I predictors over a large dataset of peptides and MHC alleles. Additionally, we evaluate the reliability of the explanations by comparing against ground truth and checking their robustness. MHCXAI seeks to increase understanding of deep learning-based predictors in the immune response domain and build trust with validated explanations"
Automatic Classification of Normal and Abnormal Cell Division Using Deep Learning Analysis of Mitosis Videos,"In recent years, there has been a surge in the development of methods for cell segmentation and tracking, with initiatives such as the Cell Tracking Challenge driving progress in the field. Most studies focus on regular cell population videos in which cells are segmented, cell tracks followed, and parental relationships annotated. However, DNA damage induced by genotoxic drugs or ionizing radiation provide additional abnormal cellular events of interest since they lead to aberrant behaviors such as abnormal cell divisions (i.e., resulting in a number of daughter cells different from two) and cell death.The dynamic development of those abnormal events can be followed using time lapse microscopy to be further analyzed. With this in mind, we developed an automatic mitosis classifier that categorizes small mitosis image sequences centered around a single cell as “Normal” or “Abnormal.” These mitosis sequences were extracted from videos of cell populations exposed to varying levels of radiation that affect the cell cycle’s development. Such an approach can aid in detecting, tracking, and characterizing the behavior of the entire population.In this study, we explored several deep-learning architectures for working with 12-frame mitosis sequences. We found that a network with a ResNet50 backbone, modified to operate independently on each video frame and then combined using a Long Short-Term Memory (LSTM) layer, produced the best results in the classification (mean F1-score: 0.93 ± 0.06). In future work, we plan to integrate the mitosis classifier in a cell segmentation and tracking pipeline to build phylogenetic trees of the entire cell population after genomic stress.Author Summary In recent years, there has been a growing interest in developing methods to analyze videos of cell populations, which show how cells move and divide over time. Typically, researchers focus on developing methods to automatically identify and track individual cells and their divisions. However, exposure to anticancer drugs or radiation can cause uncommon behaviors, such as abnormal cell divisions, which are of interest to experts studying the effects of these agents on cell behavior.To address this issue, we developed an automated tool that can determine whether a specific cell division seen in a video is normal or abnormal. We used video microscopy to capture small sequences of cell division, and then trained a deep-learning model to classify these sequences as either normal or abnormal. We found that our model achieved a high level of accuracy in this task.Our tool has the potential to aid experts in identifying abnormal cellular events, providing insights into the effects of genotoxic agents on cell behavior. In future work, we plan to integrate our tool into more complex methods for analyzing cell population videos, which may help us better understand the impact of toxic agents on the behavior of the entire cell population."
"EGGNet, a generalizable geometric deep learning framework for protein complex pose scoring","Computational prediction of molecule-protein interactions has been key for developing new molecules to interact with a target protein for therapeutics development. Past work includes two independent streams of approaches: (1) predicting protein-protein interactions (PPI) between naturally occurring proteins and (2) predicting the binding affinities between proteins and small molecule ligands (aka drug target interaction, or DTI). Studying the two problems in isolation has limited the ability of these computational models to generalize across the PPI and DTI tasks, both of which ultimately involve non-covalent interactions with a protein target. In this work, we developed an Equivariant Graph of Graphs neural Network (EGGNet), a geometric deep learning framework for molecule-protein binding predictions that can handle three types of molecules for interacting with a target protein: (1) small molecules, (2) synthetic peptides and (3) natural proteins. EGGNet leverages a graph of graphs (GoGs) representation constructed from the molecule structures at atomic-resolution and utilizes a multi-resolution equivariant graph neural network (GNN) to learn from such representations. In addition, EGGNet leverages the underlying biophysics and makes use of both atom- and residue-level interactions, which improve EGGNet’s ability to rank candidate poses from blind docking. EGGNet achieves competitive performance on both a public proteinsmall molecule binding affinity prediction task (80.2% top-1 success rate on CASF-2016) and an synthetic protein interface prediction task (88.4% AUPR). We envision that the proposed geometric deep learning framework can generalize to many other protein interaction prediction problems, such as binding site prediction and molecular docking, helping accelerate protein engineering and structure-based drug development."
Riboformer: A Deep Learning Framework for Predicting Context-Dependent Translation Dynamics,"Translation elongation is essential for maintaining cellular proteostasis, and alterations in the translational landscape are associated with a range of diseases. Ribosome profiling allows detailed measurement of translation at genome scale. However, it remains unclear how to disentangle biological variations from technical artifacts and identify sequence determinant of translation dysregulation. Here we present Riboformer, a deep learning-based framework for modeling context-dependent changes in translation dynamics. Riboformer leverages the transformer architecture to accurately predict ribosome densities at codon resolution. It corrects experimental artifacts in previously unseen datasets, reveals subtle differences in synonymous codon translation and uncovers a bottleneck in protein synthesis. Further, we show that Riboformer can be combined with in silico mutagenesis analysis to identify sequence motifs that contribute to ribosome stalling across various biological contexts, including aging and viral infection. Our tool offers a context-aware and interpretable approach for standardizing ribosome profiling datasets and elucidating the regulatory basis of translation kinetics."
Rapid Synthesis of Cryo-ET Data for Training Deep Learning Models,"Deep learning excels at cryo-tomographic image restoration and segmentation tasks but is hindered by a lack of training data. Here we introduce cryo-TomoSim (CTS), a MATLAB-based software package that builds coarse-grained models of macromolecular complexes embedded in vitreous ice and then simulates transmitted electron tilt series for tomographic reconstruction. We then demonstrate the effectiveness of these simulated datasets in training different deep learning models for use on real cryotomographic reconstructions. Computer-generated ground truth datasets provide the means for training models with voxel-level precision, allowing for unprecedented denoising and precise molecular segmentation of datasets. By modeling phenomena such as a three-dimensional contrast transfer function, probabilistic detection events, and radiation-induced damage, the simulated cryo-electron tomograms can cover a large range of imaging content and conditions to optimize training sets. When paired with small amounts of training data from real tomograms, networks become incredibly accurate at segmenting in situ macromolecular assemblies across a wide range of biological contexts.Summary By pairing rapidly synthesized Cryo-ET data with computed ground truths, deep learning models can be trained to accurately restore and segment real tomograms of biological structures both in vitro and in situ."
"FocA: A deep learning tool for reliable, near-real-time imaging focus analysis in automated cell assay pipelines","The increasing use of automation in cellular assays and cell culture presents significant opportunities to enhance the scale and throughput of imaging assays, but to do so, reliable data quality and consistency are critical. Realizing the full potential of automation will thus require the design of robust analysis pipelines that span the entire workflow in question. Here we present FocA, a deep learning tool that, in near real-time, identifies in-focus and out-of-focus images generated on a fully automated cell biology research platform, the NYSCF Global Stem Cell Array®. The tool is trained on small patches of downsampled images to maximize computational efficiency without compromising accuracy, and optimized to make sure no sub-quality images are stored and used in downstream analyses. The tool automatically generates balanced and maximally diverse training sets to avoid bias. The resulting model correctly identifies 100% of out-of-focus and 98% of in-focus images in under 4 seconds per 96-well plate, and achieves this result even in heavily downsampled data (∼30 times smaller than native resolution). Integrating the tool into automated workflows minimizes the need for human verification as well as the collection and usage of low-quality data. FocA thus offers a solution to ensure reliable image data hygiene and improve the efficiency of automated imaging workflows using minimal computational resources."
EvoAug: improving generalization and interpretability of genomic deep neural networks with evolution-inspired data augmentations,"ABSTRACTDeep neural networks (DNNs) hold promise for functional genomics prediction, but their generalization capability may be limited by the amount of available data. To address this, we propose EvoAug, a suite of evolution-inspired augmentations that enhance the training of genomic DNNs by increasing genetic variation. However, random transformation of DNA sequences can potentially alter their function in unknown ways. Thus, we employ a fine-tuning procedure using the original non-transformed data to preserve functional integrity. Our results demonstrate that EvoAug substantially improves the generalization and interpretability of established DNNs across prominent regulatory genomics prediction tasks, offering a robust solution for genomic DNNs."
DeepOM: Single-molecule optical genome mapping via deep learning,"Efficient tapping into genomic information from a single microscopic image of an intact DNA molecule fragment is an outstanding challenge and its solution will open new frontiers in molecular diagnostics. Here, a new computational method for optical genome mapping utilizing Deep Learning is presented, termed DeepOM. Utilization of a Convolutional Neural Network (CNN), trained on simulated images of labeled DNA molecules, improves the success rate in alignment of DNA images to genomic references. The method is evaluated on acquired images of human DNA molecules stretched in nano-channels. The accuracy of the method is benchmarked against state-of-the-art commercial software Bionano Solve. The results show a significant advantage in alignment success rate for molecules shorter than 50 kb. DeepOM improves yield, sensitivity and throughput of optical genome mapping experiments in applications of human genomics and microbiology."
De Novo Design of κ-Opioid Receptor Antagonists Using a Generative Deep Learning Framework,"ABSTRACTLikely effective pharmacological interventions for the treatment of opioid addiction include attempts to attenuate brain reward deficits during periods of abstinence. Pharmacological blockade of the κ-opioid receptor (KOR) has been shown to abolish brain reward deficits in rodents during withdrawal, as well as to reduce the escalation of opioid use in rats with extended access to opioids. Although KOR antagonists represent promising candidates for the treatment of opioid addiction, very few potent selective KOR antagonists are known to date and most of them exhibit significant safety concerns. Here, we used a generative deep learning framework for the de novo design of chemotypes with putative KOR antagonistic activity. Molecules generated by models trained with this framework were prioritized for chemical synthesis based on their predicted optimal interactions with the receptor. Our models and proposed training protocol were experimentally validated by binding and functional assays."
Predicting Gene Spatial Expression and Cancer Prognosis: An Integrated Graph and Image Deep Learning Approach Based on HE Slides,"ABSTRACTInterpreting the tumor microenvironment (TME) heterogeneity within solid tumors presents a cornerstone for precise disease diagnosis and prognosis. However, while spatial transcriptomics offers a wealth of data, ranging from gene expression and spatial location to corresponding Hematoxylin and Eosin (HE) images, to explore the TME of various cancers, its high cost and demanding infrastructural needs significantly limit its clinical application, highlighting the need for more accessible alternatives. To bridge this gap, we introduce the Integrated Graph and Image Deep Learning (IGI-DL) model. This innovation, a fusion of Convolutional Neural Networks and Graph Neural Networks, is designed to predict gene spatial expression using HE images. The IGI-DL model outperforms its predecessors in analyzing colorectal cancer (CRC), breast cancer, and cutaneous squamous cell carcinoma (cSCC) by leveraging both pixel intensity and structural features in images. Significantly, across all cancer types, the IGI-DL model enhances the mean correlation of the top five genes by an average of 0.125 in internal and external test sets, rising from 0.306 to 0.431, surpassing existing state-of-the-art (SOTA) models. We further present a novel risk score derived from a super-patch graph, where gene expression predicted by IGI-DL serves as node features. Demonstrating superior prognostic accuracy, this risk score, with a C-index of 0.713 and 0.741 for CRC and breast cancer, supersedes traditional HE-based risk scores. In summary, the approach augments our understanding of the TME from the aspect of histological images, portending a transformation in cancer prognostics and treatment planning and ushering in a new era of personalized and precision oncology."
Deep learning for histopathological subtyping and grading of lung adenocarcinoma,"ABSTRACTThe histopathological distinction of lung adenocarcinoma (LADC) subtypes is subject to high inter-observer variability, which can compromise the optimal assessment of the patient prognosis. Therefore, this study developed convolutional neural networks (CNNs) capable of distinguishing LADC subtypes and predicting disease-specific survival, according to the LADC tumour grades established recently by the International Association for the Study of Lung Cancer pathology committee. Consensus LADC ground truth histopathological images were obtained from seventeen expert pulmonary pathologists and one pathologist in training. Two deep learning models (AI-1 and AI-2) were trained with EfficientNet b3 architecture to predict eight different LADC classes (lepidic, acinar, papillary, micropapillary, solid, invasive mucinous adenocarcinoma, other carcinoma types, and no carcinoma cells). Furthermore, the trained models were tested on an independent cohort of 133 patients. The models achieved high precision, recall, and F1-scores exceeding 0.90 for most of the LADC classes. Clear stratification of the three LADC grades was reached in predicting the disease-specific survival by the two models. Moreover, the grading prediction of one of the trained models was more accurate than those of 14 out of 15 pulmonary pathologists involved in the study (p=0.0003). Both trained models showed high stability in the segmentation of each pair of predicted grades with low variation in the hazard ratio across 200 bootstrapped samples. These findings indicate that the trained CNNs improve the diagnostic accuracy of the pathologist, standardise LADC subtype recognition, and refine LADC grade assessment. Thus, the trained models are promising tools that may assist in the routine evaluation of LADC subtypes and grades in clinical practice."
"DeepComBat: A Statistically Motivated, Hyperparameter-Robust, Deep Learning Approach to Harmonization of Neuroimaging Data","Neuroimaging data from multiple batches (i.e. acquisition sites, scanner manufacturer, datasets, etc.) are increasingly necessary to gain new insights into the human brain. However, multi-batch data, as well as extracted radiomic features, exhibit pronounced technical artifacts across batches. These batch effects introduce confounding into the data and can obscure biological effects of interest, decreasing the generalizability and reproducibility of findings. This is especially true when multi-batch data is used alongside complex downstream analysis models, such as machine learning methods. Image harmonization methods seeking to remove these batch effects are important for mitigating these issues; however, significant multivariate batch effects remain in the data following harmonization by current state-of-the-art statistical and deep learning methods. We present DeepCombat, a deep learning harmonization method based on a conditional variational autoencoder architecture and the ComBat harmonization model. DeepCombat learns and removes subject-level batch effects by accounting for the multivariate relationships between features. Additionally, DeepComBat relaxes a number of strong assumptions commonly made by previous deep learning harmonization methods and is empirically robust across a wide range of hyperparameter choices. We apply this method to neuroimaging data from a large cognitive-aging cohort and find that DeepCombat outperforms existing methods, as assessed by a battery of machine learning methods, in removing scanner effects from cortical thickness measurements while preserving biological heterogeneity. Additionally, DeepComBat provides a new perspective for statistically-motivated deep learning harmonization methods."
Automated whole-organ histological imaging assisted with ultraviolet-excited sectioning tomography and deep learning,"Three-dimensional (3D) histopathology involves the microscopic examination of a specimen, which plays a vital role in studying tissue’s 3D structures and the signs of diseases. However, acquiring high-quality histological images of a whole organ is extremely time-consuming (e.g., several weeks) and laborious, as the organ has to be sectioned into hundreds or thousands of slices for imaging. Besides, the acquired images are required to undergo a complicated image registration process for 3D reconstruction. Here, by incorporating a recently developed vibratome-assisted block-face imaging technique with deep learning, we developed a pipeline termed HistoTRUST that can rapidly and automatically generate subcellular whole organ’s virtual hematoxylin and eosin (H&E) stained histological images which can be reconstructed into 3D by simple image stacking (i.e., without registration). The performance and robustness of HistoTRUST have been successfully validated by imaging all vital mouse organs (brain, liver, kidney, heart, lung, and spleen) within 1–3 days depending on the size. The generated 3D dataset has the same color tune as the traditional H&E stained histological images. Therefore, the virtual H&E stained images can be directly analyzed by pathologists. HistoTRUST has a high potential to serve as a new standard in providing 3D histology for research or clinical applications."
Exploration of DPP-IV inhibitory peptide design rules assisted by deep learning pipeline that identifies restriction enzyme cutting site,"Mining of anti-diabetic dipeptidyl peptidase IV (DPP-IV) inhibitory peptides (DPP-IV-IPs) is currently a costly and laborious process. Due to the absence of rational peptide design rules, it relies on cumbersome screening of unknown enzyme hydrolysates. Here, we present an enhanced deep learning (DL) model called BERT-DPPIV, specifically designed to classify DPP-IV-IPs and exploring their design rules to discover potent candidates. The end-to-end model utilizes a fine-tuned bidirectional encoder representations (BERT) architecture to extract structural/functional information from input peptides and accurately identify DPP-IV-Ips from input peptides. Experimental results in benchmark dataset showed BERT-DPPIV yielded state-of-the-art accuracy of 0.894, surpassing the 0.797 obtained by sequence-feature model. Furthermore, we leverage the attention mechanism to uncover that our model could recognize restriction enzyme cutting site and specific residues that contribute to the inhibition of DPP-IV. Moreover, guided by BERT-DPPIV, proposed design rules of DPP-IV inhibitory tripeptides and pentapeptides were validated and they can be used to screen potent DPP-IV-IPs."
"SENSE-PPI reconstructs protein-protein interactions of various complexities, within, across, and between species, with sequence-based evolutionary scale modeling and deep learning","Ab initio computational reconstructions of protein-protein interaction (PPI) networks will provide invaluable insights on cellular systems, enabling the discovery of novel molecular interactions and elucidating biological mechanisms within and between organisms. Leveraging latest generation protein language models and recurrent neural networks, we present SENSE-PPI, a sequence-based deep learning model that efficiently reconstructs ab initio PPIs, distinguishing partners among tens of thousands of proteins and identifying specific interactions within functionally similar proteins. SENSE-PPI demonstrates high accuracy, limited training requirements, and versatility in cross-species predictions, even with non-model organisms and human-virus interactions. Its performance decreases for phylogenetically more distant model and non-model organisms, but signal alteration is very slow. SENSE-PPI is state-of-the-art, outperforming all existing methods. In this regard, it demonstrates the important role of parameters in protein language models. SENSE-PPI is very fast and can test 10,000 proteins against themselves in a matter of hours, enabling the reconstruction of genome-wide proteomes.Graphical abstract SENSE-PPI is a general deep learning architecture predicting protein-protein interactions of different complexities, between stable proteins, between stable and intrinsically disordered proteins, within a species, and between species. Trained on one species, it accurately predicts interactions and reconstructs complete specialized subnetworks for model and non-model organisms, and trained on human-virus interactions, it predicts human-virus interactions for new viruses.Download figureOpen in new tab"
